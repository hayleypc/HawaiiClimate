{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hayleypc/HawaiiClimate/blob/main/gen_soil_dl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FJSR_lUJAuGW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfASAHA7B1a0",
        "outputId": "6fd38b16-2495-486b-a68a-93919e33f7f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from shapely.geometry import Point\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "FUiG_4XBCkTW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(matched_data):\n",
        "    # Initial preprocessing\n",
        "    matched_data['distance'] = 0\n",
        "    matched_data = matched_data[matched_data[\"depth_adj_bottom\"] == '20']\n",
        "    matched_data['imp_c_float'] = [float(datum) for datum in matched_data['imp_c']]\n",
        "\n",
        "    # Select ID fields that are non-numeric since can't run minmax scalar over non numeric\n",
        "    id_fields = matched_data[['source_dataset', 'island','dist_id', 'soil_column_id', 'unique_id', 'depth_top', 'depth_bottom', 'depth_adj_bottom', 'latitude', 'longitude']]\n",
        "\n",
        "    # Select numeric columns and preprocess\n",
        "    keep_cols = ['water', 'trees','grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built',\n",
        "                 'bare', 'snow_and_ice', 'max', 'elevation', 'landform', 'SRTM_mTPI','aet', 'def',\n",
        "                 'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn','tmmx', 'vap', 'vpd', 'vs',\n",
        "                 'agbd_m', 'agbd_sd', 'agbd_n']\n",
        "    numeric_cols = matched_data[keep_cols]\n",
        "    numeric_cols.replace('', np.nan, inplace=True)\n",
        "    numeric_cols = numeric_cols.astype(float)\n",
        "    numeric_cols.fillna(0, inplace=True)\n",
        "\n",
        "    # Scale numeric columns\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(numeric_cols)\n",
        "    scaled_numeric_cols = scaler.transform(numeric_cols)\n",
        "    scaled_numeric_df = pd.DataFrame(scaled_numeric_cols, columns=numeric_cols.columns, index=numeric_cols.index)\n",
        "\n",
        "    #min max scale imp_c, keep scalers\n",
        "    min_c = np.min(matched_data['imp_c_float'])\n",
        "    max_c = np.max(matched_data['imp_c_float'])\n",
        "    scaled_imp_c = (matched_data['imp_c_float'] - min_c) / (max_c - min_c)\n",
        "\n",
        "    # Combine ID fields with scaled numeric data\n",
        "    numeric_df = pd.concat([id_fields, scaled_numeric_df], axis=1)\n",
        "\n",
        "    numeric_df['imp_c_scaled'] = scaled_imp_c\n",
        "\n",
        "    return numeric_df, scaler, min_c, max_c"
      ],
      "metadata": {
        "id": "tFN33P-3ljuY"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_a(preprocess_data):\n",
        "\n",
        "    keep_cols = ['water', 'trees','grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built',\n",
        "                'bare', 'snow_and_ice', 'max', 'elevation', 'landform', 'SRTM_mTPI','aet', 'def',\n",
        "                'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn','tmmx', 'vap', 'vpd', 'vs',\n",
        "                'agbd_m', 'agbd_sd', 'agbd_n']\n",
        "\n",
        "    X = preprocess_data[keep_cols]\n",
        "\n",
        "    y = preprocess_data['imp_c_scaled']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define model\n",
        "    def build_model(input_shape):\n",
        "        model = Sequential([\n",
        "            Dense(256, activation='relu', input_dim=input_shape),\n",
        "            BatchNormalization(),\n",
        "            LeakyReLU(alpha=0.2),\n",
        "            Dropout(0.3),\n",
        "            Dense(512, activation='relu'),\n",
        "            BatchNormalization(),\n",
        "            LeakyReLU(alpha=0.2),\n",
        "            Dropout(0.3),\n",
        "            Dense(1024, activation='relu'),\n",
        "            BatchNormalization(),\n",
        "            LeakyReLU(alpha=0.2),\n",
        "            Dropout(0.3),\n",
        "            Dense(1, activation='linear')\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "    model = build_model(X_train.shape[1])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "    model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=128, verbose=1)\n",
        "\n",
        "    test_loss = model.evaluate(X_test, y_test)\n",
        "    predictions = model.predict(X_test).flatten()\n",
        "    r_squared = r2_score(y_test, predictions)\n",
        "\n",
        "    return model, test_loss, r_squared, predictions, y_test"
      ],
      "metadata": {
        "id": "YyxssltZsc4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imputed SOC dostributions\n",
        "file_path = '/content/drive/MyDrive/hawaii_soils/HI soils data/annotated_combo_imputed_SOC.gpkg'\n",
        "\n",
        "gdf = gpd.read_file(file_path)"
      ],
      "metadata": {
        "id": "Ota0Xkobt8hJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_reserve(preprocess_data, model, min_c, max_c):\n",
        "\n",
        "    df_out = preprocess_data.copy()\n",
        "    keep_cols = ['water', 'trees','grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built',\n",
        "                'bare', 'snow_and_ice', 'max', 'elevation', 'landform', 'SRTM_mTPI','aet', 'def',\n",
        "                'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn','tmmx', 'vap', 'vpd', 'vs',\n",
        "                'agbd_m', 'agbd_sd', 'agbd_n']\n",
        "\n",
        "    X = preprocess_data[keep_cols]\n",
        "    y = preprocess_data['imp_c_scaled']\n",
        "\n",
        "    # Predictions and Evaluation\n",
        "    predictions = model.predict(X)\n",
        "\n",
        "    inversed_predictions =  predictions*max_c+min_c\n",
        "\n",
        "    inversed_truth =  y*max_c+min_c\n",
        "\n",
        "    df_out['predictions'] = predictions\n",
        "    df_out['inversed_predictions'] = inversed_predictions\n",
        "    df_out['inversed_imp_c'] = inversed_truth\n",
        "\n",
        "    return df_out"
      ],
      "metadata": {
        "id": "1AHGSofJHYxA"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, scaler, inversed_predictions, inversed_truth):\n",
        "    test_loss = model.evaluate(X_test, y_test)\n",
        "    r_squared = r2_score(inversed_truth, inversed_predictions)\n",
        "\n",
        "    print(\"Test Loss:\", test_loss)\n",
        "    print(\"R-Squared Score:\", r_squared)\n",
        "\n",
        "    mae = mean_absolute_error(inversed_truth, inversed_predictions)\n",
        "    rmse = mean_squared_error(inversed_truth, inversed_predictions, squared=False)\n",
        "\n",
        "    print(\"Mean Absolute Error (MAE):\", mae)\n",
        "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "    # Scatter plot of true vs predicted values\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=inversed_truth, y=inversed_predictions)\n",
        "    plt.xlabel(\"True Values\")\n",
        "    plt.ylabel(\"Predicted Values\")\n",
        "    plt.title(\"True vs Predicted Values\")\n",
        "    plt.plot([min(inversed_truth), max(inversed_truth)], [min(inversed_truth), max(inversed_truth)], 'r')  # Diagonal line\n",
        "    plt.show()\n",
        "\n",
        "    # Residual plot\n",
        "    residuals = inversed_truth - inversed_predictions\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(residuals, kde=True)\n",
        "    plt.xlabel(\"Residuals\")\n",
        "    plt.title(\"Distribution of Residuals\")\n",
        "    plt.show()\n",
        "\n",
        "# Assuming model, test_loss, r_squared, inversed_predictions, inversed_truth, X_test, and y_test are already computed\n",
        "# model, test_loss, r_squared, inversed_predictions, inversed_truth, scaler, X_test, y_test = preprocess_and_train_model(matched_data)\n",
        "# evaluate_model(model, X_test, y_test, scaler, inversed_predictions, inversed_truth)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wnH4d79kDHXt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/sequence_data.csv'"
      ],
      "metadata": {
        "id": "46NsUEt2B80A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drivers_gpd = gpd.read_file('/content/drive/MyDrive/hawaii_soils/Analysis Data/250_summary_grid_dt.gpkg')"
      ],
      "metadata": {
        "id": "PcbyIy1MCszn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soils_csv = gpd.read_file('/content/drive/MyDrive/hawaii_soils/HI soils data/combined_soc_2024_04_05.csv')"
      ],
      "metadata": {
        "id": "4T2wvedGC1aG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame using .loc\n",
        "soils_csv = soils_csv.loc[(soils_csv['latitude'] != '') & (soils_csv['longitude'] != '')]\n",
        "\n",
        "# Create geometry column\n",
        "soils_csv['geometry'] = soils_csv.apply(lambda row: Point(float(row['longitude']), float(row['latitude'])), axis=1)\n",
        "\n",
        "# Convert to GeoDataFrame\n",
        "soils_gpd = gpd.GeoDataFrame(soils_csv, geometry='geometry', crs=\"EPSG:4326\")\n"
      ],
      "metadata": {
        "id": "-dInVuj0McBJ"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soils_gpd = pd.merge(soils_gpd, gdf.loc[:,['dist_id','unique_id']], on='unique_id', how='inner')"
      ],
      "metadata": {
        "id": "iJhuUp8kGGRe"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure both GeoDataFrames have the same CRS\n",
        "soils_gpd = soils_gpd.to_crs(drivers_gpd.crs)\n",
        "\n",
        "# Perform spatial join\n",
        "matched_data = gpd.sjoin_nearest(soils_gpd, drivers_gpd, how='left', distance_col='distance')"
      ],
      "metadata": {
        "id": "GUDqgLj2FDfT"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply a buffer to each geometry in one of the GeoDataFrames (e.g., soils_gpd)\n",
        "soils_buffered = soils_gpd.copy()\n",
        "\n",
        "soils_buffered.geometry = soils_buffered.to_crs(epsg=32604).geometry.buffer(1000).to_crs('ESRI:102261')\n",
        "\n",
        "# soils_gpd = soils_gpd\n",
        "# Step 2: Spatial Join\n",
        "# Perform a spatial join with the buffered GeoDataFrame\n",
        "# This finds all drivers_gpd points that fall within the 10,000-meter buffer of any point in soils_gpd\n",
        "matches_within_distance = gpd.sjoin(soils_buffered, drivers_gpd, how='left', predicate='intersects')\n"
      ],
      "metadata": {
        "id": "d7TjwVCOXV91"
      },
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_df, scaler, min_c, max_c = preprocess_data(matches_within_distance)"
      ],
      "metadata": {
        "id": "7hc2a8E_1bWn",
        "outputId": "38c50c38-55f2-4645-8d78-c613bc4257c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/geopandas/geodataframe.py:1528: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "<ipython-input-222-48d85629ab51>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  numeric_cols.replace('', np.nan, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s-Jt3JrELLJU",
        "outputId": "8bdd7349-9355-4b13-c42f-a88c6ea5e3d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['20'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frequency_table = numeric_df['unique_id'].value_counts().reset_index()\n",
        "frequency_table.columns = ['unique_id', 'count']\n",
        "frequency_table['count'].unique()"
      ],
      "metadata": {
        "id": "bl5Ni-qj4dae",
        "outputId": "7c49eac1-65e6-4bf2-fe52-6ef2b0a533a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 38, 37, 36, 35,\n",
              "       34, 33, 32, 31, 30, 29, 28, 27, 26, 22,  3,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting one random distribution id to leave out for cross validation\n",
        "xval_id = np.random.choice(numeric_df['dist_id'].unique())"
      ],
      "metadata": {
        "id": "kXiKA2lh13Ez"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reserve_data = numeric_df[numeric_df['dist_id']!=xval_id].groupby('unique_id').sample(n=1)\n",
        "# reserve_data"
      ],
      "metadata": {
        "id": "66ai8EL22Hl3"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reserve_data = numeric_df[numeric_df['dist_id']!=xval_id].groupby('unique_id').sample(n=1)\n",
        "reserve_data"
      ],
      "metadata": {
        "id": "0-8dcQyH4Nmk",
        "outputId": "2058c02b-751a-4372-9636-72db223afcd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     source_dataset island  dist_id soil_column_id unique_id depth_top  \\\n",
              "0               FIA  Kauai      NaN       FIA_1060      FIA1         0   \n",
              "100             FIA   Oahu      NaN       FIA_1433    FIA101         0   \n",
              "105             FIA   Oahu      NaN       FIA_1454    FIA106         0   \n",
              "10              FIA  Kauai      NaN       FIA_1077     FIA11         0   \n",
              "110             FIA   Oahu      NaN       FIA_1457    FIA111         0   \n",
              "...             ...    ...      ...            ...       ...       ...   \n",
              "5997             SH  Kauai      NaN        SH94-01      SH95         0   \n",
              "5998             SH  Kauai      NaN        SH94-01      SH96         0   \n",
              "5999             SH  Kauai      NaN        SH97-01      SH97         0   \n",
              "6000             SH  Kauai      NaN        SH97-01      SH98         0   \n",
              "6001             SH  Kauai      NaN        SH97-01      SH99         0   \n",
              "\n",
              "     depth_bottom depth_adj_bottom    latitude    longitude  ...  swe  \\\n",
              "0              20               20   22.185643  -159.350787  ...  0.0   \n",
              "100            20               20   21.475448  -157.984458  ...  0.0   \n",
              "105            20               20   21.419936  -157.906723  ...  0.0   \n",
              "10             20               20   22.152306  -159.380618  ...  0.0   \n",
              "110            20               20   21.404189  -157.854121  ...  0.0   \n",
              "...           ...              ...         ...          ...  ...  ...   \n",
              "5997           15               20   21.967096  -159.692819  ...  0.0   \n",
              "5998           15               20   21.967096  -159.692819  ...  0.0   \n",
              "5999           15               20  21.9670959  -159.692819  ...  0.0   \n",
              "6000           15               20  21.9670959  -159.692819  ...  0.0   \n",
              "6001           15               20  21.9670959  -159.692819  ...  0.0   \n",
              "\n",
              "          tmmn      tmmx       vap       vpd        vs    agbd_m   agbd_sd  \\\n",
              "0     0.919650  0.946761  0.947442  0.833200  0.510523  0.016828  0.030577   \n",
              "100   0.900208  0.934330  0.924736  0.816007  0.514500  0.094650  0.164560   \n",
              "105   0.871936  0.909543  0.898124  0.762932  0.542160  0.044217  0.070038   \n",
              "10    0.818287  0.885699  0.885619  0.657210  0.487529  0.205160  0.517108   \n",
              "110   0.876864  0.910243  0.898774  0.769978  0.544770  0.000000  0.000000   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5997  0.902048  0.954855  0.950564  0.826877  0.519562  0.004020  0.007715   \n",
              "5998  0.902048  0.954855  0.950564  0.826877  0.519562  0.002663  0.008040   \n",
              "5999  0.902048  0.954855  0.950564  0.826877  0.519562  0.006749  0.009302   \n",
              "6000  0.902048  0.954855  0.950564  0.826877  0.519562  0.000306  0.000000   \n",
              "6001  0.902048  0.954855  0.950564  0.826877  0.519562  0.007591  0.023007   \n",
              "\n",
              "        agbd_n  imp_c_scaled  \n",
              "0     0.137931      0.064231  \n",
              "100   0.551724      0.064954  \n",
              "105   0.465517      0.143556  \n",
              "10    0.086207      0.099888  \n",
              "110   0.000000      0.039570  \n",
              "...        ...           ...  \n",
              "5997  0.086207      0.113633  \n",
              "5998  0.103448      0.076609  \n",
              "5999  0.137931      0.107264  \n",
              "6000  0.017241      0.025221  \n",
              "6001  0.120690      0.027442  \n",
              "\n",
              "[2715 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8965420-2878-4799-800b-fed0ad29c7bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_dataset</th>\n",
              "      <th>island</th>\n",
              "      <th>dist_id</th>\n",
              "      <th>soil_column_id</th>\n",
              "      <th>unique_id</th>\n",
              "      <th>depth_top</th>\n",
              "      <th>depth_bottom</th>\n",
              "      <th>depth_adj_bottom</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>...</th>\n",
              "      <th>swe</th>\n",
              "      <th>tmmn</th>\n",
              "      <th>tmmx</th>\n",
              "      <th>vap</th>\n",
              "      <th>vpd</th>\n",
              "      <th>vs</th>\n",
              "      <th>agbd_m</th>\n",
              "      <th>agbd_sd</th>\n",
              "      <th>agbd_n</th>\n",
              "      <th>imp_c_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FIA</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FIA_1060</td>\n",
              "      <td>FIA1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>22.185643</td>\n",
              "      <td>-159.350787</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.919650</td>\n",
              "      <td>0.946761</td>\n",
              "      <td>0.947442</td>\n",
              "      <td>0.833200</td>\n",
              "      <td>0.510523</td>\n",
              "      <td>0.016828</td>\n",
              "      <td>0.030577</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0.064231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>FIA</td>\n",
              "      <td>Oahu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FIA_1433</td>\n",
              "      <td>FIA101</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>21.475448</td>\n",
              "      <td>-157.984458</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.900208</td>\n",
              "      <td>0.934330</td>\n",
              "      <td>0.924736</td>\n",
              "      <td>0.816007</td>\n",
              "      <td>0.514500</td>\n",
              "      <td>0.094650</td>\n",
              "      <td>0.164560</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>0.064954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>FIA</td>\n",
              "      <td>Oahu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FIA_1454</td>\n",
              "      <td>FIA106</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>21.419936</td>\n",
              "      <td>-157.906723</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.871936</td>\n",
              "      <td>0.909543</td>\n",
              "      <td>0.898124</td>\n",
              "      <td>0.762932</td>\n",
              "      <td>0.542160</td>\n",
              "      <td>0.044217</td>\n",
              "      <td>0.070038</td>\n",
              "      <td>0.465517</td>\n",
              "      <td>0.143556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>FIA</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FIA_1077</td>\n",
              "      <td>FIA11</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>22.152306</td>\n",
              "      <td>-159.380618</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.818287</td>\n",
              "      <td>0.885699</td>\n",
              "      <td>0.885619</td>\n",
              "      <td>0.657210</td>\n",
              "      <td>0.487529</td>\n",
              "      <td>0.205160</td>\n",
              "      <td>0.517108</td>\n",
              "      <td>0.086207</td>\n",
              "      <td>0.099888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>FIA</td>\n",
              "      <td>Oahu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FIA_1457</td>\n",
              "      <td>FIA111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>21.404189</td>\n",
              "      <td>-157.854121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.876864</td>\n",
              "      <td>0.910243</td>\n",
              "      <td>0.898774</td>\n",
              "      <td>0.769978</td>\n",
              "      <td>0.544770</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.039570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>SH</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SH94-01</td>\n",
              "      <td>SH95</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21.967096</td>\n",
              "      <td>-159.692819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.902048</td>\n",
              "      <td>0.954855</td>\n",
              "      <td>0.950564</td>\n",
              "      <td>0.826877</td>\n",
              "      <td>0.519562</td>\n",
              "      <td>0.004020</td>\n",
              "      <td>0.007715</td>\n",
              "      <td>0.086207</td>\n",
              "      <td>0.113633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>SH</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SH94-01</td>\n",
              "      <td>SH96</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21.967096</td>\n",
              "      <td>-159.692819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.902048</td>\n",
              "      <td>0.954855</td>\n",
              "      <td>0.950564</td>\n",
              "      <td>0.826877</td>\n",
              "      <td>0.519562</td>\n",
              "      <td>0.002663</td>\n",
              "      <td>0.008040</td>\n",
              "      <td>0.103448</td>\n",
              "      <td>0.076609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>SH</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SH97-01</td>\n",
              "      <td>SH97</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21.9670959</td>\n",
              "      <td>-159.692819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.902048</td>\n",
              "      <td>0.954855</td>\n",
              "      <td>0.950564</td>\n",
              "      <td>0.826877</td>\n",
              "      <td>0.519562</td>\n",
              "      <td>0.006749</td>\n",
              "      <td>0.009302</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0.107264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6000</th>\n",
              "      <td>SH</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SH97-01</td>\n",
              "      <td>SH98</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21.9670959</td>\n",
              "      <td>-159.692819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.902048</td>\n",
              "      <td>0.954855</td>\n",
              "      <td>0.950564</td>\n",
              "      <td>0.826877</td>\n",
              "      <td>0.519562</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017241</td>\n",
              "      <td>0.025221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6001</th>\n",
              "      <td>SH</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SH97-01</td>\n",
              "      <td>SH99</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21.9670959</td>\n",
              "      <td>-159.692819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.902048</td>\n",
              "      <td>0.954855</td>\n",
              "      <td>0.950564</td>\n",
              "      <td>0.826877</td>\n",
              "      <td>0.519562</td>\n",
              "      <td>0.007591</td>\n",
              "      <td>0.023007</td>\n",
              "      <td>0.120690</td>\n",
              "      <td>0.027442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2715 rows Ã— 41 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8965420-2878-4799-800b-fed0ad29c7bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8965420-2878-4799-800b-fed0ad29c7bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8965420-2878-4799-800b-fed0ad29c7bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f4ace380-d3aa-4933-a81c-15f6f8aeba8d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4ace380-d3aa-4933-a81c-15f6f8aeba8d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f4ace380-d3aa-4933-a81c-15f6f8aeba8d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dab7f739-6cb2-4bbe-b352-fff712bc7690\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('reserve_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dab7f739-6cb2-4bbe-b352-fff712bc7690 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('reserve_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "reserve_data"
            }
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reserve_data = numeric_df[numeric_df['dist_id']!=xval_id].groupby('unique_id').sample(n=1)\n",
        "reserve_data"
      ],
      "metadata": {
        "id": "ieXPTgP0BEtm",
        "outputId": "681c5a17-16ad-4587-894d-c12a8a2ceceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     source_dataset island  dist_id soil_column_id unique_id depth_top  \\\n",
              "0               FIA  Kauai      NaN       FIA_1060      FIA1         0   \n",
              "100             FIA   Oahu      NaN       FIA_1433    FIA101         0   \n",
              "105             FIA   Oahu      NaN       FIA_1454    FIA106         0   \n",
              "10              FIA  Kauai      NaN       FIA_1077     FIA11         0   \n",
              "110             FIA   Oahu      NaN       FIA_1457    FIA111         0   \n",
              "...             ...    ...      ...            ...       ...       ...   \n",
              "5997             SH  Kauai      NaN        SH94-01      SH95         0   \n",
              "5998             SH  Kauai      NaN        SH94-01      SH96         0   \n",
              "5999             SH  Kauai      NaN        SH97-01      SH97         0   \n",
              "6000             SH  Kauai      NaN        SH97-01      SH98         0   \n",
              "6001             SH  Kauai      NaN        SH97-01      SH99         0   \n",
              "\n",
              "     depth_bottom depth_adj_bottom    latitude    longitude  ...  swe  \\\n",
              "0              20               20   22.185643  -159.350787  ...  0.0   \n",
              "100            20               20   21.475448  -157.984458  ...  0.0   \n",
              "105            20               20   21.419936  -157.906723  ...  0.0   \n",
              "10             20               20   22.152306  -159.380618  ...  0.0   \n",
              "110            20               20   21.404189  -157.854121  ...  0.0   \n",
              "...           ...              ...         ...          ...  ...  ...   \n",
              "5997           15               20   21.967096  -159.692819  ...  0.0   \n",
              "5998           15               20   21.967096  -159.692819  ...  0.0   \n",
              "5999           15               20  21.9670959  -159.692819  ...  0.0   \n",
              "6000           15               20  21.9670959  -159.692819  ...  0.0   \n",
              "6001           15               20  21.9670959  -159.692819  ...  0.0   \n",
              "\n",
              "          tmmn      tmmx       vap       vpd        vs    agbd_m   agbd_sd  \\\n",
              "0     0.919650  0.946761  0.947442  0.833200  0.510523  0.049059  0.124622   \n",
              "100   0.900208  0.934330  0.924736  0.816007  0.514500  0.078824  0.148215   \n",
              "105   0.887293  0.920565  0.910170  0.790353  0.539879  0.039453  0.044276   \n",
              "10    0.849930  0.904856  0.904350  0.711917  0.491875  0.126932  0.231857   \n",
              "110   0.876864  0.910243  0.898774  0.769978  0.544770  0.030351  0.065481   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5997  0.902048  0.954855  0.950564  0.826877  0.519562  0.002138  0.002781   \n",
              "5998  0.902048  0.954855  0.950564  0.826877  0.519562  0.000651  0.002159   \n",
              "5999  0.902048  0.954855  0.950564  0.826877  0.519562  0.003482  0.014753   \n",
              "6000  0.902048  0.954855  0.950564  0.826877  0.519562  0.000000  0.000000   \n",
              "6001  0.902048  0.954855  0.950564  0.826877  0.519562  0.024898  0.066095   \n",
              "\n",
              "        agbd_n  imp_c_scaled  \n",
              "0     0.068966      0.064231  \n",
              "100   0.241379      0.064954  \n",
              "105   0.379310      0.143556  \n",
              "10    0.051724      0.099888  \n",
              "110   0.137931      0.039570  \n",
              "...        ...           ...  \n",
              "5997  0.068966      0.113633  \n",
              "5998  0.137931      0.076609  \n",
              "5999  0.172414      0.107264  \n",
              "6000  0.000000      0.025221  \n",
              "6001  0.172414      0.027442  \n",
              "\n",
              "[2715 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11dcdf96-5860-4bc0-9e6e-fbf58b5a2863\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_dataset</th>\n",
              "      <th>island</th>\n",
              "      <th>dist_id</th>\n",
              "      <th>soil_column_id</th>\n",
              "      <th>unique_id</th>\n",
              "      <th>depth_top</th>\n",
              "      <th>depth_bottom</th>\n",
              "      <th>depth_adj_bottom</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>...</th>\n",
              "      <th>swe</th>\n",
              "      <th>tmmn</th>\n",
              "      <th>tmmx</th>\n",
              "      <th>vap</th>\n",
              "      <th>vpd</th>\n",
              "      <th>vs</th>\n",
              "      <th>agbd_m</th>\n",
              "      <th>agbd_sd</th>\n",
              "      <th>agbd_n</th>\n",
              "      <th>imp_c_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FIA</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FIA_1060</td>\n",
              "      <td>FIA1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>22.185643</td>\n",
              "      <td>-159.350787</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.919650</td>\n",
              "      <td>0.946761</td>\n",
              "      <td>0.947442</td>\n",
              "      <td>0.833200</td>\n",
              "      <td>0.510523</td>\n",
              "      <td>0.049059</td>\n",
              "      <td>0.124622</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.064231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>FIA</td>\n",
              "      <td>Oahu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FIA_1433</td>\n",
              "      <td>FIA101</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>21.475448</td>\n",
              "      <td>-157.984458</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.900208</td>\n",
              "      <td>0.934330</td>\n",
              "      <td>0.924736</td>\n",
              "      <td>0.816007</td>\n",
              "      <td>0.514500</td>\n",
              "      <td>0.078824</td>\n",
              "      <td>0.148215</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>0.064954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>FIA</td>\n",
              "      <td>Oahu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FIA_1454</td>\n",
              "      <td>FIA106</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>21.419936</td>\n",
              "      <td>-157.906723</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.887293</td>\n",
              "      <td>0.920565</td>\n",
              "      <td>0.910170</td>\n",
              "      <td>0.790353</td>\n",
              "      <td>0.539879</td>\n",
              "      <td>0.039453</td>\n",
              "      <td>0.044276</td>\n",
              "      <td>0.379310</td>\n",
              "      <td>0.143556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>FIA</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FIA_1077</td>\n",
              "      <td>FIA11</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>22.152306</td>\n",
              "      <td>-159.380618</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.849930</td>\n",
              "      <td>0.904856</td>\n",
              "      <td>0.904350</td>\n",
              "      <td>0.711917</td>\n",
              "      <td>0.491875</td>\n",
              "      <td>0.126932</td>\n",
              "      <td>0.231857</td>\n",
              "      <td>0.051724</td>\n",
              "      <td>0.099888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>FIA</td>\n",
              "      <td>Oahu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FIA_1457</td>\n",
              "      <td>FIA111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>21.404189</td>\n",
              "      <td>-157.854121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.876864</td>\n",
              "      <td>0.910243</td>\n",
              "      <td>0.898774</td>\n",
              "      <td>0.769978</td>\n",
              "      <td>0.544770</td>\n",
              "      <td>0.030351</td>\n",
              "      <td>0.065481</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0.039570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>SH</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SH94-01</td>\n",
              "      <td>SH95</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21.967096</td>\n",
              "      <td>-159.692819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.902048</td>\n",
              "      <td>0.954855</td>\n",
              "      <td>0.950564</td>\n",
              "      <td>0.826877</td>\n",
              "      <td>0.519562</td>\n",
              "      <td>0.002138</td>\n",
              "      <td>0.002781</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.113633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>SH</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SH94-01</td>\n",
              "      <td>SH96</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21.967096</td>\n",
              "      <td>-159.692819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.902048</td>\n",
              "      <td>0.954855</td>\n",
              "      <td>0.950564</td>\n",
              "      <td>0.826877</td>\n",
              "      <td>0.519562</td>\n",
              "      <td>0.000651</td>\n",
              "      <td>0.002159</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0.076609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>SH</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SH97-01</td>\n",
              "      <td>SH97</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21.9670959</td>\n",
              "      <td>-159.692819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.902048</td>\n",
              "      <td>0.954855</td>\n",
              "      <td>0.950564</td>\n",
              "      <td>0.826877</td>\n",
              "      <td>0.519562</td>\n",
              "      <td>0.003482</td>\n",
              "      <td>0.014753</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>0.107264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6000</th>\n",
              "      <td>SH</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SH97-01</td>\n",
              "      <td>SH98</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21.9670959</td>\n",
              "      <td>-159.692819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.902048</td>\n",
              "      <td>0.954855</td>\n",
              "      <td>0.950564</td>\n",
              "      <td>0.826877</td>\n",
              "      <td>0.519562</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6001</th>\n",
              "      <td>SH</td>\n",
              "      <td>Kauai</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SH97-01</td>\n",
              "      <td>SH99</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>21.9670959</td>\n",
              "      <td>-159.692819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.902048</td>\n",
              "      <td>0.954855</td>\n",
              "      <td>0.950564</td>\n",
              "      <td>0.826877</td>\n",
              "      <td>0.519562</td>\n",
              "      <td>0.024898</td>\n",
              "      <td>0.066095</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>0.027442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2715 rows Ã— 41 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11dcdf96-5860-4bc0-9e6e-fbf58b5a2863')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11dcdf96-5860-4bc0-9e6e-fbf58b5a2863 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11dcdf96-5860-4bc0-9e6e-fbf58b5a2863');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6172265c-9f55-488e-9eea-d30246de443a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6172265c-9f55-488e-9eea-d30246de443a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6172265c-9f55-488e-9eea-d30246de443a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_eca7da2d-64bb-4101-8215-58b025f62cc4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('reserve_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eca7da2d-64bb-4101-8215-58b025f62cc4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('reserve_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "reserve_data"
            }
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numeric_df[numeric_df['unique_id'] == 'FIA1']"
      ],
      "metadata": {
        "id": "7NrwqOLXKWgE"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the function with your DataFrame\n",
        "reserve_data = numeric_df[numeric_df['dist_id']!=xval_id].groupby('unique_id').sample(n=1)\n",
        "r2_list = []\n",
        "loss_list = []\n",
        "prediction_list = []\n",
        "matched_data_list = []\n",
        "model_list = []\n",
        "for i in range(10):\n",
        "  matched_data = numeric_df[numeric_df['dist_id']!=xval_id].groupby('unique_id').sample(n=1)\n",
        "  matched_data = matched_data.reset_index(drop=True)\n",
        "  model, test_loss, r_squared, predictions, y_test = train_model_a(matched_data)\n",
        "  predictions = predict_on_reserve(reserve_data, model, min_c, max_c)\n",
        "  matched_data_list.append(matched_data)\n",
        "  prediction_list.append(predictions)\n",
        "  model_list.append(model)"
      ],
      "metadata": {
        "id": "AB3AQBqMMtOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00879e1-48ce-4b56-a26e-5aa2c45454dd"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 19ms/step - loss: 2.1307 - val_loss: 0.0307\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.6448 - val_loss: 0.0204\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.1009 - val_loss: 0.0207\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.9411 - val_loss: 0.0217\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7457 - val_loss: 0.0182\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6461 - val_loss: 0.0187\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5693 - val_loss: 0.0214\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4610 - val_loss: 0.0196\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4031 - val_loss: 0.0213\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3374 - val_loss: 0.0178\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3213 - val_loss: 0.0176\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3106 - val_loss: 0.0162\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2894 - val_loss: 0.0207\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2812 - val_loss: 0.0177\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2194 - val_loss: 0.0186\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2024 - val_loss: 0.0151\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1758 - val_loss: 0.0140\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1568 - val_loss: 0.0153\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1605 - val_loss: 0.0142\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1118 - val_loss: 0.0154\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1139 - val_loss: 0.0128\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1195 - val_loss: 0.0146\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0941 - val_loss: 0.0136\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0938 - val_loss: 0.0160\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0843 - val_loss: 0.0151\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0794 - val_loss: 0.0139\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0748 - val_loss: 0.0138\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0713 - val_loss: 0.0147\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0577 - val_loss: 0.0143\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0572 - val_loss: 0.0126\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0515 - val_loss: 0.0115\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0495 - val_loss: 0.0114\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0385 - val_loss: 0.0099\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0474 - val_loss: 0.0103\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0376 - val_loss: 0.0105\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0389 - val_loss: 0.0105\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0374 - val_loss: 0.0091\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0335 - val_loss: 0.0097\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0299 - val_loss: 0.0105\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0251 - val_loss: 0.0112\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0261 - val_loss: 0.0087\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0228 - val_loss: 0.0085\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0242 - val_loss: 0.0086\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.0088\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0103\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0111\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0202 - val_loss: 0.0079\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0081\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0082\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0082\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0076\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0073\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0075\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0081\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0074\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0090\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0075\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0081\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0075\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0071\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0077\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0070\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0071\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0074\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0072\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0069\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0069\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0068\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0072\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0070\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0066\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0068\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0070\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0069\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0071\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0064\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0068\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0069\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0068\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0068\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0074\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0068\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0070\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0065\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0067\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0066\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0064\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0069\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0063\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0071\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0066\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0071\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0067\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0066\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0063\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0069\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0063\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0052\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "85/85 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 19ms/step - loss: 2.6193 - val_loss: 0.0269\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.5009 - val_loss: 0.0291\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.3497 - val_loss: 0.0287\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.1166 - val_loss: 0.0333\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.8353 - val_loss: 0.0289\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.8169 - val_loss: 0.0258\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7077 - val_loss: 0.0313\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.5447 - val_loss: 0.0212\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5337 - val_loss: 0.0239\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4329 - val_loss: 0.0247\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3516 - val_loss: 0.0229\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3132 - val_loss: 0.0219\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2780 - val_loss: 0.0213\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2789 - val_loss: 0.0155\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2581 - val_loss: 0.0195\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2189 - val_loss: 0.0207\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2115 - val_loss: 0.0199\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2112 - val_loss: 0.0190\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1869 - val_loss: 0.0194\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1528 - val_loss: 0.0208\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1368 - val_loss: 0.0187\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1336 - val_loss: 0.0194\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1279 - val_loss: 0.0196\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1227 - val_loss: 0.0173\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1161 - val_loss: 0.0156\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0921 - val_loss: 0.0167\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0897 - val_loss: 0.0166\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0795 - val_loss: 0.0155\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0694 - val_loss: 0.0169\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0713 - val_loss: 0.0159\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0637 - val_loss: 0.0142\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0549 - val_loss: 0.0143\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0530 - val_loss: 0.0148\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0519 - val_loss: 0.0137\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0448 - val_loss: 0.0139\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0468 - val_loss: 0.0132\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0386 - val_loss: 0.0126\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0419 - val_loss: 0.0120\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0112\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0298 - val_loss: 0.0104\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0320 - val_loss: 0.0105\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0260 - val_loss: 0.0093\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0265 - val_loss: 0.0091\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0091\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0245 - val_loss: 0.0096\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0224 - val_loss: 0.0089\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0093\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0086\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0091\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0083\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0118\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0094\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0082\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0083\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0077\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0072\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0082\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0086\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0081\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0073\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0072\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0077\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0076\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0075\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0078\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0066\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0074\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0076\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0075\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0067\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0071\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0070\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0067\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0067\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0070\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0068\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0073\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0070\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0068\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0070\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0066\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0066\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0066\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0066\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0067\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0068\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0064\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0062\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0069\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0062\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0062\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0066\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0062\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0061\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0061\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0066\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "85/85 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 4s 20ms/step - loss: 1.6979 - val_loss: 0.0255\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.3480 - val_loss: 0.0243\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.0275 - val_loss: 0.0267\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.9562 - val_loss: 0.0310\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7619 - val_loss: 0.0262\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5906 - val_loss: 0.0240\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4599 - val_loss: 0.0242\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4122 - val_loss: 0.0259\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3610 - val_loss: 0.0231\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3433 - val_loss: 0.0211\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2753 - val_loss: 0.0182\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2424 - val_loss: 0.0189\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2536 - val_loss: 0.0216\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2077 - val_loss: 0.0175\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2007 - val_loss: 0.0170\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1792 - val_loss: 0.0172\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1376 - val_loss: 0.0162\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1318 - val_loss: 0.0158\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1410 - val_loss: 0.0156\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1165 - val_loss: 0.0162\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1076 - val_loss: 0.0152\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1128 - val_loss: 0.0159\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0924 - val_loss: 0.0146\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0848 - val_loss: 0.0130\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0829 - val_loss: 0.0131\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0681 - val_loss: 0.0119\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0686 - val_loss: 0.0117\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0634 - val_loss: 0.0112\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0539 - val_loss: 0.0126\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0522 - val_loss: 0.0109\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0473 - val_loss: 0.0115\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0515 - val_loss: 0.0111\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0370 - val_loss: 0.0110\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0442 - val_loss: 0.0112\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0385 - val_loss: 0.0107\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0308 - val_loss: 0.0103\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0287 - val_loss: 0.0099\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0099\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0099\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0281 - val_loss: 0.0107\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0101\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0090\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0220 - val_loss: 0.0090\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0083\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0089\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0090\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0091\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0091\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0079\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0087\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0079\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0084\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0079\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0076\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0072\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0075\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0086\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0078\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0087\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0069\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0072\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0087\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0079\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0073\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0070\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0070\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0076\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0079\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0069\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0069\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0078\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0067\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0071\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0071\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0068\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0071\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0068\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0068\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0064\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0068\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0065\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0063\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0066\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0066\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0067\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0068\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0067\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0064\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0065\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0067\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0067\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0062\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0066\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0066\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0066\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0067\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0065\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0073\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0065\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "85/85 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 19ms/step - loss: 2.3050 - val_loss: 0.0279\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.5008 - val_loss: 0.0260\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.0493 - val_loss: 0.0261\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.8515 - val_loss: 0.0267\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7088 - val_loss: 0.0234\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5712 - val_loss: 0.0232\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4583 - val_loss: 0.0233\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4217 - val_loss: 0.0195\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4131 - val_loss: 0.0223\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3100 - val_loss: 0.0210\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3120 - val_loss: 0.0218\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2900 - val_loss: 0.0218\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2765 - val_loss: 0.0219\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2398 - val_loss: 0.0209\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1765 - val_loss: 0.0181\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1763 - val_loss: 0.0160\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1715 - val_loss: 0.0182\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1378 - val_loss: 0.0178\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1359 - val_loss: 0.0185\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1267 - val_loss: 0.0178\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0990 - val_loss: 0.0181\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0979 - val_loss: 0.0213\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1081 - val_loss: 0.0181\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0846 - val_loss: 0.0168\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0783 - val_loss: 0.0174\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0672 - val_loss: 0.0168\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0647 - val_loss: 0.0158\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0558 - val_loss: 0.0150\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0510 - val_loss: 0.0131\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0441 - val_loss: 0.0130\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0437 - val_loss: 0.0130\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0385 - val_loss: 0.0120\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0358 - val_loss: 0.0118\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0326 - val_loss: 0.0130\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0295 - val_loss: 0.0109\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0336 - val_loss: 0.0108\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0105\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0242 - val_loss: 0.0102\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0241 - val_loss: 0.0098\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0095\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.0106\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0108\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0216 - val_loss: 0.0095\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0084\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0086\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0090\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0083\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0081\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0087\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0082\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0087\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0078\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0077\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0074\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0074\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0074\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0074\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0075\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0068\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0070\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0066\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0069\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0079\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0075\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0066\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0068\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0067\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0066\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0063\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0066\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0073\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0065\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0066\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0067\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0066\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0064\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0065\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0064\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0065\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0061\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0063\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0063\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0063\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0073\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0066\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0067\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0064\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0062\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0062\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0062\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0064\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0079\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0065\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0063\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0063\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "85/85 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 19ms/step - loss: 1.8113 - val_loss: 0.0216\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.3739 - val_loss: 0.0178\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.1257 - val_loss: 0.0201\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.9364 - val_loss: 0.0172\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.8997 - val_loss: 0.0189\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5983 - val_loss: 0.0169\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4877 - val_loss: 0.0174\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4469 - val_loss: 0.0173\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3315 - val_loss: 0.0202\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3231 - val_loss: 0.0181\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2793 - val_loss: 0.0163\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2827 - val_loss: 0.0192\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2180 - val_loss: 0.0200\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1935 - val_loss: 0.0207\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1785 - val_loss: 0.0182\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1678 - val_loss: 0.0182\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1618 - val_loss: 0.0179\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1422 - val_loss: 0.0175\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1156 - val_loss: 0.0154\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1111 - val_loss: 0.0170\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1062 - val_loss: 0.0161\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0897 - val_loss: 0.0157\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0842 - val_loss: 0.0156\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0667 - val_loss: 0.0155\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0667 - val_loss: 0.0135\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0649 - val_loss: 0.0127\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.0122\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0602 - val_loss: 0.0123\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0530 - val_loss: 0.0144\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0392 - val_loss: 0.0128\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0408 - val_loss: 0.0120\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0411 - val_loss: 0.0131\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0368 - val_loss: 0.0120\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0113\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0306 - val_loss: 0.0112\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0278 - val_loss: 0.0109\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0271 - val_loss: 0.0107\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0253 - val_loss: 0.0110\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0246 - val_loss: 0.0100\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0097\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0096\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0089\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0083\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0087\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0083\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0083\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0080\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0084\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0086\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0086\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0083\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0072\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0077\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0070\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0075\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0078\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0072\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0078\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0076\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0072\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0073\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0068\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0068\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0075\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0069\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0076\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0070\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0071\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0070\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0066\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0069\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0070\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0070\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0065\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0070\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0066\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0067\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0063\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0069\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0074\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0066\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0065\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0064\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0062\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0066\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0067\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0061\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0067\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0068\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0063\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0063\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0065\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0068\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0064\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0066\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0060\n",
            "17/17 [==============================] - 0s 1ms/step\n",
            "85/85 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 19ms/step - loss: 1.7364 - val_loss: 0.0244\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.5480 - val_loss: 0.0221\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.2656 - val_loss: 0.0199\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.8359 - val_loss: 0.0207\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6774 - val_loss: 0.0205\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5314 - val_loss: 0.0191\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4789 - val_loss: 0.0173\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4186 - val_loss: 0.0190\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3621 - val_loss: 0.0184\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3404 - val_loss: 0.0184\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3338 - val_loss: 0.0185\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2719 - val_loss: 0.0196\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2240 - val_loss: 0.0179\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2186 - val_loss: 0.0205\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1731 - val_loss: 0.0166\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1587 - val_loss: 0.0156\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1601 - val_loss: 0.0175\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1626 - val_loss: 0.0194\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1428 - val_loss: 0.0162\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1251 - val_loss: 0.0148\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0171\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0925 - val_loss: 0.0161\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1008 - val_loss: 0.0159\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0874 - val_loss: 0.0163\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0904 - val_loss: 0.0167\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0819 - val_loss: 0.0163\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0769 - val_loss: 0.0155\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0655 - val_loss: 0.0140\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0620 - val_loss: 0.0146\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0654 - val_loss: 0.0144\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0555 - val_loss: 0.0142\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0515 - val_loss: 0.0143\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0408 - val_loss: 0.0125\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0426 - val_loss: 0.0121\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0387 - val_loss: 0.0130\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0337 - val_loss: 0.0127\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0326 - val_loss: 0.0116\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0295 - val_loss: 0.0109\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0322 - val_loss: 0.0100\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0274 - val_loss: 0.0104\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0255 - val_loss: 0.0105\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0284 - val_loss: 0.0120\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0245 - val_loss: 0.0103\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0092\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0082\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0101\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0092\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0092\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0077\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0080\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0089\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0100\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0091\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0092\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0088\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0076\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0075\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0076\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0085\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0080\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0074\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0071\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0078\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0072\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0069\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0067\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0076\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0074\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0072\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0069\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0070\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0069\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0068\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0071\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0070\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0067\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0066\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0071\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0068\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0065\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0073\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0066\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0068\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0065\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0067\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0066\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0066\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0066\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0070\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0065\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0065\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0064\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0074\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0067\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "85/85 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 20ms/step - loss: 1.9266 - val_loss: 0.0173\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.4499 - val_loss: 0.0155\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.2784 - val_loss: 0.0167\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.8836 - val_loss: 0.0166\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7780 - val_loss: 0.0173\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6258 - val_loss: 0.0173\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5289 - val_loss: 0.0185\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5199 - val_loss: 0.0187\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4477 - val_loss: 0.0194\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4136 - val_loss: 0.0220\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.3266 - val_loss: 0.0177\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2926 - val_loss: 0.0234\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2684 - val_loss: 0.0168\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2502 - val_loss: 0.0179\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2373 - val_loss: 0.0277\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2058 - val_loss: 0.0214\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1911 - val_loss: 0.0200\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1724 - val_loss: 0.0205\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1426 - val_loss: 0.0188\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1452 - val_loss: 0.0169\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1326 - val_loss: 0.0194\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1321 - val_loss: 0.0173\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1244 - val_loss: 0.0167\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0838 - val_loss: 0.0153\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0910 - val_loss: 0.0155\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0910 - val_loss: 0.0130\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0743 - val_loss: 0.0145\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0740 - val_loss: 0.0150\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0715 - val_loss: 0.0164\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0662 - val_loss: 0.0148\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0535 - val_loss: 0.0130\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0465 - val_loss: 0.0130\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0435 - val_loss: 0.0123\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0419 - val_loss: 0.0111\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0428 - val_loss: 0.0103\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0418 - val_loss: 0.0107\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0107\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0388 - val_loss: 0.0103\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0316 - val_loss: 0.0098\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0263 - val_loss: 0.0092\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0290 - val_loss: 0.0086\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0237 - val_loss: 0.0085\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0228 - val_loss: 0.0092\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0088\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0080\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0079\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0086\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0078\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0074\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0102\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0082\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0071\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0070\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0071\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0078\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0102\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0083\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0076\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0070\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0072\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0072\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0078\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0069\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0074\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0077\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0078\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0069\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0068\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0070\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0070\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0068\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0062\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0062\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0071\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0067\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0065\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0066\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0068\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0067\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0068\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0065\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0062\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0065\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0064\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0071\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0062\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0062\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0066\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0069\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0063\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0063\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0062\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0066\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0068\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0080\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0062\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0061\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0066\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "85/85 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 19ms/step - loss: 2.0060 - val_loss: 0.0175\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.6970 - val_loss: 0.0164\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.2016 - val_loss: 0.0163\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.9096 - val_loss: 0.0157\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7027 - val_loss: 0.0161\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5172 - val_loss: 0.0157\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5096 - val_loss: 0.0158\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4619 - val_loss: 0.0177\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3811 - val_loss: 0.0192\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3518 - val_loss: 0.0176\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3332 - val_loss: 0.0154\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3074 - val_loss: 0.0169\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2440 - val_loss: 0.0173\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1998 - val_loss: 0.0174\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1873 - val_loss: 0.0163\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2022 - val_loss: 0.0161\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1646 - val_loss: 0.0155\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1479 - val_loss: 0.0142\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1375 - val_loss: 0.0176\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1226 - val_loss: 0.0190\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1053 - val_loss: 0.0167\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0956 - val_loss: 0.0168\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0864 - val_loss: 0.0164\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0757 - val_loss: 0.0179\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0845 - val_loss: 0.0182\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0677 - val_loss: 0.0183\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0674 - val_loss: 0.0176\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0482 - val_loss: 0.0160\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0484 - val_loss: 0.0160\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0525 - val_loss: 0.0156\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0418 - val_loss: 0.0143\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0402 - val_loss: 0.0132\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0403 - val_loss: 0.0143\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0356 - val_loss: 0.0154\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0336 - val_loss: 0.0135\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0290 - val_loss: 0.0119\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0336 - val_loss: 0.0136\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0300 - val_loss: 0.0143\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0269 - val_loss: 0.0132\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0260 - val_loss: 0.0104\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.0107\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0097\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0095\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0096\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0090\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0108\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0088\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0080\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0081\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0097\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0081\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0075\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0075\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0073\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0073\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0075\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0082\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0078\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0074\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0083\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0069\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0074\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0072\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0066\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0070\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0070\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0070\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0072\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0067\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0069\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0070\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0069\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0088\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0070\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0066\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0074\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0076\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0062\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0069\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0074\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0072\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0070\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0067\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0067\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0064\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0063\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0070\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0071\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0072\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0067\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0065\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0065\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "85/85 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 19ms/step - loss: 2.0603 - val_loss: 0.0149\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.3872 - val_loss: 0.0201\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.1587 - val_loss: 0.0232\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.9704 - val_loss: 0.0231\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.8586 - val_loss: 0.0206\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7169 - val_loss: 0.0254\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5591 - val_loss: 0.0219\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4781 - val_loss: 0.0232\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.3702 - val_loss: 0.0200\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3537 - val_loss: 0.0202\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3231 - val_loss: 0.0210\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2909 - val_loss: 0.0296\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2683 - val_loss: 0.0213\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2469 - val_loss: 0.0186\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2068 - val_loss: 0.0192\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1921 - val_loss: 0.0178\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1812 - val_loss: 0.0179\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1565 - val_loss: 0.0195\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1433 - val_loss: 0.0170\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1373 - val_loss: 0.0171\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1388 - val_loss: 0.0173\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1118 - val_loss: 0.0159\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1016 - val_loss: 0.0146\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0949 - val_loss: 0.0148\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0899 - val_loss: 0.0161\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0797 - val_loss: 0.0167\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0699 - val_loss: 0.0161\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0654 - val_loss: 0.0152\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0632 - val_loss: 0.0142\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0599 - val_loss: 0.0171\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0547 - val_loss: 0.0172\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0483 - val_loss: 0.0162\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0479 - val_loss: 0.0148\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0367 - val_loss: 0.0120\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0365 - val_loss: 0.0118\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0120\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0384 - val_loss: 0.0110\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0339 - val_loss: 0.0107\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0327 - val_loss: 0.0113\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0314 - val_loss: 0.0144\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0337 - val_loss: 0.0120\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.0090\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0256 - val_loss: 0.0088\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0087\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0207 - val_loss: 0.0087\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0088\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0089\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0083\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0084\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0078\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0077\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0077\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0075\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0074\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0073\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0074\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0076\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0085\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0072\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0080\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0072\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0071\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0068\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0075\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0070\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0075\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0074\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0074\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0067\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0075\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0070\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0068\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0071\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0068\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0071\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0076\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0069\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0065\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0067\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0070\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0066\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0067\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0066\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0068\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0072\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0068\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0068\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0062\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0069\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0071\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0068\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0065\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0064\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0061\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0066\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "85/85 [==============================] - 0s 1ms/step\n",
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 20ms/step - loss: 2.0094 - val_loss: 0.0161\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.6245 - val_loss: 0.0172\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.2200 - val_loss: 0.0160\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.9423 - val_loss: 0.0169\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7599 - val_loss: 0.0156\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7003 - val_loss: 0.0151\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6182 - val_loss: 0.0152\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4797 - val_loss: 0.0161\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5000 - val_loss: 0.0162\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3647 - val_loss: 0.0146\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3446 - val_loss: 0.0162\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3653 - val_loss: 0.0161\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3050 - val_loss: 0.0158\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2456 - val_loss: 0.0172\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2438 - val_loss: 0.0170\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1946 - val_loss: 0.0157\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1746 - val_loss: 0.0175\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1608 - val_loss: 0.0192\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1467 - val_loss: 0.0169\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1394 - val_loss: 0.0187\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1309 - val_loss: 0.0147\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1463 - val_loss: 0.0145\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1161 - val_loss: 0.0122\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1015 - val_loss: 0.0141\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1061 - val_loss: 0.0156\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0941 - val_loss: 0.0164\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0816 - val_loss: 0.0179\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0800 - val_loss: 0.0164\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0742 - val_loss: 0.0141\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0636 - val_loss: 0.0153\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0592 - val_loss: 0.0121\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0543 - val_loss: 0.0123\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0490 - val_loss: 0.0114\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0481 - val_loss: 0.0110\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0443 - val_loss: 0.0113\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0438 - val_loss: 0.0101\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0441 - val_loss: 0.0102\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0413 - val_loss: 0.0118\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0393 - val_loss: 0.0092\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0351 - val_loss: 0.0090\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0374 - val_loss: 0.0091\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0327 - val_loss: 0.0091\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0084\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.0084\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0105\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0237 - val_loss: 0.0095\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0226 - val_loss: 0.0084\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0208 - val_loss: 0.0089\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0204 - val_loss: 0.0090\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0075\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0091\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0101\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0098\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0085\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0084\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0090\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0081\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0093\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0077\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0092\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0088\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0076\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0073\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0073\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0075\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0074\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0087\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0078\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0086\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0083\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0067\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0068\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0073\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0070\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0069\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0070\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0066\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0074\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0069\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0067\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0068\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0067\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0067\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0067\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0077\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0075\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0067\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0074\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0063\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0062\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0061\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0068\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0064\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0067\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0062\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0067\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0070\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0062\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0061\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.0047\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "85/85 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keep_cols = ['water', 'trees','grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built',\n",
        "            'bare', 'snow_and_ice', 'max', 'elevation', 'landform', 'SRTM_mTPI','aet', 'def',\n",
        "            'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn','tmmx', 'vap', 'vpd', 'vs',\n",
        "            'agbd_m', 'agbd_sd', 'agbd_n']\n",
        "\n",
        "# X = preprocess_data[keep_cols]\n",
        "\n",
        "# [model.predict(reserve_data[keep_cols]) for model in model_list]"
      ],
      "metadata": {
        "id": "igtHtywFIVXC"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[np.all(prediction['predictions'] ==prediction_list[0]['predictions']) for prediction in prediction_list]"
      ],
      "metadata": {
        "id": "cErVcXnK3O_I",
        "outputId": "e269be96-954b-47f9-f326-822785dd3a99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True, False, False, False, False, False, False, False, False, False]"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction_list[0]"
      ],
      "metadata": {
        "id": "Ub8BlUzd3rlJ"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_array = np.array([predictions['predictions'].values for predictions in prediction_list])"
      ],
      "metadata": {
        "id": "oDUVPC4OcwtB"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_array[combined_array < 0 ] = 0"
      ],
      "metadata": {
        "id": "0YMv9SoCj0-m"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combined_array[0]"
      ],
      "metadata": {
        "id": "LTpk26dD3ZzE"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_min = np.min(combined_array.flatten())\n",
        "arr_max = np.max(combined_array.flatten())"
      ],
      "metadata": {
        "id": "T-LnWRrDhoU2"
      },
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_max"
      ],
      "metadata": {
        "id": "8WEDqIpHanxH",
        "outputId": "a3808cdc-fcd5-4c4e-8d74-87604eef9f93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4143471"
            ]
          },
          "metadata": {},
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist_array = [np.sort(np.array([i[j] for  i in combined_array])) for j in range(combined_array.shape[1])]\n",
        "norm_dist_array =  [np.sort((np.array([i[j] for  i in combined_array]) - arr_min) / (arr_max-arr_min)) for j in range(combined_array.shape[1])]"
      ],
      "metadata": {
        "id": "WFc9BR7vhyiD"
      },
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_dist_array"
      ],
      "metadata": {
        "id": "K6NLTyaH1GF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a9b0d5-a838-4abf-8d54-2b483e8c867a"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.15070552, 0.16126002, 0.16477309, 0.1723021 , 0.18046306,\n",
              "        0.19868198, 0.2045922 , 0.20518483, 0.20821075, 0.24726897],\n",
              "       dtype=float32),\n",
              " array([0.01398647, 0.05992526, 0.09265756, 0.10223117, 0.10429706,\n",
              "        0.11649988, 0.12070768, 0.1271945 , 0.1568653 , 0.17923605],\n",
              "       dtype=float32),\n",
              " array([0.1505433 , 0.15699747, 0.17459525, 0.18883468, 0.20210585,\n",
              "        0.22589785, 0.24036191, 0.2916991 , 0.32737744, 0.36591774],\n",
              "       dtype=float32),\n",
              " array([0.17300975, 0.17649162, 0.1974824 , 0.23049429, 0.23481312,\n",
              "        0.25913474, 0.262052  , 0.29644412, 0.37688234, 0.38538116],\n",
              "       dtype=float32),\n",
              " array([0.14428955, 0.21177003, 0.22880228, 0.24262021, 0.32928166,\n",
              "        0.33472556, 0.3524563 , 0.39456907, 0.4205497 , 0.4413554 ],\n",
              "       dtype=float32),\n",
              " array([0.15590909, 0.18209638, 0.1881512 , 0.19573505, 0.19947293,\n",
              "        0.20556863, 0.23144361, 0.23421714, 0.25827828, 0.2946519 ],\n",
              "       dtype=float32),\n",
              " array([0.18622254, 0.18719082, 0.20346166, 0.22922736, 0.23632523,\n",
              "        0.23643623, 0.31020012, 0.34454063, 0.37790576, 0.384117  ],\n",
              "       dtype=float32),\n",
              " array([0.07284933, 0.08318577, 0.09585333, 0.10348296, 0.11794438,\n",
              "        0.15033396, 0.15581167, 0.16184862, 0.1632578 , 0.20878994],\n",
              "       dtype=float32),\n",
              " array([0.15351968, 0.16142783, 0.23409101, 0.23477532, 0.24844135,\n",
              "        0.26579937, 0.2703045 , 0.29957104, 0.30307397, 0.32157955],\n",
              "       dtype=float32),\n",
              " array([0.14556709, 0.17141394, 0.17433651, 0.21989486, 0.22785431,\n",
              "        0.22858019, 0.25772142, 0.3136088 , 0.32759076, 0.36311856],\n",
              "       dtype=float32),\n",
              " array([0.05219007, 0.05408672, 0.05679236, 0.06445302, 0.06889027,\n",
              "        0.069865  , 0.08557466, 0.08602722, 0.10254744, 0.13974406],\n",
              "       dtype=float32),\n",
              " array([0.19068491, 0.20583473, 0.22068338, 0.22701164, 0.23293142,\n",
              "        0.23654453, 0.24303617, 0.26157972, 0.29215991, 0.33679572],\n",
              "       dtype=float32),\n",
              " array([0.12678649, 0.15254831, 0.1797208 , 0.20127943, 0.2199668 ,\n",
              "        0.22175746, 0.23330317, 0.23742706, 0.27136382, 0.30974895],\n",
              "       dtype=float32),\n",
              " array([0.2561153 , 0.33775917, 0.37033263, 0.40149897, 0.40910214,\n",
              "        0.4238302 , 0.43234774, 0.4494454 , 0.45005056, 0.54070795],\n",
              "       dtype=float32),\n",
              " array([0.16189282, 0.16498993, 0.20187327, 0.20693742, 0.22084624,\n",
              "        0.22606671, 0.25349677, 0.26622838, 0.26764882, 0.28810248],\n",
              "       dtype=float32),\n",
              " array([0.20116757, 0.21716428, 0.2282267 , 0.30153486, 0.30153686,\n",
              "        0.3211798 , 0.3407764 , 0.3561298 , 0.36191848, 0.4328474 ],\n",
              "       dtype=float32),\n",
              " array([0.01250622, 0.03269835, 0.05025928, 0.05285631, 0.05469305,\n",
              "        0.05948716, 0.06484686, 0.08026407, 0.08962517, 0.09936754],\n",
              "       dtype=float32),\n",
              " array([0.21591122, 0.22189306, 0.23001914, 0.24506593, 0.25807843,\n",
              "        0.27263588, 0.2941217 , 0.3057886 , 0.31418815, 0.34360686],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.00685697, 0.00999367, 0.0286832 , 0.04384927,\n",
              "        0.04614588, 0.06337769, 0.06882018, 0.11036976, 0.14972019],\n",
              "       dtype=float32),\n",
              " array([0.20277315, 0.23440781, 0.23640862, 0.26637557, 0.28009677,\n",
              "        0.29937223, 0.30499956, 0.31626493, 0.3304335 , 0.41232303],\n",
              "       dtype=float32),\n",
              " array([0.03420988, 0.04487767, 0.08355359, 0.09894606, 0.09925476,\n",
              "        0.09968675, 0.10184884, 0.10895191, 0.11026396, 0.12682928],\n",
              "       dtype=float32),\n",
              " array([0.42405745, 0.4242243 , 0.46465555, 0.4754398 , 0.4860551 ,\n",
              "        0.5036067 , 0.54812056, 0.59645575, 0.60185605, 0.6438155 ],\n",
              "       dtype=float32),\n",
              " array([0.41244286, 0.41516382, 0.42806628, 0.47720626, 0.5322296 ,\n",
              "        0.5504823 , 0.56884784, 0.5734117 , 0.5773504 , 0.619866  ],\n",
              "       dtype=float32),\n",
              " array([0.11793428, 0.12343474, 0.2408684 , 0.3018184 , 0.3515124 ,\n",
              "        0.4111509 , 0.437129  , 0.45161107, 0.46387562, 0.55117846],\n",
              "       dtype=float32),\n",
              " array([0.39584693, 0.45068216, 0.45490384, 0.5103378 , 0.5318591 ,\n",
              "        0.53498435, 0.56774104, 0.6000658 , 0.89245486, 0.9147273 ],\n",
              "       dtype=float32),\n",
              " array([0.3407273 , 0.39305818, 0.44246724, 0.47061068, 0.50216836,\n",
              "        0.5374241 , 0.5420817 , 0.55410606, 0.588462  , 0.65591925],\n",
              "       dtype=float32),\n",
              " array([0.04834903, 0.12632398, 0.13650382, 0.1483447 , 0.17482224,\n",
              "        0.1870951 , 0.19025016, 0.19860245, 0.26079524, 0.29800877],\n",
              "       dtype=float32),\n",
              " array([0.06821782, 0.07823315, 0.09210935, 0.09477811, 0.09531045,\n",
              "        0.11264927, 0.13674693, 0.14060695, 0.1407058 , 0.16405538],\n",
              "       dtype=float32),\n",
              " array([0.27085322, 0.28429025, 0.31066695, 0.3684225 , 0.37981856,\n",
              "        0.38583562, 0.41445872, 0.44238967, 0.44379   , 0.4719356 ],\n",
              "       dtype=float32),\n",
              " array([0.60424954, 0.6343993 , 0.74195516, 0.77004635, 0.8202687 ,\n",
              "        0.8288595 , 0.8530678 , 0.8585611 , 0.9072312 , 0.93496597],\n",
              "       dtype=float32),\n",
              " array([0.17675714, 0.25835165, 0.28065822, 0.28276533, 0.2935021 ,\n",
              "        0.32655352, 0.33010605, 0.34247398, 0.37332788, 0.42513117],\n",
              "       dtype=float32),\n",
              " array([0.13527997, 0.17034204, 0.17103738, 0.1747001 , 0.18179813,\n",
              "        0.19497116, 0.22696044, 0.24072616, 0.248343  , 0.2575561 ],\n",
              "       dtype=float32),\n",
              " array([0.38465747, 0.4182799 , 0.4569989 , 0.45802984, 0.47073698,\n",
              "        0.47906074, 0.5185858 , 0.531033  , 0.6062176 , 0.69299936],\n",
              "       dtype=float32),\n",
              " array([0.41957363, 0.46988222, 0.49020624, 0.5195207 , 0.5260811 ,\n",
              "        0.5862195 , 0.6133437 , 0.6331354 , 0.6376194 , 0.65155494],\n",
              "       dtype=float32),\n",
              " array([0.1260377 , 0.14387956, 0.14847359, 0.15604055, 0.15641837,\n",
              "        0.15832677, 0.1951121 , 0.20167619, 0.24032377, 0.27860913],\n",
              "       dtype=float32),\n",
              " array([0.45375896, 0.48347494, 0.48665673, 0.4986966 , 0.51946545,\n",
              "        0.5234275 , 0.54919523, 0.5830604 , 0.59148633, 0.6228925 ],\n",
              "       dtype=float32),\n",
              " array([0.26098648, 0.28547594, 0.30474618, 0.31542966, 0.36205605,\n",
              "        0.36294928, 0.3639891 , 0.36667174, 0.44792113, 0.5100775 ],\n",
              "       dtype=float32),\n",
              " array([0.69886994, 0.7124034 , 0.73847467, 0.81249213, 0.81249905,\n",
              "        0.87472534, 0.9271228 , 0.93652403, 0.94672185, 0.99037564],\n",
              "       dtype=float32),\n",
              " array([0.6555416 , 0.7126114 , 0.74026096, 0.7413949 , 0.7576825 ,\n",
              "        0.7815656 , 0.80499125, 0.81712496, 0.8579645 , 0.9530852 ],\n",
              "       dtype=float32),\n",
              " array([0.3841719 , 0.42127854, 0.4416597 , 0.44828382, 0.4915263 ,\n",
              "        0.5147218 , 0.54046094, 0.58321196, 0.59452814, 0.6001445 ],\n",
              "       dtype=float32),\n",
              " array([0.46062   , 0.49044275, 0.49558276, 0.54960805, 0.5660288 ,\n",
              "        0.56672716, 0.5896512 , 0.6044173 , 0.6119683 , 0.64949584],\n",
              "       dtype=float32),\n",
              " array([0.56717074, 0.58581483, 0.6092328 , 0.6126385 , 0.6194818 ,\n",
              "        0.62999773, 0.64697134, 0.65050936, 0.661787  , 0.7444222 ],\n",
              "       dtype=float32),\n",
              " array([0.35911888, 0.3793938 , 0.38883418, 0.41540095, 0.4356154 ,\n",
              "        0.45376426, 0.51491505, 0.51623046, 0.54732674, 0.55723405],\n",
              "       dtype=float32),\n",
              " array([0.3657198 , 0.37968507, 0.4178861 , 0.4302307 , 0.47936854,\n",
              "        0.48734063, 0.50344473, 0.5044399 , 0.5092307 , 0.55415255],\n",
              "       dtype=float32),\n",
              " array([0.35596412, 0.39850253, 0.40547237, 0.41005945, 0.41527078,\n",
              "        0.46626332, 0.46641406, 0.49127135, 0.58791447, 0.5905299 ],\n",
              "       dtype=float32),\n",
              " array([0.24947156, 0.26483616, 0.32901686, 0.3598487 , 0.3720526 ,\n",
              "        0.37480593, 0.3754378 , 0.42654085, 0.4473557 , 0.44830316],\n",
              "       dtype=float32),\n",
              " array([0.28936908, 0.42528358, 0.45628843, 0.4612539 , 0.4663436 ,\n",
              "        0.48238102, 0.48581734, 0.50380194, 0.5264726 , 0.5285618 ],\n",
              "       dtype=float32),\n",
              " array([0.2491591 , 0.27967128, 0.29199544, 0.30135936, 0.34832352,\n",
              "        0.37512285, 0.39165512, 0.40850994, 0.4237429 , 0.44932517],\n",
              "       dtype=float32),\n",
              " array([0.6131261 , 0.67998576, 0.72469556, 0.7498568 , 0.7848488 ,\n",
              "        0.8093942 , 0.81980723, 0.82446206, 0.8366104 , 0.8464099 ],\n",
              "       dtype=float32),\n",
              " array([0.5397039 , 0.54839015, 0.548725  , 0.5781881 , 0.58216256,\n",
              "        0.5885046 , 0.5894008 , 0.6452905 , 0.6613081 , 0.6995795 ],\n",
              "       dtype=float32),\n",
              " array([0.36216798, 0.39939633, 0.41355446, 0.42008185, 0.4242987 ,\n",
              "        0.514323  , 0.5188003 , 0.53346723, 0.5976997 , 0.6296147 ],\n",
              "       dtype=float32),\n",
              " array([0.31851637, 0.36426628, 0.41488048, 0.42460144, 0.42549324,\n",
              "        0.43908063, 0.456755  , 0.49991417, 0.5012174 , 0.51062316],\n",
              "       dtype=float32),\n",
              " array([0.4681382 , 0.48881188, 0.50241774, 0.5179136 , 0.5261281 ,\n",
              "        0.5824068 , 0.6168542 , 0.6238044 , 0.6652421 , 0.73331743],\n",
              "       dtype=float32),\n",
              " array([0.3670503 , 0.36718994, 0.38252568, 0.419456  , 0.44406575,\n",
              "        0.45910522, 0.4642712 , 0.49117553, 0.5841534 , 0.6269795 ],\n",
              "       dtype=float32),\n",
              " array([0.1658468 , 0.20187202, 0.20936464, 0.22346137, 0.22350676,\n",
              "        0.24172913, 0.28489915, 0.29190794, 0.30633986, 0.32571027],\n",
              "       dtype=float32),\n",
              " array([0.5844038 , 0.5887028 , 0.6566638 , 0.6608393 , 0.7199142 ,\n",
              "        0.7301315 , 0.7302864 , 0.73546976, 0.7868058 , 0.78998613],\n",
              "       dtype=float32),\n",
              " array([0.22841585, 0.26454172, 0.2784203 , 0.28130203, 0.29878595,\n",
              "        0.31920332, 0.3339571 , 0.35286695, 0.425996  , 0.44129613],\n",
              "       dtype=float32),\n",
              " array([0.14559111, 0.17647237, 0.20976886, 0.21209909, 0.21618673,\n",
              "        0.25498286, 0.26233748, 0.2629871 , 0.2636734 , 0.36179107],\n",
              "       dtype=float32),\n",
              " array([0.16396837, 0.1719618 , 0.1782497 , 0.17945191, 0.18076266,\n",
              "        0.19435216, 0.19753054, 0.20927867, 0.23264314, 0.25942197],\n",
              "       dtype=float32),\n",
              " array([0.33843526, 0.37490377, 0.41205665, 0.4225799 , 0.44703978,\n",
              "        0.45117873, 0.48531857, 0.48583528, 0.49319482, 0.49685246],\n",
              "       dtype=float32),\n",
              " array([0.27236417, 0.31288737, 0.3334474 , 0.3642841 , 0.36477348,\n",
              "        0.37853995, 0.38734666, 0.4208959 , 0.43354717, 0.44441542],\n",
              "       dtype=float32),\n",
              " array([0.44109285, 0.4433011 , 0.45645794, 0.49165934, 0.49588168,\n",
              "        0.5013925 , 0.5067314 , 0.57183975, 0.57428783, 0.6159147 ],\n",
              "       dtype=float32),\n",
              " array([0.26661074, 0.2705807 , 0.3037189 , 0.3064544 , 0.37139505,\n",
              "        0.39304692, 0.4265668 , 0.43162027, 0.45866004, 0.46817005],\n",
              "       dtype=float32),\n",
              " array([0.13983513, 0.16527577, 0.24427688, 0.25436944, 0.29293436,\n",
              "        0.32190725, 0.34391853, 0.3497652 , 0.3544606 , 0.41709077],\n",
              "       dtype=float32),\n",
              " array([0.5268794 , 0.5929565 , 0.6097752 , 0.63542855, 0.6497641 ,\n",
              "        0.6639824 , 0.720449  , 0.7312165 , 0.76271147, 0.76693094],\n",
              "       dtype=float32),\n",
              " array([0.41506404, 0.4235146 , 0.44114468, 0.44982564, 0.457604  ,\n",
              "        0.49909258, 0.5338839 , 0.56829274, 0.56939024, 0.6234934 ],\n",
              "       dtype=float32),\n",
              " array([0.20465207, 0.23550643, 0.3193357 , 0.32076198, 0.33177564,\n",
              "        0.33280233, 0.3379827 , 0.3583676 , 0.39303535, 0.4074049 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.06011127, 0.06069674, 0.06133511, 0.0801812 ,\n",
              "        0.08504566, 0.10346253, 0.13904782, 0.15538153, 0.16315176],\n",
              "       dtype=float32),\n",
              " array([0.07014796, 0.10362159, 0.10503831, 0.12103616, 0.12630558,\n",
              "        0.1352382 , 0.14076237, 0.19422671, 0.26481938, 0.28823063],\n",
              "       dtype=float32),\n",
              " array([0.23157506, 0.268859  , 0.27331504, 0.3399856 , 0.3608684 ,\n",
              "        0.36572564, 0.39009884, 0.42872697, 0.44717273, 0.4498058 ],\n",
              "       dtype=float32),\n",
              " array([0.5424317 , 0.582484  , 0.6339977 , 0.6409048 , 0.6625304 ,\n",
              "        0.6735241 , 0.68191683, 0.7065226 , 0.7222875 , 0.7314135 ],\n",
              "       dtype=float32),\n",
              " array([0.2503268 , 0.25162676, 0.26650104, 0.26908705, 0.28515056,\n",
              "        0.3145182 , 0.32310602, 0.33258203, 0.350381  , 0.3594627 ],\n",
              "       dtype=float32),\n",
              " array([0.48859054, 0.49641556, 0.50535905, 0.5151313 , 0.5469691 ,\n",
              "        0.55095834, 0.57501125, 0.58939886, 0.59347254, 0.6481319 ],\n",
              "       dtype=float32),\n",
              " array([0.46000284, 0.47846738, 0.5075303 , 0.54033464, 0.54904175,\n",
              "        0.59093   , 0.5951102 , 0.60605127, 0.63422054, 0.66503567],\n",
              "       dtype=float32),\n",
              " array([0.18025115, 0.18808983, 0.22154012, 0.25627613, 0.26986918,\n",
              "        0.27927208, 0.28498727, 0.29274255, 0.3134829 , 0.31549403],\n",
              "       dtype=float32),\n",
              " array([0.13456763, 0.1381665 , 0.15111418, 0.17854248, 0.19218278,\n",
              "        0.21147566, 0.21488966, 0.21989809, 0.24531643, 0.2741007 ],\n",
              "       dtype=float32),\n",
              " array([0.06329225, 0.0936785 , 0.11098195, 0.11579698, 0.12276118,\n",
              "        0.14749189, 0.1518491 , 0.15629175, 0.20249085, 0.20539054],\n",
              "       dtype=float32),\n",
              " array([0.37058762, 0.4108795 , 0.49163023, 0.5275906 , 0.5558657 ,\n",
              "        0.57606345, 0.5930391 , 0.6078412 , 0.6245191 , 0.64576066],\n",
              "       dtype=float32),\n",
              " array([0.14142114, 0.16752733, 0.16841547, 0.17717485, 0.18982719,\n",
              "        0.19250591, 0.19665319, 0.21814401, 0.23687796, 0.27234647],\n",
              "       dtype=float32),\n",
              " array([0.17252478, 0.20081721, 0.20278156, 0.20724875, 0.21437   ,\n",
              "        0.22428632, 0.22685689, 0.25888562, 0.27853075, 0.2798052 ],\n",
              "       dtype=float32),\n",
              " array([0.10842744, 0.11450186, 0.15396948, 0.16133076, 0.17037429,\n",
              "        0.18382366, 0.19114028, 0.21864827, 0.26698062, 0.27329507],\n",
              "       dtype=float32),\n",
              " array([0.13776058, 0.14307554, 0.17083009, 0.17206182, 0.18048924,\n",
              "        0.1819642 , 0.22044238, 0.22902103, 0.23736264, 0.25322866],\n",
              "       dtype=float32),\n",
              " array([0.19138162, 0.21387516, 0.22531752, 0.23557949, 0.2510616 ,\n",
              "        0.26855138, 0.2782449 , 0.290605  , 0.32112497, 0.34103072],\n",
              "       dtype=float32),\n",
              " array([0.10304575, 0.11001339, 0.12509552, 0.13370486, 0.1481695 ,\n",
              "        0.15911178, 0.16746332, 0.18400516, 0.19730555, 0.23452808],\n",
              "       dtype=float32),\n",
              " array([0.07213276, 0.12518637, 0.13609408, 0.16136351, 0.19362532,\n",
              "        0.19970581, 0.2003223 , 0.20859566, 0.23848921, 0.28119025],\n",
              "       dtype=float32),\n",
              " array([0.16072503, 0.21247388, 0.21578607, 0.21773371, 0.21945667,\n",
              "        0.22659607, 0.25051612, 0.2599876 , 0.26946938, 0.27517954],\n",
              "       dtype=float32),\n",
              " array([0.5015767 , 0.5724383 , 0.5854479 , 0.5858801 , 0.62081844,\n",
              "        0.6391962 , 0.69612354, 0.7021372 , 0.7050422 , 0.7415518 ],\n",
              "       dtype=float32),\n",
              " array([0.5304136 , 0.593376  , 0.6161542 , 0.661672  , 0.66839015,\n",
              "        0.676558  , 0.6931159 , 0.70351964, 0.7185575 , 0.7492507 ],\n",
              "       dtype=float32),\n",
              " array([0.18747923, 0.21783601, 0.250505  , 0.27153155, 0.27376094,\n",
              "        0.27853215, 0.28692684, 0.29329973, 0.29628038, 0.3807462 ],\n",
              "       dtype=float32),\n",
              " array([0.17534621, 0.19411506, 0.20643704, 0.21175075, 0.2119491 ,\n",
              "        0.22503392, 0.243739  , 0.24441896, 0.2574095 , 0.32932416],\n",
              "       dtype=float32),\n",
              " array([0.17835753, 0.23049359, 0.2691622 , 0.29708335, 0.30159625,\n",
              "        0.30580193, 0.3170004 , 0.32112652, 0.35385507, 0.52786857],\n",
              "       dtype=float32),\n",
              " array([0.21474901, 0.24140042, 0.25526345, 0.25526896, 0.25553223,\n",
              "        0.2556606 , 0.26652935, 0.27344307, 0.2763303 , 0.29510462],\n",
              "       dtype=float32),\n",
              " array([0.4944648 , 0.5430003 , 0.5956453 , 0.5963045 , 0.615018  ,\n",
              "        0.6441691 , 0.6593733 , 0.70619637, 0.70821315, 0.75454646],\n",
              "       dtype=float32),\n",
              " array([0.14603719, 0.16505182, 0.16835472, 0.1816626 , 0.19030291,\n",
              "        0.21136971, 0.21366243, 0.21369658, 0.2230033 , 0.25687176],\n",
              "       dtype=float32),\n",
              " array([0.16279362, 0.1634274 , 0.1695648 , 0.1896164 , 0.19644377,\n",
              "        0.2014262 , 0.2121579 , 0.21893777, 0.21932144, 0.2778824 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.02212357, 0.04076203, 0.0572443 , 0.05954354,\n",
              "        0.06546588, 0.07187871, 0.07768425, 0.08184132, 0.09290925],\n",
              "       dtype=float32),\n",
              " array([0.12779413, 0.13433799, 0.13580161, 0.16149384, 0.1622786 ,\n",
              "        0.1639843 , 0.17376706, 0.182566  , 0.22501712, 0.24861468],\n",
              "       dtype=float32),\n",
              " array([0.60847753, 0.6366396 , 0.65937775, 0.672517  , 0.6994045 ,\n",
              "        0.7276622 , 0.7560958 , 0.76237535, 0.7695083 , 0.8214875 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.02212357, 0.04076203, 0.0572443 , 0.05954354,\n",
              "        0.06546588, 0.07187871, 0.07768425, 0.08184132, 0.09290925],\n",
              "       dtype=float32),\n",
              " array([0.1474097 , 0.16489038, 0.17861034, 0.21310262, 0.23882869,\n",
              "        0.23995593, 0.24924764, 0.2576099 , 0.2634821 , 0.3959849 ],\n",
              "       dtype=float32),\n",
              " array([0.11837224, 0.17916657, 0.18848525, 0.19662634, 0.19733189,\n",
              "        0.19812159, 0.22249475, 0.25135747, 0.26201776, 0.26254445],\n",
              "       dtype=float32),\n",
              " array([0.1279975 , 0.1441503 , 0.14794883, 0.15344723, 0.15757501,\n",
              "        0.1715367 , 0.17611517, 0.18667723, 0.1923851 , 0.2549077 ],\n",
              "       dtype=float32),\n",
              " array([0.5595227 , 0.61325413, 0.67849046, 0.67900205, 0.7059011 ,\n",
              "        0.7300716 , 0.7337109 , 0.7443759 , 0.76762944, 0.7937192 ],\n",
              "       dtype=float32),\n",
              " array([0.1279975 , 0.1441503 , 0.14794883, 0.15344723, 0.15757501,\n",
              "        0.1715367 , 0.17611517, 0.18667723, 0.1923851 , 0.2549077 ],\n",
              "       dtype=float32),\n",
              " array([0.15719837, 0.16233179, 0.16373076, 0.16641538, 0.16700478,\n",
              "        0.16822134, 0.1750121 , 0.22490704, 0.2382734 , 0.25013638],\n",
              "       dtype=float32),\n",
              " array([0.10525266, 0.13228193, 0.1375049 , 0.1458836 , 0.14808826,\n",
              "        0.15498757, 0.17218743, 0.18929453, 0.20956591, 0.24492039],\n",
              "       dtype=float32),\n",
              " array([0.14248754, 0.15252978, 0.15326175, 0.15726824, 0.16217728,\n",
              "        0.16558647, 0.17318217, 0.17897268, 0.19151863, 0.2318153 ],\n",
              "       dtype=float32),\n",
              " array([0.07129505, 0.10616846, 0.10848597, 0.11167531, 0.11217432,\n",
              "        0.11730251, 0.12160657, 0.12769061, 0.14989583, 0.16838309],\n",
              "       dtype=float32),\n",
              " array([0.11837224, 0.17916657, 0.18848525, 0.19662634, 0.19733189,\n",
              "        0.19812159, 0.22249475, 0.25135747, 0.26201776, 0.26254445],\n",
              "       dtype=float32),\n",
              " array([0.16206072, 0.17443107, 0.17626356, 0.18408889, 0.19166626,\n",
              "        0.19676083, 0.20438994, 0.20744881, 0.20905004, 0.27526867],\n",
              "       dtype=float32),\n",
              " array([0.13284042, 0.13390997, 0.13746208, 0.14949942, 0.16284949,\n",
              "        0.18634835, 0.20434925, 0.21806376, 0.24476264, 0.32692063],\n",
              "       dtype=float32),\n",
              " array([0.14352372, 0.14947875, 0.17971717, 0.21147102, 0.2231371 ,\n",
              "        0.24970485, 0.24998802, 0.27493316, 0.2988288 , 0.4049835 ],\n",
              "       dtype=float32),\n",
              " array([0.15134701, 0.15920517, 0.17072174, 0.17222984, 0.17700274,\n",
              "        0.20850085, 0.20946357, 0.21144632, 0.22936688, 0.31787997],\n",
              "       dtype=float32),\n",
              " array([0.16799411, 0.16976434, 0.17906016, 0.18353543, 0.18490629,\n",
              "        0.18625373, 0.19244124, 0.2169246 , 0.22186457, 0.2308344 ],\n",
              "       dtype=float32),\n",
              " array([0.14810139, 0.1495312 , 0.1608282 , 0.16262577, 0.17736037,\n",
              "        0.18169829, 0.19552599, 0.19585963, 0.19758517, 0.25801343],\n",
              "       dtype=float32),\n",
              " array([0.08493806, 0.13182688, 0.13225044, 0.14080147, 0.140963  ,\n",
              "        0.14616443, 0.15607476, 0.1751996 , 0.17712766, 0.19324374],\n",
              "       dtype=float32),\n",
              " array([0.088862  , 0.0961694 , 0.10220899, 0.11580542, 0.12485336,\n",
              "        0.1461372 , 0.1678523 , 0.17433867, 0.17949703, 0.18389718],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.04051191, 0.06836077, 0.07332408, 0.07589769,\n",
              "        0.07627544, 0.09846468, 0.10977022, 0.11016227, 0.11768725],\n",
              "       dtype=float32),\n",
              " array([0.12779413, 0.13433799, 0.13580161, 0.16149384, 0.1622786 ,\n",
              "        0.1639843 , 0.17376706, 0.182566  , 0.22501712, 0.24861468],\n",
              "       dtype=float32),\n",
              " array([0.12779413, 0.13433799, 0.13580161, 0.16149384, 0.1622786 ,\n",
              "        0.1639843 , 0.17376706, 0.182566  , 0.22501712, 0.24861468],\n",
              "       dtype=float32),\n",
              " array([0.07129505, 0.10616846, 0.10848597, 0.11167531, 0.11217432,\n",
              "        0.11730251, 0.12160657, 0.12769061, 0.14989583, 0.16838309],\n",
              "       dtype=float32),\n",
              " array([0.13295354, 0.13478795, 0.13516098, 0.13614306, 0.15362759,\n",
              "        0.17944817, 0.19834115, 0.21821591, 0.24042597, 0.31951478],\n",
              "       dtype=float32),\n",
              " array([0.03848385, 0.04284166, 0.04896459, 0.06196223, 0.0794121 ,\n",
              "        0.08194385, 0.08429531, 0.08662052, 0.08801435, 0.09923851],\n",
              "       dtype=float32),\n",
              " array([0.1577344 , 0.22585416, 0.23666963, 0.24119285, 0.26238102,\n",
              "        0.26790825, 0.27826017, 0.28811267, 0.3683156 , 0.4429775 ],\n",
              "       dtype=float32),\n",
              " array([0.18289006, 0.24776122, 0.25417665, 0.26519892, 0.2902718 ,\n",
              "        0.3017179 , 0.30556688, 0.31081668, 0.31204763, 0.45691654],\n",
              "       dtype=float32),\n",
              " array([0.16119188, 0.2498951 , 0.2520715 , 0.27493298, 0.28722915,\n",
              "        0.28798804, 0.29609883, 0.3192473 , 0.40595356, 0.499054  ],\n",
              "       dtype=float32),\n",
              " array([0.17117795, 0.21765234, 0.2724195 , 0.27488884, 0.28843495,\n",
              "        0.28914467, 0.2981615 , 0.3017382 , 0.350469  , 0.49363425],\n",
              "       dtype=float32),\n",
              " array([0.21724221, 0.28253534, 0.2945236 , 0.30060017, 0.31738397,\n",
              "        0.31812552, 0.32370958, 0.343716  , 0.36090055, 0.4557418 ],\n",
              "       dtype=float32),\n",
              " array([0.18176506, 0.25956655, 0.2611061 , 0.3198822 , 0.32013136,\n",
              "        0.3246425 , 0.33979452, 0.37942198, 0.39267895, 0.57893395],\n",
              "       dtype=float32),\n",
              " array([0.15434483, 0.19390646, 0.22063582, 0.22437122, 0.23327465,\n",
              "        0.2615555 , 0.27208486, 0.27848402, 0.34913152, 0.41109732],\n",
              "       dtype=float32),\n",
              " array([0.26080218, 0.31176195, 0.32327735, 0.33101293, 0.3415616 ,\n",
              "        0.35860834, 0.36213624, 0.3669698 , 0.3943229 , 0.40753174],\n",
              "       dtype=float32),\n",
              " array([0.1776252 , 0.24359049, 0.24725685, 0.30899286, 0.31152526,\n",
              "        0.33384177, 0.34283078, 0.3681395 , 0.38445428, 0.5770172 ],\n",
              "       dtype=float32),\n",
              " array([0.21724221, 0.28253534, 0.2945236 , 0.30060017, 0.31738397,\n",
              "        0.31812552, 0.32370958, 0.343716  , 0.36090055, 0.4557418 ],\n",
              "       dtype=float32),\n",
              " array([0.11196187, 0.11933741, 0.14260331, 0.14519303, 0.15615049,\n",
              "        0.165247  , 0.18729788, 0.20967053, 0.21295336, 0.23404785],\n",
              "       dtype=float32),\n",
              " array([0.18403894, 0.24879117, 0.25850418, 0.2950905 , 0.30037513,\n",
              "        0.30631334, 0.31072846, 0.31642407, 0.32405847, 0.43824765],\n",
              "       dtype=float32),\n",
              " array([0.18559341, 0.1897469 , 0.19661322, 0.19709319, 0.2122353 ,\n",
              "        0.2143963 , 0.2165864 , 0.23810628, 0.24918406, 0.28867653],\n",
              "       dtype=float32),\n",
              " array([0.1838089 , 0.22938536, 0.23924632, 0.25343576, 0.25851324,\n",
              "        0.28026837, 0.2850734 , 0.29368597, 0.29797262, 0.41933358],\n",
              "       dtype=float32),\n",
              " array([0.17035443, 0.18045613, 0.19421566, 0.19603512, 0.2042595 ,\n",
              "        0.20534466, 0.20771807, 0.22578076, 0.23146108, 0.27651453],\n",
              "       dtype=float32),\n",
              " array([0.17614637, 0.19610685, 0.21573918, 0.22093064, 0.23613127,\n",
              "        0.24552841, 0.24872363, 0.25931177, 0.27790466, 0.33572686],\n",
              "       dtype=float32),\n",
              " array([0.62339836, 0.673785  , 0.6793503 , 0.71154994, 0.76998925,\n",
              "        0.8170673 , 0.8546902 , 0.8601946 , 0.8689614 , 0.90289956],\n",
              "       dtype=float32),\n",
              " array([0.10249832, 0.17412364, 0.18704726, 0.20317839, 0.2092326 ,\n",
              "        0.21512212, 0.22949648, 0.2357867 , 0.27284694, 0.29133803],\n",
              "       dtype=float32),\n",
              " array([0.1475518 , 0.17040491, 0.17303142, 0.20045447, 0.20333403,\n",
              "        0.21138819, 0.22100411, 0.2231287 , 0.22664966, 0.2376001 ],\n",
              "       dtype=float32),\n",
              " array([0.19416204, 0.19575098, 0.20594259, 0.20601712, 0.23570961,\n",
              "        0.24001844, 0.2402923 , 0.29114252, 0.30543268, 0.33517668],\n",
              "       dtype=float32),\n",
              " array([0.20479852, 0.24748054, 0.2586857 , 0.27810845, 0.28260976,\n",
              "        0.29390132, 0.29917353, 0.31969422, 0.32202312, 0.40281224],\n",
              "       dtype=float32),\n",
              " array([0.43977597, 0.5226223 , 0.57506365, 0.5759566 , 0.5968121 ,\n",
              "        0.62153953, 0.7148917 , 0.7604374 , 0.7618571 , 0.7669186 ],\n",
              "       dtype=float32),\n",
              " array([0.23862967, 0.24271783, 0.24916753, 0.26955158, 0.27825785,\n",
              "        0.2869792 , 0.30639362, 0.31659746, 0.3427404 , 0.35584673],\n",
              "       dtype=float32),\n",
              " array([0.23690383, 0.24723509, 0.2525541 , 0.28084832, 0.286124  ,\n",
              "        0.30649585, 0.31441256, 0.31768364, 0.34899592, 0.36953497],\n",
              "       dtype=float32),\n",
              " array([0.23184991, 0.24489608, 0.26085114, 0.27508533, 0.2821432 ,\n",
              "        0.30319306, 0.30485368, 0.3124575 , 0.33773685, 0.36311197],\n",
              "       dtype=float32),\n",
              " array([0.21887308, 0.24161315, 0.2708142 , 0.27951482, 0.28046846,\n",
              "        0.28409514, 0.31654513, 0.32509202, 0.3608497 , 0.36653358],\n",
              "       dtype=float32),\n",
              " array([0.5083067 , 0.54350936, 0.6208045 , 0.6245881 , 0.6412347 ,\n",
              "        0.68508106, 0.73156434, 0.7486387 , 0.75340974, 0.77978367],\n",
              "       dtype=float32),\n",
              " array([0.22253747, 0.29285112, 0.30106682, 0.31219754, 0.3531808 ,\n",
              "        0.35652444, 0.3625842 , 0.37273008, 0.37316298, 0.4026701 ],\n",
              "       dtype=float32),\n",
              " array([0.19299363, 0.2514506 , 0.25833285, 0.28037363, 0.31311977,\n",
              "        0.32892233, 0.34792265, 0.3491274 , 0.36098212, 0.40855014],\n",
              "       dtype=float32),\n",
              " array([0.16885899, 0.18265086, 0.24369207, 0.24400395, 0.25170612,\n",
              "        0.25303692, 0.26686573, 0.29362237, 0.3082873 , 0.3199231 ],\n",
              "       dtype=float32),\n",
              " array([0.20256335, 0.20461906, 0.23226798, 0.2400381 , 0.24337253,\n",
              "        0.24637033, 0.26424995, 0.2831273 , 0.28806642, 0.33517328],\n",
              "       dtype=float32),\n",
              " array([0.6784312 , 0.7429069 , 0.7807765 , 0.784081  , 0.80251455,\n",
              "        0.84274274, 0.84773004, 0.87069327, 0.87117875, 0.9339897 ],\n",
              "       dtype=float32),\n",
              " array([0.21155868, 0.25058404, 0.27708757, 0.2797515 , 0.30936778,\n",
              "        0.3201179 , 0.32821637, 0.332206  , 0.33945805, 0.35906565],\n",
              "       dtype=float32),\n",
              " array([0.25644073, 0.26450098, 0.2769148 , 0.31424135, 0.33079284,\n",
              "        0.33865643, 0.3411298 , 0.3463318 , 0.3678859 , 0.37527868],\n",
              "       dtype=float32),\n",
              " array([0.20043641, 0.21447189, 0.23248102, 0.23837087, 0.25604668,\n",
              "        0.25769717, 0.2942168 , 0.29476774, 0.30883712, 0.31416175],\n",
              "       dtype=float32),\n",
              " array([0.20479852, 0.24748054, 0.2586857 , 0.27810845, 0.28260976,\n",
              "        0.29390132, 0.29917353, 0.31969422, 0.32202312, 0.40281224],\n",
              "       dtype=float32),\n",
              " array([0.6559584 , 0.6691736 , 0.68445426, 0.7699255 , 0.78490275,\n",
              "        0.82910645, 0.8629132 , 0.8649267 , 0.87948775, 0.89957726],\n",
              "       dtype=float32),\n",
              " array([0.1887082 , 0.2267583 , 0.2430095 , 0.262128  , 0.27486253,\n",
              "        0.28038573, 0.28416023, 0.29144147, 0.33871225, 0.4045269 ],\n",
              "       dtype=float32),\n",
              " array([0.21096002, 0.25334156, 0.2584396 , 0.2826932 , 0.2873991 ,\n",
              "        0.2978763 , 0.30417436, 0.3391589 , 0.34454256, 0.42788622],\n",
              "       dtype=float32),\n",
              " array([0.23862967, 0.24271783, 0.24916753, 0.26955158, 0.27825785,\n",
              "        0.2869792 , 0.30639362, 0.31659746, 0.3427404 , 0.35584673],\n",
              "       dtype=float32),\n",
              " array([0.20479852, 0.24748054, 0.2586857 , 0.27810845, 0.28260976,\n",
              "        0.29390132, 0.29917353, 0.31969422, 0.32202312, 0.40281224],\n",
              "       dtype=float32),\n",
              " array([0.63123894, 0.66750866, 0.6862693 , 0.71067035, 0.76568264,\n",
              "        0.81435984, 0.8634089 , 0.8639493 , 0.88057387, 0.90683794],\n",
              "       dtype=float32),\n",
              " array([0.22870326, 0.23567975, 0.2553322 , 0.25758007, 0.26369563,\n",
              "        0.27889913, 0.2861829 , 0.29544684, 0.32599214, 0.3687904 ],\n",
              "       dtype=float32),\n",
              " array([0.19560774, 0.25374407, 0.27633864, 0.29489046, 0.30139259,\n",
              "        0.31016898, 0.31389785, 0.31870446, 0.34962767, 0.41043302],\n",
              "       dtype=float32),\n",
              " array([0.20439817, 0.24419823, 0.2518084 , 0.25211877, 0.26225922,\n",
              "        0.265849  , 0.265926  , 0.27186266, 0.32303056, 0.3696805 ],\n",
              "       dtype=float32),\n",
              " array([0.20479852, 0.24748054, 0.2586857 , 0.27810845, 0.28260976,\n",
              "        0.29390132, 0.29917353, 0.31969422, 0.32202312, 0.40281224],\n",
              "       dtype=float32),\n",
              " array([0.4678729 , 0.60781664, 0.6107411 , 0.61900705, 0.65162146,\n",
              "        0.6993463 , 0.7439184 , 0.7584976 , 0.7836826 , 0.8124313 ],\n",
              "       dtype=float32),\n",
              " array([0.20686775, 0.2766203 , 0.28417456, 0.28974733, 0.3298125 ,\n",
              "        0.3471921 , 0.3721184 , 0.3750556 , 0.39950043, 0.49773648],\n",
              "       dtype=float32),\n",
              " array([0.18264566, 0.219043  , 0.22076546, 0.22615789, 0.24189484,\n",
              "        0.24747214, 0.25515762, 0.27659187, 0.28542238, 0.2929143 ],\n",
              "       dtype=float32),\n",
              " array([0.19524488, 0.20769002, 0.22028305, 0.24043012, 0.24289078,\n",
              "        0.24383263, 0.25139382, 0.25492305, 0.27625024, 0.30431807],\n",
              "       dtype=float32),\n",
              " array([0.19524488, 0.20769002, 0.22028305, 0.24043012, 0.24289078,\n",
              "        0.24383263, 0.25139382, 0.25492305, 0.27625024, 0.30431807],\n",
              "       dtype=float32),\n",
              " array([0.7069581 , 0.7467482 , 0.85607857, 0.86533815, 0.88039005,\n",
              "        0.90562475, 0.9095626 , 0.9119035 , 0.9173256 , 0.9863565 ],\n",
              "       dtype=float32),\n",
              " array([0.2008578 , 0.22669716, 0.24449547, 0.26176   , 0.27967706,\n",
              "        0.29037267, 0.29165447, 0.2936649 , 0.3704252 , 0.37747833],\n",
              "       dtype=float32),\n",
              " array([0.19389705, 0.19791253, 0.21274687, 0.22721243, 0.2522959 ,\n",
              "        0.25912672, 0.26182693, 0.31581253, 0.3253999 , 0.3319758 ],\n",
              "       dtype=float32),\n",
              " array([0.20810942, 0.22426741, 0.2528009 , 0.25398588, 0.25717795,\n",
              "        0.26884335, 0.28534174, 0.28951722, 0.30133927, 0.31997913],\n",
              "       dtype=float32),\n",
              " array([0.1855491 , 0.21033551, 0.244734  , 0.24910876, 0.26689237,\n",
              "        0.2686192 , 0.26897216, 0.2972876 , 0.33207124, 0.3386242 ],\n",
              "       dtype=float32),\n",
              " array([0.20544842, 0.24462418, 0.25563043, 0.28050905, 0.28095996,\n",
              "        0.28856403, 0.29418656, 0.31135952, 0.3178442 , 0.41107303],\n",
              "       dtype=float32),\n",
              " array([0.26070833, 0.27025345, 0.30635518, 0.32585278, 0.3382605 ,\n",
              "        0.34768903, 0.36020115, 0.36969328, 0.3752221 , 0.3780702 ],\n",
              "       dtype=float32),\n",
              " array([0.21646336, 0.26576665, 0.27311486, 0.2867831 , 0.28808478,\n",
              "        0.3062201 , 0.33617568, 0.33959398, 0.3495164 , 0.37119257],\n",
              "       dtype=float32),\n",
              " array([0.21155868, 0.25058404, 0.27708757, 0.2797515 , 0.30936778,\n",
              "        0.3201179 , 0.32821637, 0.332206  , 0.33945805, 0.35906565],\n",
              "       dtype=float32),\n",
              " array([0.19069466, 0.22933273, 0.23111206, 0.24248755, 0.26176262,\n",
              "        0.2661139 , 0.27290702, 0.27594525, 0.28970626, 0.34744686],\n",
              "       dtype=float32),\n",
              " array([0.21008773, 0.27349797, 0.28350976, 0.28849566, 0.2942689 ,\n",
              "        0.32235634, 0.32311955, 0.32945535, 0.33935297, 0.40288818],\n",
              "       dtype=float32),\n",
              " array([0.20439817, 0.24419823, 0.2518084 , 0.25211877, 0.26225922,\n",
              "        0.265849  , 0.265926  , 0.27186266, 0.32303056, 0.3696805 ],\n",
              "       dtype=float32),\n",
              " array([0.23221762, 0.28835702, 0.2998212 , 0.30624497, 0.31401947,\n",
              "        0.33011758, 0.34569722, 0.35806462, 0.3677528 , 0.42251456],\n",
              "       dtype=float32),\n",
              " array([0.20688097, 0.22670306, 0.26506367, 0.27241206, 0.29316962,\n",
              "        0.30934888, 0.3118293 , 0.3133456 , 0.32870317, 0.4185427 ],\n",
              "       dtype=float32),\n",
              " array([0.26070833, 0.27025345, 0.30635518, 0.32585278, 0.3382605 ,\n",
              "        0.34768903, 0.36020115, 0.36969328, 0.3752221 , 0.3780702 ],\n",
              "       dtype=float32),\n",
              " array([0.19818155, 0.24725664, 0.2496558 , 0.25399044, 0.2550598 ,\n",
              "        0.27732027, 0.2987417 , 0.30897078, 0.32653984, 0.35369083],\n",
              "       dtype=float32),\n",
              " array([0.17364219, 0.24275416, 0.26654658, 0.28694424, 0.28823167,\n",
              "        0.30518603, 0.3230794 , 0.32370687, 0.3877666 , 0.3994651 ],\n",
              "       dtype=float32),\n",
              " array([0.20667545, 0.21254434, 0.24704334, 0.2511952 , 0.26230887,\n",
              "        0.27181658, 0.28371897, 0.29079923, 0.3136292 , 0.34839356],\n",
              "       dtype=float32),\n",
              " array([0.2811618 , 0.3628967 , 0.3693692 , 0.38722154, 0.4154387 ,\n",
              "        0.4542067 , 0.45730472, 0.47405714, 0.49184093, 0.4966798 ],\n",
              "       dtype=float32),\n",
              " array([0.18918523, 0.22484091, 0.24849917, 0.25161773, 0.25779393,\n",
              "        0.26860324, 0.27074838, 0.2746516 , 0.28518915, 0.3542044 ],\n",
              "       dtype=float32),\n",
              " array([0.3546585 , 0.392454  , 0.3942566 , 0.40624312, 0.43637398,\n",
              "        0.4408267 , 0.45283228, 0.4674661 , 0.48621568, 0.51765317],\n",
              "       dtype=float32),\n",
              " array([0.18918523, 0.22484091, 0.24849917, 0.25161773, 0.25779393,\n",
              "        0.26860324, 0.27074838, 0.2746516 , 0.28518915, 0.3542044 ],\n",
              "       dtype=float32),\n",
              " array([0.18193015, 0.18589321, 0.22622913, 0.24199626, 0.2517697 ,\n",
              "        0.25993162, 0.2707571 , 0.27879125, 0.3392343 , 0.36699814],\n",
              "       dtype=float32),\n",
              " array([0.25138244, 0.25403348, 0.26157728, 0.26789564, 0.2701931 ,\n",
              "        0.27655503, 0.28881744, 0.31345043, 0.31921843, 0.379162  ],\n",
              "       dtype=float32),\n",
              " array([0.17364219, 0.24275416, 0.26654658, 0.28694424, 0.28823167,\n",
              "        0.30518603, 0.3230794 , 0.32370687, 0.3877666 , 0.3994651 ],\n",
              "       dtype=float32),\n",
              " array([0.18270741, 0.22867015, 0.23115622, 0.25347376, 0.271489  ,\n",
              "        0.27236468, 0.27995422, 0.2831699 , 0.29671428, 0.4082749 ],\n",
              "       dtype=float32),\n",
              " array([0.18289006, 0.24776122, 0.25417665, 0.26519892, 0.2902718 ,\n",
              "        0.3017179 , 0.30556688, 0.31081668, 0.31204763, 0.45691654],\n",
              "       dtype=float32),\n",
              " array([0.17474142, 0.18737486, 0.1932115 , 0.20098396, 0.20502515,\n",
              "        0.21618447, 0.22859246, 0.23722044, 0.24941747, 0.3088893 ],\n",
              "       dtype=float32),\n",
              " array([0.17474142, 0.18737486, 0.1932115 , 0.20098396, 0.20502515,\n",
              "        0.21618447, 0.22859246, 0.23722044, 0.24941747, 0.3088893 ],\n",
              "       dtype=float32),\n",
              " array([0.18551923, 0.2034395 , 0.2145251 , 0.21615091, 0.21975213,\n",
              "        0.22500926, 0.25847793, 0.25948593, 0.26886263, 0.29007828],\n",
              "       dtype=float32),\n",
              " array([0.17095198, 0.18762627, 0.19026713, 0.19200142, 0.19536477,\n",
              "        0.21626322, 0.22019488, 0.22906426, 0.2614157 , 0.29172805],\n",
              "       dtype=float32),\n",
              " array([0.272249  , 0.31363857, 0.3238307 , 0.3370435 , 0.3434795 ,\n",
              "        0.3446367 , 0.357634  , 0.3933508 , 0.42364332, 0.4640296 ],\n",
              "       dtype=float32),\n",
              " array([0.272249  , 0.31363857, 0.3238307 , 0.3370435 , 0.3434795 ,\n",
              "        0.3446367 , 0.357634  , 0.3933508 , 0.42364332, 0.4640296 ],\n",
              "       dtype=float32),\n",
              " array([0.2157792 , 0.25750396, 0.2666775 , 0.27961972, 0.28017792,\n",
              "        0.2810772 , 0.28458592, 0.2994556 , 0.3434938 , 0.37145728],\n",
              "       dtype=float32),\n",
              " array([0.2670765 , 0.28193203, 0.28515694, 0.2936282 , 0.30378625,\n",
              "        0.3117372 , 0.32809806, 0.34725136, 0.38526928, 0.39006078],\n",
              "       dtype=float32),\n",
              " array([0.18064548, 0.24286246, 0.24289048, 0.2659285 , 0.27668586,\n",
              "        0.28118968, 0.28428647, 0.29614756, 0.29796687, 0.42992496],\n",
              "       dtype=float32),\n",
              " array([0.08919824, 0.17180182, 0.17989206, 0.20189996, 0.20440878,\n",
              "        0.20467165, 0.2086811 , 0.21804145, 0.24122255, 0.27837455],\n",
              "       dtype=float32),\n",
              " array([0.22347909, 0.28069797, 0.31180874, 0.31478104, 0.3492182 ,\n",
              "        0.35204318, 0.39336506, 0.41840965, 0.4302917 , 0.48973668],\n",
              "       dtype=float32),\n",
              " array([0.1789572 , 0.23817411, 0.23821883, 0.2546745 , 0.26087496,\n",
              "        0.28082478, 0.29220197, 0.2966035 , 0.29766   , 0.4182892 ],\n",
              "       dtype=float32),\n",
              " array([0.17949352, 0.24095137, 0.24799883, 0.24922906, 0.27744737,\n",
              "        0.284212  , 0.30004346, 0.30608895, 0.30817816, 0.43553203],\n",
              "       dtype=float32),\n",
              " array([0.17534621, 0.19411506, 0.20643704, 0.21175075, 0.2119491 ,\n",
              "        0.22503392, 0.243739  , 0.24441896, 0.2574095 , 0.32932416],\n",
              "       dtype=float32),\n",
              " array([0.18551923, 0.2034395 , 0.2145251 , 0.21615091, 0.21975213,\n",
              "        0.22500926, 0.25847793, 0.25948593, 0.26886263, 0.29007828],\n",
              "       dtype=float32),\n",
              " array([0.333749  , 0.3750344 , 0.40113056, 0.432883  , 0.46702445,\n",
              "        0.46894646, 0.49948677, 0.5071943 , 0.51990896, 0.5731579 ],\n",
              "       dtype=float32),\n",
              " array([0.17789787, 0.22489493, 0.26920986, 0.29361528, 0.30051193,\n",
              "        0.30653697, 0.3157758 , 0.31658432, 0.35394028, 0.5243427 ],\n",
              "       dtype=float32),\n",
              " array([0.2157792 , 0.25750396, 0.2666775 , 0.27961972, 0.28017792,\n",
              "        0.2810772 , 0.28458592, 0.2994556 , 0.3434938 , 0.37145728],\n",
              "       dtype=float32),\n",
              " array([0.18058032, 0.19493808, 0.2010606 , 0.20873362, 0.22066012,\n",
              "        0.22922085, 0.23806724, 0.24659607, 0.28062093, 0.31323305],\n",
              "       dtype=float32),\n",
              " array([0.19696417, 0.19821315, 0.20055015, 0.21410814, 0.21908732,\n",
              "        0.22090916, 0.22832377, 0.2315838 , 0.24359848, 0.2543789 ],\n",
              "       dtype=float32),\n",
              " array([0.45999888, 0.4727716 , 0.4762256 , 0.5033065 , 0.516432  ,\n",
              "        0.589668  , 0.59726083, 0.60087454, 0.6494793 , 0.7091208 ],\n",
              "       dtype=float32),\n",
              " array([0.18270741, 0.22867015, 0.23115622, 0.25347376, 0.271489  ,\n",
              "        0.27236468, 0.27995422, 0.2831699 , 0.29671428, 0.4082749 ],\n",
              "       dtype=float32),\n",
              " array([0.18300715, 0.19987479, 0.20237488, 0.2031248 , 0.21009685,\n",
              "        0.22115427, 0.2432549 , 0.25084704, 0.2595542 , 0.33751893],\n",
              "       dtype=float32),\n",
              " array([0.11837896, 0.12547557, 0.14462562, 0.1569779 , 0.1672576 ,\n",
              "        0.18395017, 0.18778153, 0.19098721, 0.19112442, 0.26545727],\n",
              "       dtype=float32),\n",
              " array([0.09264155, 0.1066434 , 0.14049844, 0.15126711, 0.1554961 ,\n",
              "        0.15896973, 0.16635132, 0.1739882 , 0.17901199, 0.20823291],\n",
              "       dtype=float32),\n",
              " array([0.25367013, 0.32812166, 0.3367387 , 0.37648696, 0.37932855,\n",
              "        0.38451168, 0.3970978 , 0.41268963, 0.44002676, 0.52081704],\n",
              "       dtype=float32),\n",
              " array([0.17365661, 0.17552762, 0.18262291, 0.18512811, 0.19138882,\n",
              "        0.2021    , 0.20483625, 0.21836877, 0.23322272, 0.23932745],\n",
              "       dtype=float32),\n",
              " array([0.12957314, 0.17264445, 0.18798293, 0.21036193, 0.21292208,\n",
              "        0.21691926, 0.22168708, 0.22293435, 0.22674227, 0.26798227],\n",
              "       dtype=float32),\n",
              " array([0.17408042, 0.18147565, 0.18831041, 0.1954984 , 0.20153911,\n",
              "        0.20543467, 0.20860547, 0.22023594, 0.22710846, 0.2855285 ],\n",
              "       dtype=float32),\n",
              " array([0.17035443, 0.18045613, 0.19421566, 0.19603512, 0.2042595 ,\n",
              "        0.20534466, 0.20771807, 0.22578076, 0.23146108, 0.27651453],\n",
              "       dtype=float32),\n",
              " array([0.11406206, 0.17906813, 0.250086  , 0.28286597, 0.30539423,\n",
              "        0.32776505, 0.33090818, 0.3548525 , 0.3682937 , 0.47644877],\n",
              "       dtype=float32),\n",
              " array([0.18765429, 0.19211774, 0.19571622, 0.19850402, 0.20102984,\n",
              "        0.20280562, 0.2193003 , 0.2312709 , 0.23715083, 0.2859975 ],\n",
              "       dtype=float32),\n",
              " array([0.17249137, 0.17289689, 0.22317472, 0.22893013, 0.23202717,\n",
              "        0.23585193, 0.24356225, 0.2546398 , 0.26067385, 0.3243646 ],\n",
              "       dtype=float32),\n",
              " array([0.17408042, 0.18147565, 0.18831041, 0.1954984 , 0.20153911,\n",
              "        0.20543467, 0.20860547, 0.22023594, 0.22710846, 0.2855285 ],\n",
              "       dtype=float32),\n",
              " array([0.18559341, 0.1897469 , 0.19661322, 0.19709319, 0.2122353 ,\n",
              "        0.2143963 , 0.2165864 , 0.23810628, 0.24918406, 0.28867653],\n",
              "       dtype=float32),\n",
              " array([0.5152233 , 0.5467041 , 0.57386386, 0.5965451 , 0.5996112 ,\n",
              "        0.6142871 , 0.6393459 , 0.6443634 , 0.7044603 , 0.7093001 ],\n",
              "       dtype=float32),\n",
              " array([0.1475518 , 0.17040491, 0.17303142, 0.20045447, 0.20333403,\n",
              "        0.21138819, 0.22100411, 0.2231287 , 0.22664966, 0.2376001 ],\n",
              "       dtype=float32),\n",
              " array([0.17732218, 0.1912745 , 0.1916635 , 0.19268988, 0.19959438,\n",
              "        0.19982497, 0.20260738, 0.22534104, 0.23252802, 0.25504842],\n",
              "       dtype=float32),\n",
              " array([0.4527452 , 0.47603887, 0.5018783 , 0.5163485 , 0.52142054,\n",
              "        0.5313117 , 0.5705036 , 0.57166374, 0.5765279 , 0.66549736],\n",
              "       dtype=float32),\n",
              " array([0.60788494, 0.6442249 , 0.66910475, 0.6953683 , 0.7042103 ,\n",
              "        0.7263692 , 0.7329499 , 0.7655152 , 0.78844136, 0.80472773],\n",
              "       dtype=float32),\n",
              " array([0.6005544 , 0.61505127, 0.65287316, 0.6755314 , 0.7114835 ,\n",
              "        0.7319038 , 0.7481781 , 0.7521994 , 0.79936934, 0.82349163],\n",
              "       dtype=float32),\n",
              " array([0.3925166 , 0.4086699 , 0.41529247, 0.41952085, 0.4541086 ,\n",
              "        0.47191033, 0.4783995 , 0.508031  , 0.5507352 , 0.6075507 ],\n",
              "       dtype=float32),\n",
              " array([0.32658815, 0.4082297 , 0.4260396 , 0.43284702, 0.44199595,\n",
              "        0.44520512, 0.49541032, 0.51308846, 0.5156572 , 0.54939574],\n",
              "       dtype=float32),\n",
              " array([0.24602938, 0.31816906, 0.32679665, 0.3550171 , 0.35799545,\n",
              "        0.37123913, 0.37879127, 0.39024228, 0.3961002 , 0.5542874 ],\n",
              "       dtype=float32),\n",
              " array([0.28053015, 0.3548938 , 0.38274136, 0.39999282, 0.41405362,\n",
              "        0.43120944, 0.43418795, 0.44854474, 0.48086187, 0.48647264],\n",
              "       dtype=float32),\n",
              " array([0.58911973, 0.5921742 , 0.63711256, 0.6821016 , 0.71638435,\n",
              "        0.7433848 , 0.7552641 , 0.762524  , 0.7864225 , 0.83154607],\n",
              "       dtype=float32),\n",
              " array([0.255262  , 0.32345268, 0.34251103, 0.35333258, 0.35355884,\n",
              "        0.36506948, 0.38632408, 0.4016454 , 0.43201894, 0.5184294 ],\n",
              "       dtype=float32),\n",
              " array([0.2658545 , 0.3536176 , 0.3587739 , 0.36144346, 0.37813678,\n",
              "        0.3790446 , 0.4242171 , 0.43755883, 0.4559454 , 0.4684624 ],\n",
              "       dtype=float32),\n",
              " array([0.3677953 , 0.40824625, 0.45414945, 0.47440788, 0.4790958 ,\n",
              "        0.53204876, 0.53659165, 0.5422619 , 0.571088  , 0.70056385],\n",
              "       dtype=float32),\n",
              " array([0.26973775, 0.41528314, 0.42622942, 0.43070605, 0.43834534,\n",
              "        0.43912324, 0.449058  , 0.45308945, 0.45326695, 0.5551984 ],\n",
              "       dtype=float32),\n",
              " array([0.555822  , 0.58219004, 0.624695  , 0.62867135, 0.65351385,\n",
              "        0.676148  , 0.69533384, 0.73506945, 0.7726893 , 0.82674223],\n",
              "       dtype=float32),\n",
              " array([0.2803815 , 0.32219675, 0.355503  , 0.38176763, 0.38758695,\n",
              "        0.39562103, 0.4156063 , 0.42056248, 0.46264568, 0.54778713],\n",
              "       dtype=float32),\n",
              " array([0.2273358 , 0.2796306 , 0.31686923, 0.3514535 , 0.37794542,\n",
              "        0.384692  , 0.39588   , 0.4224773 , 0.46244982, 0.4642831 ],\n",
              "       dtype=float32),\n",
              " array([0.2658545 , 0.3536176 , 0.3587739 , 0.36144346, 0.37813678,\n",
              "        0.3790446 , 0.4242171 , 0.43755883, 0.4559454 , 0.4684624 ],\n",
              "       dtype=float32),\n",
              " array([0.24089417, 0.3018386 , 0.332023  , 0.36347997, 0.39936692,\n",
              "        0.4012842 , 0.41434476, 0.42620718, 0.44439337, 0.47407097],\n",
              "       dtype=float32),\n",
              " array([0.6005544 , 0.61505127, 0.65287316, 0.6755314 , 0.7114835 ,\n",
              "        0.7319038 , 0.7481781 , 0.7521994 , 0.79936934, 0.82349163],\n",
              "       dtype=float32),\n",
              " array([0.04777701, 0.0593028 , 0.05960819, 0.05967936, 0.07197389,\n",
              "        0.08719161, 0.09356549, 0.1103145 , 0.11967809, 0.13480505],\n",
              "       dtype=float32),\n",
              " array([0.05506043, 0.05664916, 0.05994621, 0.06610659, 0.0733098 ,\n",
              "        0.08332402, 0.09057252, 0.10942194, 0.11124576, 0.13037618],\n",
              "       dtype=float32),\n",
              " array([0.04777701, 0.0593028 , 0.05960819, 0.05967936, 0.07197389,\n",
              "        0.08719161, 0.09356549, 0.1103145 , 0.11967809, 0.13480505],\n",
              "       dtype=float32),\n",
              " array([0.06213341, 0.07507554, 0.08360608, 0.09205619, 0.103311  ,\n",
              "        0.10619139, 0.12531178, 0.12990381, 0.14034005, 0.14867085],\n",
              "       dtype=float32),\n",
              " array([0.05208679, 0.05545431, 0.05555608, 0.06310512, 0.06783097,\n",
              "        0.08562957, 0.09631547, 0.10873561, 0.12400387, 0.13409448],\n",
              "       dtype=float32),\n",
              " array([0.0776419 , 0.07866953, 0.08962286, 0.10028266, 0.10092326,\n",
              "        0.10252272, 0.1120913 , 0.11687444, 0.1325945 , 0.14816354],\n",
              "       dtype=float32),\n",
              " array([0.05637309, 0.05795078, 0.0653611 , 0.06557593, 0.06854467,\n",
              "        0.07795326, 0.09607106, 0.10875393, 0.11082316, 0.13194826],\n",
              "       dtype=float32),\n",
              " array([0.42664889, 0.42983904, 0.43763158, 0.46354583, 0.49982423,\n",
              "        0.51471543, 0.53335524, 0.5540985 , 0.6026    , 0.66091037],\n",
              "       dtype=float32),\n",
              " array([0.04788105, 0.05465606, 0.05851287, 0.05869237, 0.07084972,\n",
              "        0.07832259, 0.09837105, 0.09949435, 0.10365339, 0.12295388],\n",
              "       dtype=float32),\n",
              " array([0.03942191, 0.04789564, 0.05217503, 0.05334042, 0.05388677,\n",
              "        0.06724706, 0.09796495, 0.10511071, 0.11136129, 0.12200659],\n",
              "       dtype=float32),\n",
              " array([0.04607645, 0.04950374, 0.05571948, 0.05607731, 0.05770005,\n",
              "        0.0674187 , 0.09425218, 0.09766205, 0.10460497, 0.12092546],\n",
              "       dtype=float32),\n",
              " array([0.0433155 , 0.04692521, 0.05978642, 0.06111918, 0.06223626,\n",
              "        0.07257106, 0.09258624, 0.10453105, 0.10912744, 0.12126796],\n",
              "       dtype=float32),\n",
              " array([0.06214327, 0.06528331, 0.07726223, 0.08040565, 0.08306126,\n",
              "        0.08371118, 0.11062668, 0.11388072, 0.1279223 , 0.12804861],\n",
              "       dtype=float32),\n",
              " array([0.30914506, 0.3400374 , 0.36006987, 0.3949158 , 0.42033842,\n",
              "        0.42524365, 0.45697325, 0.45932734, 0.48285365, 0.49221244],\n",
              "       dtype=float32),\n",
              " array([0.1420599 , 0.15131977, 0.19362712, 0.22509886, 0.23025729,\n",
              "        0.23074147, 0.23517522, 0.2835706 , 0.34470955, 0.35465693],\n",
              "       dtype=float32),\n",
              " array([0.22780082, 0.2692986 , 0.3003655 , 0.30206114, 0.32038158,\n",
              "        0.33676222, 0.33733526, 0.36483863, 0.4155596 , 0.4615185 ],\n",
              "       dtype=float32),\n",
              " array([0.2402239 , 0.28167558, 0.29352126, 0.30811033, 0.32102442,\n",
              "        0.34102726, 0.34366104, 0.3735637 , 0.43233955, 0.4636376 ],\n",
              "       dtype=float32),\n",
              " array([0.40351796, 0.41696188, 0.42010248, 0.4210585 , 0.45817167,\n",
              "        0.48286054, 0.48416284, 0.53229547, 0.5548849 , 0.6043316 ],\n",
              "       dtype=float32),\n",
              " array([0.20768023, 0.23182815, 0.23314382, 0.25111565, 0.2766803 ,\n",
              "        0.29754293, 0.30788305, 0.321396  , 0.39221662, 0.41630653],\n",
              "       dtype=float32),\n",
              " array([0.29607075, 0.31219754, 0.3207665 , 0.34200165, 0.35928732,\n",
              "        0.37208834, 0.37993273, 0.42884073, 0.461422  , 0.47313336],\n",
              "       dtype=float32),\n",
              " array([0.1331281 , 0.13585964, 0.18845911, 0.20176116, 0.21012384,\n",
              "        0.22104605, 0.22640136, 0.2880452 , 0.329533  , 0.3375833 ],\n",
              "       dtype=float32),\n",
              " array([0.2402239 , 0.28167558, 0.29352126, 0.30811033, 0.32102442,\n",
              "        0.34102726, 0.34366104, 0.3735637 , 0.43233955, 0.4636376 ],\n",
              "       dtype=float32),\n",
              " array([0.12807444, 0.13018677, 0.15787925, 0.19737078, 0.20257355,\n",
              "        0.20318668, 0.21014442, 0.27819312, 0.31215075, 0.33081132],\n",
              "       dtype=float32),\n",
              " array([0.20219812, 0.20809382, 0.21385118, 0.2540576 , 0.26496375,\n",
              "        0.27467087, 0.29046217, 0.29588708, 0.38805225, 0.4035443 ],\n",
              "       dtype=float32),\n",
              " array([0.14076534, 0.19105338, 0.21753469, 0.2258134 , 0.24710183,\n",
              "        0.2624313 , 0.29574183, 0.29782176, 0.34573185, 0.35299355],\n",
              "       dtype=float32),\n",
              " array([0.23437119, 0.27365756, 0.27507952, 0.28069675, 0.30198404,\n",
              "        0.33383206, 0.33557004, 0.35805473, 0.42581806, 0.4427381 ],\n",
              "       dtype=float32),\n",
              " array([0.04053885, 0.06021954, 0.0669898 , 0.07204512, 0.07690154,\n",
              "        0.08544949, 0.09503101, 0.11254717, 0.12004165, 0.14513975],\n",
              "       dtype=float32),\n",
              " array([0.5011686 , 0.5713982 , 0.5812959 , 0.60317314, 0.60459733,\n",
              "        0.6219864 , 0.6262338 , 0.6414402 , 0.66523266, 0.6832943 ],\n",
              "       dtype=float32),\n",
              " array([0.04168902, 0.05405409, 0.05483266, 0.06132898, 0.06141362,\n",
              "        0.07126957, 0.092371  , 0.1099906 , 0.11075882, 0.12820284],\n",
              "       dtype=float32),\n",
              " array([0.04410741, 0.05207824, 0.05967868, 0.06162849, 0.06477081,\n",
              "        0.06924431, 0.09305435, 0.09488922, 0.10307171, 0.1302623 ],\n",
              "       dtype=float32),\n",
              " array([0.05239574, 0.05463198, 0.0635555 , 0.0708739 , 0.07445181,\n",
              "        0.07864287, 0.10065906, 0.10138541, 0.11729784, 0.12858231],\n",
              "       dtype=float32),\n",
              " array([0.04410741, 0.05207824, 0.05967868, 0.06162849, 0.06477081,\n",
              "        0.06924431, 0.09305435, 0.09488922, 0.10307171, 0.1302623 ],\n",
              "       dtype=float32),\n",
              " array([0.04900189, 0.05158736, 0.06604973, 0.06628187, 0.07196485,\n",
              "        0.07444785, 0.09808535, 0.09864124, 0.11272128, 0.12011553],\n",
              "       dtype=float32),\n",
              " array([0.04600842, 0.05443112, 0.05808123, 0.0653429 , 0.06986495,\n",
              "        0.09052472, 0.10048206, 0.1032944 , 0.11052292, 0.1261029 ],\n",
              "       dtype=float32),\n",
              " array([0.25713086, 0.29367098, 0.353888  , 0.35477173, 0.37711102,\n",
              "        0.40089902, 0.4367593 , 0.49789232, 0.5334242 , 0.5647152 ],\n",
              "       dtype=float32),\n",
              " array([0.5454169 , 0.54837424, 0.619585  , 0.6205164 , 0.62515897,\n",
              "        0.67840487, 0.7128679 , 0.7492186 , 0.75237036, 0.79249096],\n",
              "       dtype=float32),\n",
              " array([0.3630175 , 0.3865721 , 0.4164136 , 0.47386307, 0.48051432,\n",
              "        0.48243055, 0.5387618 , 0.5494867 , 0.5630811 , 0.5747117 ],\n",
              "       dtype=float32),\n",
              " array([0.5970522 , 0.6239919 , 0.6284967 , 0.6298202 , 0.6370743 ,\n",
              "        0.65632623, 0.70959044, 0.7106757 , 0.7140482 , 0.76775265],\n",
              "       dtype=float32),\n",
              " array([0.53549975, 0.55972284, 0.6193622 , 0.62272084, 0.62785447,\n",
              "        0.67306364, 0.7030165 , 0.74142516, 0.75579834, 0.78764373],\n",
              "       dtype=float32),\n",
              " array([0.3830337 , 0.39096794, 0.4047082 , 0.43126833, 0.44002593,\n",
              "        0.48576164, 0.48905322, 0.52883863, 0.55078745, 0.65962416],\n",
              "       dtype=float32),\n",
              " array([0.5069053 , 0.52632594, 0.5984611 , 0.60415095, 0.62661296,\n",
              "        0.66469675, 0.6897671 , 0.690099  , 0.70195717, 0.7613323 ],\n",
              "       dtype=float32),\n",
              " array([0.5069053 , 0.52632594, 0.5984611 , 0.60415095, 0.62661296,\n",
              "        0.66469675, 0.6897671 , 0.690099  , 0.70195717, 0.7613323 ],\n",
              "       dtype=float32),\n",
              " array([0.28072104, 0.32306215, 0.36969852, 0.37124616, 0.38839304,\n",
              "        0.40092468, 0.44341892, 0.4951322 , 0.575291  , 0.5912045 ],\n",
              "       dtype=float32),\n",
              " array([0.38344386, 0.4183764 , 0.42964658, 0.4560607 , 0.46253708,\n",
              "        0.46788636, 0.4896367 , 0.49145916, 0.5538829 , 0.58253586],\n",
              "       dtype=float32),\n",
              " array([0.3673528 , 0.40521654, 0.42701727, 0.4398733 , 0.49312675,\n",
              "        0.514922  , 0.52528673, 0.56849056, 0.58376324, 0.6199391 ],\n",
              "       dtype=float32),\n",
              " array([0.45941606, 0.46083277, 0.4929312 , 0.53189826, 0.55251354,\n",
              "        0.5601053 , 0.59731203, 0.6114744 , 0.6260932 , 0.7362464 ],\n",
              "       dtype=float32),\n",
              " array([0.40318954, 0.45638907, 0.458121  , 0.46102068, 0.47071856,\n",
              "        0.48812053, 0.49021477, 0.5161335 , 0.5186379 , 0.5994379 ],\n",
              "       dtype=float32),\n",
              " array([0.47119653, 0.4993135 , 0.5951638 , 0.60728157, 0.6337165 ,\n",
              "        0.6408421 , 0.6443484 , 0.6558154 , 0.66291744, 0.762561  ],\n",
              "       dtype=float32),\n",
              " array([0.46075085, 0.4619591 , 0.47316614, 0.4968932 , 0.49697772,\n",
              "        0.4980621 , 0.5029638 , 0.5259832 , 0.59444183, 0.59584826],\n",
              "       dtype=float32),\n",
              " array([0.39407793, 0.3945996 , 0.39604855, 0.4114769 , 0.45406902,\n",
              "        0.4683203 , 0.47077116, 0.50954247, 0.5541473 , 0.5849031 ],\n",
              "       dtype=float32),\n",
              " array([0.3006731 , 0.31592262, 0.3258804 , 0.33301926, 0.34185785,\n",
              "        0.34812865, 0.36905235, 0.3783903 , 0.39055267, 0.4157654 ],\n",
              "       dtype=float32),\n",
              " array([0.39732188, 0.44889617, 0.45604837, 0.46050495, 0.4723305 ,\n",
              "        0.47980928, 0.49817127, 0.578097  , 0.5890961 , 0.5899006 ],\n",
              "       dtype=float32),\n",
              " array([0.4227796 , 0.4467853 , 0.47502983, 0.48070773, 0.49659786,\n",
              "        0.5182571 , 0.5282845 , 0.5624858 , 0.58363533, 0.6064657 ],\n",
              "       dtype=float32),\n",
              " array([0.34419337, 0.36218917, 0.43116423, 0.4415672 , 0.45259133,\n",
              "        0.4627096 , 0.49404767, 0.50032645, 0.5170585 , 0.56221515],\n",
              "       dtype=float32),\n",
              " array([0.58020633, 0.60908544, 0.6745163 , 0.6921189 , 0.70745647,\n",
              "        0.7204563 , 0.72104704, 0.748192  , 0.76638174, 0.815347  ],\n",
              "       dtype=float32),\n",
              " array([0.5747629 , 0.64954287, 0.68716836, 0.6982144 , 0.70445067,\n",
              "        0.7493988 , 0.76503795, 0.7724925 , 0.8164817 , 0.8413199 ],\n",
              "       dtype=float32),\n",
              " array([0.58020633, 0.60908544, 0.6745163 , 0.6921189 , 0.70745647,\n",
              "        0.7204563 , 0.72104704, 0.748192  , 0.76638174, 0.815347  ],\n",
              "       dtype=float32),\n",
              " array([0.58932716, 0.6563752 , 0.666626  , 0.67929614, 0.6828849 ,\n",
              "        0.7370769 , 0.7458389 , 0.7675117 , 0.7780106 , 0.9091681 ],\n",
              "       dtype=float32),\n",
              " array([0.55212176, 0.5588858 , 0.568766  , 0.6025958 , 0.6412962 ,\n",
              "        0.64363563, 0.6537626 , 0.67058295, 0.68792295, 0.7476278 ],\n",
              "       dtype=float32),\n",
              " array([0.45871672, 0.47502658, 0.50035626, 0.51357025, 0.57044965,\n",
              "        0.58386564, 0.6036224 , 0.6760385 , 0.6886996 , 0.76420534],\n",
              "       dtype=float32),\n",
              " array([0.5191367 , 0.603834  , 0.6101508 , 0.6156749 , 0.6443519 ,\n",
              "        0.66150814, 0.6748268 , 0.7365459 , 0.74314815, 0.8008732 ],\n",
              "       dtype=float32),\n",
              " array([0.50344014, 0.62134624, 0.64806575, 0.67945373, 0.7073942 ,\n",
              "        0.7709543 , 0.7792586 , 0.8239325 , 0.83587873, 0.84248537],\n",
              "       dtype=float32),\n",
              " array([0.35767484, 0.43138602, 0.43233895, 0.47470802, 0.4957261 ,\n",
              "        0.4979836 , 0.5074753 , 0.5116682 , 0.53265417, 0.5496596 ],\n",
              "       dtype=float32),\n",
              " array([0.4698335 , 0.48577526, 0.54414517, 0.56678474, 0.57002276,\n",
              "        0.6417493 , 0.6586987 , 0.6607578 , 0.7102405 , 0.7328705 ],\n",
              "       dtype=float32),\n",
              " array([0.5374311 , 0.64998364, 0.65538615, 0.6960989 , 0.71383566,\n",
              "        0.7316145 , 0.77554727, 0.8025566 , 0.8138588 , 0.85915625],\n",
              "       dtype=float32),\n",
              " array([0.48649898, 0.54882026, 0.63782436, 0.64552337, 0.6507434 ,\n",
              "        0.65956366, 0.6662556 , 0.6683108 , 0.67037904, 0.7924465 ],\n",
              "       dtype=float32),\n",
              " array([0.5737099 , 0.61100817, 0.64832354, 0.664323  , 0.6974545 ,\n",
              "        0.7158705 , 0.71710277, 0.7232553 , 0.75239915, 0.8477364 ],\n",
              "       dtype=float32),\n",
              " array([0.50344014, 0.62134624, 0.64806575, 0.67945373, 0.7073942 ,\n",
              "        0.7709543 , 0.7792586 , 0.8239325 , 0.83587873, 0.84248537],\n",
              "       dtype=float32),\n",
              " array([0.4690528 , 0.5175917 , 0.5208088 , 0.5344131 , 0.569844  ,\n",
              "        0.6105394 , 0.6173816 , 0.61839813, 0.62554806, 0.6670617 ],\n",
              "       dtype=float32),\n",
              " array([0.37664148, 0.41920218, 0.4518885 , 0.5052744 , 0.51543885,\n",
              "        0.55365837, 0.5579198 , 0.57462364, 0.5975636 , 0.6643346 ],\n",
              "       dtype=float32),\n",
              " array([0.5185411 , 0.6123977 , 0.6282827 , 0.64269626, 0.64780104,\n",
              "        0.6505867 , 0.69625413, 0.77226955, 0.77621824, 0.78306115],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.0237816 , 0.03110419, 0.04392653, 0.04824752,\n",
              "        0.04897891, 0.07178374, 0.09188279, 0.09863501, 0.11058372],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.00967384, 0.01468467, 0.02418818, 0.02687036,\n",
              "        0.0464839 , 0.05811973, 0.06590679, 0.08168144, 0.12751383],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.00459726, 0.00521344, 0.02593613,\n",
              "        0.03518457, 0.06128868, 0.06147353, 0.07159054, 0.11693902],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.00113167, 0.01076058, 0.01834607, 0.03697805,\n",
              "        0.0377817 , 0.04712375, 0.07623932, 0.09228679, 0.11069544],\n",
              "       dtype=float32),\n",
              " array([0.01207083, 0.01412327, 0.02332409, 0.0237315 , 0.03739437,\n",
              "        0.04982074, 0.06263662, 0.07455621, 0.08067548, 0.13203402],\n",
              "       dtype=float32),\n",
              " array([0.01207083, 0.01412327, 0.02332409, 0.0237315 , 0.03739437,\n",
              "        0.04982074, 0.06263662, 0.07455621, 0.08067548, 0.13203402],\n",
              "       dtype=float32),\n",
              " array([0.45233396, 0.458791  , 0.4909792 , 0.4960348 , 0.5117499 ,\n",
              "        0.5499461 , 0.5511333 , 0.5697896 , 0.6277324 , 0.65900606],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.0046927 , 0.00505376, 0.02018749, 0.03579375,\n",
              "        0.04046598, 0.05094258, 0.06188582, 0.07113199, 0.12112197],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.01640696, 0.06242305, 0.06501671, 0.06958959,\n",
              "        0.09094473, 0.10097978, 0.10971944, 0.14472291, 0.19188625],\n",
              "       dtype=float32),\n",
              " array([0.02574331, 0.03686541, 0.05007704, 0.05139886, 0.05579356,\n",
              "        0.0685192 , 0.07779443, 0.09407618, 0.10448445, 0.11427484],\n",
              "       dtype=float32),\n",
              " array([0.03399034, 0.03517863, 0.04727912, 0.05545972, 0.05995329,\n",
              "        0.06593169, 0.0705357 , 0.08336373, 0.09534834, 0.10967413],\n",
              "       dtype=float32),\n",
              " array([0.06546021, 0.12067443, 0.13444324, 0.13858297, 0.15373884,\n",
              "        0.15730321, 0.16343309, 0.16491719, 0.2035529 , 0.20703645],\n",
              "       dtype=float32),\n",
              " array([0.02510662, 0.11291067, 0.12447117, 0.13558902, 0.16910097,\n",
              "        0.16966659, 0.18643987, 0.19827333, 0.21078636, 0.33351278],\n",
              "       dtype=float32),\n",
              " array([0.48001304, 0.48341048, 0.50462043, 0.5137984 , 0.5293712 ,\n",
              "        0.544213  , 0.5552928 , 0.5709858 , 0.6292995 , 0.6746703 ],\n",
              "       dtype=float32),\n",
              " array([0.07242489, 0.14089282, 0.14477484, 0.17563778, 0.17716935,\n",
              "        0.18819152, 0.20110315, 0.22813109, 0.23394784, 0.23855118],\n",
              "       dtype=float32),\n",
              " array([0.05652193, 0.10964463, 0.133407  , 0.13564317, 0.13790826,\n",
              "        0.15428923, 0.15490577, 0.1726314 , 0.20383571, 0.21694651],\n",
              "       dtype=float32),\n",
              " array([0.05582631, 0.12604798, 0.13289796, 0.1453074 , 0.15735564,\n",
              "        0.17080396, 0.17698576, 0.1785422 , 0.23142101, 0.2437244 ],\n",
              "       dtype=float32),\n",
              " array([0.21803516, 0.24271785, 0.25877422, 0.270596  , 0.27548522,\n",
              "        0.2796589 , 0.29753906, 0.31692737, 0.3275262 , 0.3495648 ],\n",
              "       dtype=float32),\n",
              " array([0.27164578, 0.31405964, 0.33016074, 0.3409803 , 0.34655282,\n",
              "        0.3503254 , 0.35357052, 0.35707238, 0.39859393, 0.46180528],\n",
              "       dtype=float32),\n",
              " array([0.1393191 , 0.1724785 , 0.18133765, 0.18240738, 0.19325928,\n",
              "        0.19799763, 0.20489888, 0.20961644, 0.24255072, 0.2501523 ],\n",
              "       dtype=float32),\n",
              " array([0.36849463, 0.39160848, 0.39525273, 0.47207358, 0.4810579 ,\n",
              "        0.51542944, 0.54542434, 0.55688584, 0.5858961 , 0.60011524],\n",
              "       dtype=float32),\n",
              " array([0.22671747, 0.236171  , 0.24188383, 0.25580457, 0.25707477,\n",
              "        0.28055742, 0.29732317, 0.29939696, 0.30812943, 0.34429345],\n",
              "       dtype=float32),\n",
              " array([0.17964396, 0.18665183, 0.2088656 , 0.21888317, 0.24144322,\n",
              "        0.24760722, 0.26702073, 0.31107202, 0.3139238 , 0.31997102],\n",
              "       dtype=float32),\n",
              " array([0.23308398, 0.24419202, 0.25993443, 0.26458633, 0.26882926,\n",
              "        0.3092428 , 0.34982437, 0.35375398, 0.40136668, 0.42908698],\n",
              "       dtype=float32),\n",
              " array([0.14878866, 0.18222766, 0.21731256, 0.2329246 , 0.25239775,\n",
              "        0.25573713, 0.25698587, 0.30519056, 0.31769943, 0.3548525 ],\n",
              "       dtype=float32),\n",
              " array([0.23176587, 0.24845363, 0.25471973, 0.26237336, 0.29270095,\n",
              "        0.2928582 , 0.2948721 , 0.32229406, 0.3266938 , 0.3579986 ],\n",
              "       dtype=float32),\n",
              " array([0.15336052, 0.15916829, 0.1617561 , 0.16464436, 0.1649162 ,\n",
              "        0.16922998, 0.18408923, 0.1854464 , 0.22903268, 0.23630738],\n",
              "       dtype=float32),\n",
              " array([0.44071692, 0.4595165 , 0.46068916, 0.49714908, 0.51782477,\n",
              "        0.51864827, 0.5391398 , 0.54328936, 0.6089993 , 0.6600418 ],\n",
              "       dtype=float32),\n",
              " array([0.21063103, 0.23432133, 0.25066027, 0.2831339 , 0.29028022,\n",
              "        0.31457102, 0.31688732, 0.31936336, 0.34094426, 0.37803364],\n",
              "       dtype=float32),\n",
              " array([0.17437708, 0.17744161, 0.18704113, 0.19663477, 0.21560268,\n",
              "        0.24146435, 0.27750364, 0.28184977, 0.2824726 , 0.30953345],\n",
              "       dtype=float32),\n",
              " array([0.3804953 , 0.41268334, 0.44806087, 0.4641235 , 0.47316766,\n",
              "        0.5054806 , 0.55395555, 0.5587475 , 0.56743723, 0.6026768 ],\n",
              "       dtype=float32),\n",
              " array([0.38963705, 0.5012984 , 0.5105233 , 0.53013873, 0.5309886 ,\n",
              "        0.57637817, 0.5863116 , 0.60600257, 0.61950046, 0.6741403 ],\n",
              "       dtype=float32),\n",
              " array([0.40647832, 0.46691328, 0.46721166, 0.46903428, 0.5047348 ,\n",
              "        0.54784703, 0.5482151 , 0.5930174 , 0.62964696, 0.6324378 ],\n",
              "       dtype=float32),\n",
              " array([0.3669281 , 0.39150065, 0.42674613, 0.4492803 , 0.45380777,\n",
              "        0.49297288, 0.5523142 , 0.5543258 , 0.55977285, 0.5613264 ],\n",
              "       dtype=float32),\n",
              " array([0.37444162, 0.40258443, 0.440518  , 0.45635873, 0.47255751,\n",
              "        0.49746665, 0.55298173, 0.55861753, 0.5614654 , 0.5805101 ],\n",
              "       dtype=float32),\n",
              " array([0.38676628, 0.3943189 , 0.45175782, 0.48751733, 0.5085816 ,\n",
              "        0.51896214, 0.52294165, 0.53545403, 0.55060714, 0.56973577],\n",
              "       dtype=float32),\n",
              " array([0.38676628, 0.3943189 , 0.45175782, 0.48751733, 0.5085816 ,\n",
              "        0.51896214, 0.52294165, 0.53545403, 0.55060714, 0.56973577],\n",
              "       dtype=float32),\n",
              " array([0.36762172, 0.40342748, 0.45896724, 0.5008689 , 0.52549845,\n",
              "        0.52629626, 0.5508929 , 0.55207443, 0.5806555 , 0.616869  ],\n",
              "       dtype=float32),\n",
              " array([0.38225767, 0.39807898, 0.43496022, 0.44032896, 0.44503614,\n",
              "        0.48517478, 0.52790564, 0.5362059 , 0.5525138 , 0.5894721 ],\n",
              "       dtype=float32),\n",
              " array([0.38237217, 0.48100638, 0.4869758 , 0.5183825 , 0.51897496,\n",
              "        0.5391998 , 0.5690204 , 0.5981197 , 0.5982398 , 0.6455993 ],\n",
              "       dtype=float32),\n",
              " array([0.19931671, 0.19961491, 0.2125881 , 0.22254048, 0.22826192,\n",
              "        0.2580325 , 0.26523215, 0.2780786 , 0.43754265, 0.51558113],\n",
              "       dtype=float32),\n",
              " array([0.13346827, 0.16628781, 0.21600144, 0.21877341, 0.22063899,\n",
              "        0.22194372, 0.23656595, 0.3253179 , 0.3260939 , 0.49597633],\n",
              "       dtype=float32),\n",
              " array([0.14819045, 0.19871487, 0.20823787, 0.22524823, 0.24199964,\n",
              "        0.24715434, 0.25620902, 0.3374375 , 0.37178877, 0.45616993],\n",
              "       dtype=float32),\n",
              " array([0.2420142 , 0.2545376 , 0.27312675, 0.27655044, 0.29041603,\n",
              "        0.30560386, 0.33539099, 0.33641046, 0.45776483, 0.49073276],\n",
              "       dtype=float32),\n",
              " array([0.21868603, 0.25267774, 0.2622757 , 0.2663724 , 0.2787167 ,\n",
              "        0.317113  , 0.32928213, 0.38173643, 0.4668309 , 0.50965124],\n",
              "       dtype=float32),\n",
              " array([0.1591442 , 0.16467756, 0.19337691, 0.19411504, 0.20667501,\n",
              "        0.2496603 , 0.25148603, 0.3248923 , 0.3750467 , 0.388935  ],\n",
              "       dtype=float32),\n",
              " array([0.20367582, 0.20605707, 0.23248638, 0.23502998, 0.23841132,\n",
              "        0.2878298 , 0.28917247, 0.38730672, 0.41750318, 0.47959575],\n",
              "       dtype=float32),\n",
              " array([0.37623987, 0.41522312, 0.4156731 , 0.43045613, 0.43707907,\n",
              "        0.4471758 , 0.49171528, 0.5422155 , 0.55355394, 0.6066408 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.39736968, 0.4185633 , 0.42102498, 0.4302625 , 0.47981197,\n",
              "        0.4833727 , 0.5040013 , 0.561472  , 0.56264114, 0.625532  ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.01212742, 0.0361124 , 0.0396243 , 0.06663155, 0.0934532 ,\n",
              "        0.12753357, 0.15516298, 0.16213453, 0.16359662, 0.16980599],\n",
              "       dtype=float32),\n",
              " array([0.08279487, 0.10300143, 0.10964134, 0.13713966, 0.14737692,\n",
              "        0.15396416, 0.17473568, 0.17607684, 0.17733063, 0.22028942],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.01834719, 0.02397173, 0.02668031,\n",
              "        0.03238648, 0.08092615, 0.08594237, 0.11631001, 0.13443933],\n",
              "       dtype=float32),\n",
              " array([0.08122376, 0.0962914 , 0.12598807, 0.16202757, 0.1719792 ,\n",
              "        0.17282552, 0.18534778, 0.19154929, 0.20646143, 0.280057  ],\n",
              "       dtype=float32),\n",
              " array([0.02760597, 0.0551093 , 0.05850556, 0.11522397, 0.11555739,\n",
              "        0.15837437, 0.17419226, 0.17692432, 0.19786754, 0.20103824],\n",
              "       dtype=float32),\n",
              " array([0.3673528 , 0.40521654, 0.42701727, 0.4398733 , 0.49312675,\n",
              "        0.514922  , 0.52528673, 0.56849056, 0.58376324, 0.6199391 ],\n",
              "       dtype=float32),\n",
              " array([0.07497789, 0.0950833 , 0.09798469, 0.14995109, 0.1584575 ,\n",
              "        0.15893957, 0.16708004, 0.18407133, 0.2178159 , 0.22184862],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.00711418, 0.05469816, 0.07382845,\n",
              "        0.09821733, 0.1163794 , 0.12093149, 0.1337595 , 0.13858607],\n",
              "       dtype=float32),\n",
              " array([0.07497789, 0.0950833 , 0.09798469, 0.14995109, 0.1584575 ,\n",
              "        0.15893957, 0.16708004, 0.18407133, 0.2178159 , 0.22184862],\n",
              "       dtype=float32),\n",
              " array([0.11727598, 0.13615794, 0.15555702, 0.15948847, 0.18724683,\n",
              "        0.19050251, 0.20786518, 0.22330302, 0.24058734, 0.2461182 ],\n",
              "       dtype=float32),\n",
              " array([0.10268942, 0.10605551, 0.14326239, 0.14355657, 0.16655421,\n",
              "        0.18062301, 0.2025306 , 0.21662933, 0.22120242, 0.25661042],\n",
              "       dtype=float32),\n",
              " array([0.01853916, 0.03851927, 0.05436468, 0.09374788, 0.09538744,\n",
              "        0.11527293, 0.11894112, 0.12221695, 0.12888089, 0.13066076],\n",
              "       dtype=float32),\n",
              " array([0.28844097, 0.35112908, 0.36861548, 0.37814963, 0.42170048,\n",
              "        0.4255807 , 0.42813778, 0.43676987, 0.4494423 , 0.48758644],\n",
              "       dtype=float32),\n",
              " array([0.49731097, 0.49806398, 0.50067663, 0.51155114, 0.5463473 ,\n",
              "        0.57121336, 0.57360166, 0.5915066 , 0.6260745 , 0.68172234],\n",
              "       dtype=float32),\n",
              " array([0.2904743 , 0.32428873, 0.32917032, 0.3619673 , 0.3859218 ,\n",
              "        0.39704213, 0.39726838, 0.42999974, 0.4561233 , 0.461276  ],\n",
              "       dtype=float32),\n",
              " array([0.2515605 , 0.25307563, 0.28169063, 0.29215834, 0.30828294,\n",
              "        0.32730997, 0.3289288 , 0.3411821 , 0.3790274 , 0.39510947],\n",
              "       dtype=float32),\n",
              " array([0.27506176, 0.33615515, 0.33824912, 0.34942928, 0.40763396,\n",
              "        0.41704825, 0.4171535 , 0.42224947, 0.43091416, 0.46343043],\n",
              "       dtype=float32),\n",
              " array([0.27815786, 0.3021443 , 0.32815933, 0.34602338, 0.34989685,\n",
              "        0.37320033, 0.38094625, 0.39237022, 0.42203048, 0.428754  ],\n",
              "       dtype=float32),\n",
              " array([0.27815786, 0.3021443 , 0.32815933, 0.34602338, 0.34989685,\n",
              "        0.37320033, 0.38094625, 0.39237022, 0.42203048, 0.428754  ],\n",
              "       dtype=float32),\n",
              " array([0.25188756, 0.26239187, 0.27079868, 0.32873678, 0.33118173,\n",
              "        0.34435958, 0.36208615, 0.36963964, 0.39853862, 0.40702018],\n",
              "       dtype=float32),\n",
              " array([0.2883865 , 0.30670246, 0.3110515 , 0.32975447, 0.38623992,\n",
              "        0.39403778, 0.401064  , 0.40287587, 0.41738877, 0.44725826],\n",
              "       dtype=float32),\n",
              " array([0.3630175 , 0.3865721 , 0.4164136 , 0.47386307, 0.48051432,\n",
              "        0.48243055, 0.5387618 , 0.5494867 , 0.5630811 , 0.5747117 ],\n",
              "       dtype=float32),\n",
              " array([0.27338114, 0.35588866, 0.3762479 , 0.40377578, 0.42055553,\n",
              "        0.43423164, 0.44644535, 0.4578927 , 0.46709126, 0.47179002],\n",
              "       dtype=float32),\n",
              " array([0.27466   , 0.2809366 , 0.28656736, 0.32316342, 0.35731855,\n",
              "        0.36204597, 0.36566228, 0.39682728, 0.39724445, 0.40387568],\n",
              "       dtype=float32),\n",
              " array([0.27506176, 0.33615515, 0.33824912, 0.34942928, 0.40763396,\n",
              "        0.41704825, 0.4171535 , 0.42224947, 0.43091416, 0.46343043],\n",
              "       dtype=float32),\n",
              " array([0.27506176, 0.33615515, 0.33824912, 0.34942928, 0.40763396,\n",
              "        0.41704825, 0.4171535 , 0.42224947, 0.43091416, 0.46343043],\n",
              "       dtype=float32),\n",
              " array([0.25291836, 0.30854285, 0.31276217, 0.33504018, 0.3384948 ,\n",
              "        0.35285872, 0.3543345 , 0.36839697, 0.37275112, 0.4818353 ],\n",
              "       dtype=float32),\n",
              " array([0.2746906 , 0.37066808, 0.39484584, 0.4056737 , 0.44822973,\n",
              "        0.45607278, 0.47145894, 0.476175  , 0.49340215, 0.509627  ],\n",
              "       dtype=float32),\n",
              " array([0.26612085, 0.38350064, 0.43820953, 0.43966803, 0.45774227,\n",
              "        0.45953   , 0.4869506 , 0.5067513 , 0.5073761 , 0.51515424],\n",
              "       dtype=float32),\n",
              " array([0.2515605 , 0.25307563, 0.28169063, 0.29215834, 0.30828294,\n",
              "        0.32730997, 0.3289288 , 0.3411821 , 0.3790274 , 0.39510947],\n",
              "       dtype=float32),\n",
              " array([0.09401519, 0.14868481, 0.18031532, 0.18104674, 0.18165137,\n",
              "        0.18238461, 0.1996405 , 0.20984137, 0.23171246, 0.3038249 ],\n",
              "       dtype=float32),\n",
              " array([0.05975963, 0.08283431, 0.09428086, 0.10611083, 0.11906904,\n",
              "        0.13620125, 0.18727654, 0.19069806, 0.19175445, 0.26426902],\n",
              "       dtype=float32),\n",
              " array([0.16411977, 0.17703907, 0.18091989, 0.20859146, 0.21770461,\n",
              "        0.2379528 , 0.24980426, 0.2569451 , 0.2584662 , 0.28103074],\n",
              "       dtype=float32),\n",
              " array([0.11193427, 0.16042063, 0.17271926, 0.1778079 , 0.1842457 ,\n",
              "        0.1878842 , 0.20220588, 0.21290478, 0.27085003, 0.28751597],\n",
              "       dtype=float32),\n",
              " array([0.16441771, 0.18440156, 0.19046599, 0.2020888 , 0.21586828,\n",
              "        0.22091585, 0.23234479, 0.2439799 , 0.25900343, 0.28496298],\n",
              "       dtype=float32),\n",
              " array([0.12112657, 0.14803046, 0.18654019, 0.19574422, 0.21206397,\n",
              "        0.21289119, 0.21821494, 0.21925655, 0.23217785, 0.2876779 ],\n",
              "       dtype=float32),\n",
              " array([0.16021375, 0.17266063, 0.17521015, 0.20504716, 0.21525756,\n",
              "        0.219544  , 0.22807124, 0.24068514, 0.2501502 , 0.29119238],\n",
              "       dtype=float32),\n",
              " array([0.11303955, 0.12307032, 0.13203053, 0.17933284, 0.1956937 ,\n",
              "        0.20463853, 0.21353507, 0.22442129, 0.22600248, 0.23579758],\n",
              "       dtype=float32),\n",
              " array([0.14997731, 0.17481466, 0.19509326, 0.21312492, 0.22235824,\n",
              "        0.22981295, 0.2583257 , 0.27281207, 0.2736617 , 0.33418414],\n",
              "       dtype=float32),\n",
              " array([0.16704811, 0.17489165, 0.18124531, 0.21200988, 0.2163802 ,\n",
              "        0.21860312, 0.24171823, 0.2531638 , 0.2537802 , 0.30459568],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.02973634, 0.03900516, 0.04185426, 0.04325962,\n",
              "        0.08353537, 0.09642985, 0.12413561, 0.15762034, 0.21454933],\n",
              "       dtype=float32),\n",
              " array([0.10874055, 0.1139727 , 0.14511815, 0.15937354, 0.17412065,\n",
              "        0.17613545, 0.18908033, 0.19030526, 0.19059448, 0.21305095],\n",
              "       dtype=float32),\n",
              " array([0.29215577, 0.33803797, 0.34181526, 0.34959695, 0.3827112 ,\n",
              "        0.40799236, 0.44230646, 0.45480642, 0.4722701 , 0.53957266],\n",
              "       dtype=float32),\n",
              " array([0.05856121, 0.09464533, 0.09543634, 0.10605952, 0.1244104 ,\n",
              "        0.1302487 , 0.1452137 , 0.1528379 , 0.15403289, 0.18236138],\n",
              "       dtype=float32),\n",
              " array([0.07502522, 0.11159006, 0.11630975, 0.14678767, 0.16379462,\n",
              "        0.22506769, 0.23788445, 0.29728803, 0.3127107 , 0.32516572],\n",
              "       dtype=float32),\n",
              " array([0.14276125, 0.16371721, 0.18138002, 0.22243623, 0.23769079,\n",
              "        0.2381808 , 0.24197851, 0.254558  , 0.26540002, 0.28659686],\n",
              "       dtype=float32),\n",
              " array([0.13753459, 0.17729698, 0.20171641, 0.20605318, 0.24626125,\n",
              "        0.26618668, 0.29565215, 0.3379303 , 0.37653992, 0.42356923],\n",
              "       dtype=float32),\n",
              " array([0.18959084, 0.20344925, 0.20468985, 0.20956853, 0.23659195,\n",
              "        0.24045329, 0.24164557, 0.30443665, 0.316043  , 0.3650842 ],\n",
              "       dtype=float32),\n",
              " array([0.47311008, 0.48400733, 0.52712655, 0.5286079 , 0.57551974,\n",
              "        0.59260225, 0.59336936, 0.6092474 , 0.64681596, 0.6555274 ],\n",
              "       dtype=float32),\n",
              " array([0.3230849 , 0.34515056, 0.34661657, 0.35259023, 0.3632302 ,\n",
              "        0.36875334, 0.3879215 , 0.42843267, 0.45795488, 0.504899  ],\n",
              "       dtype=float32),\n",
              " array([0.21530339, 0.22825958, 0.23574553, 0.25735384, 0.2582629 ,\n",
              "        0.2595295 , 0.26094368, 0.3454912 , 0.36345676, 0.37233672],\n",
              "       dtype=float32),\n",
              " array([0.4880273 , 0.50814265, 0.51920134, 0.5350925 , 0.5498042 ,\n",
              "        0.55386627, 0.6356876 , 0.66120243, 0.6893018 , 0.7006219 ],\n",
              "       dtype=float32),\n",
              " array([0.47311008, 0.48400733, 0.52712655, 0.5286079 , 0.57551974,\n",
              "        0.59260225, 0.59336936, 0.6092474 , 0.64681596, 0.6555274 ],\n",
              "       dtype=float32),\n",
              " array([0.3264732 , 0.34557977, 0.3557677 , 0.36612272, 0.371698  ,\n",
              "        0.37645164, 0.39567566, 0.43705064, 0.44673932, 0.49999738],\n",
              "       dtype=float32),\n",
              " array([0.48661718, 0.5239588 , 0.5448184 , 0.5467739 , 0.54856294,\n",
              "        0.5497883 , 0.65010333, 0.6944753 , 0.6995553 , 0.70355487],\n",
              "       dtype=float32),\n",
              " array([0.56998175, 0.64922017, 0.6508586 , 0.65473086, 0.6663631 ,\n",
              "        0.67217714, 0.72397053, 0.7559891 , 0.7733239 , 0.7865988 ],\n",
              "       dtype=float32),\n",
              " array([0.5237089 , 0.5323332 , 0.5558595 , 0.5805891 , 0.6003764 ,\n",
              "        0.60232335, 0.61945826, 0.63815856, 0.6816594 , 0.74276936],\n",
              "       dtype=float32),\n",
              " array([0.18950568, 0.19259591, 0.21849282, 0.2190083 , 0.22628978,\n",
              "        0.24222584, 0.24489447, 0.29006568, 0.29819265, 0.3416694 ],\n",
              "       dtype=float32),\n",
              " array([0.42163354, 0.4357603 , 0.46311694, 0.47467077, 0.52665037,\n",
              "        0.5450658 , 0.5574702 , 0.57520074, 0.6063231 , 0.6247102 ],\n",
              "       dtype=float32),\n",
              " array([0.47311008, 0.48400733, 0.52712655, 0.5286079 , 0.57551974,\n",
              "        0.59260225, 0.59336936, 0.6092474 , 0.64681596, 0.6555274 ],\n",
              "       dtype=float32),\n",
              " array([0.31461403, 0.31908178, 0.33728954, 0.3406013 , 0.35227942,\n",
              "        0.3619768 , 0.3661298 , 0.40372297, 0.44092152, 0.4981623 ],\n",
              "       dtype=float32),\n",
              " array([0.45364332, 0.48811582, 0.55675226, 0.55757684, 0.59252894,\n",
              "        0.59810305, 0.6318464 , 0.642079  , 0.6479746 , 0.6749834 ],\n",
              "       dtype=float32),\n",
              " array([0.5436022 , 0.60173166, 0.60285336, 0.6119551 , 0.621938  ,\n",
              "        0.646335  , 0.68603194, 0.6925599 , 0.72797596, 0.7479189 ],\n",
              "       dtype=float32),\n",
              " array([0.34437752, 0.3665988 , 0.38417888, 0.39930335, 0.40300155,\n",
              "        0.42178994, 0.4487327 , 0.47573987, 0.49768078, 0.51725394],\n",
              "       dtype=float32),\n",
              " array([0.23975195, 0.2429665 , 0.28536573, 0.2893942 , 0.3073993 ,\n",
              "        0.31971335, 0.32417   , 0.3350328 , 0.34246117, 0.34751275],\n",
              "       dtype=float32),\n",
              " array([0.15616488, 0.18473378, 0.2031855 , 0.20872898, 0.22178754,\n",
              "        0.24285078, 0.2709909 , 0.2723092 , 0.29363453, 0.33900377],\n",
              "       dtype=float32),\n",
              " array([0.05856121, 0.09464533, 0.09543634, 0.10605952, 0.1244104 ,\n",
              "        0.1302487 , 0.1452137 , 0.1528379 , 0.15403289, 0.18236138],\n",
              "       dtype=float32),\n",
              " array([0.18546142, 0.23807842, 0.24306151, 0.2563592 , 0.26581055,\n",
              "        0.28612942, 0.29215688, 0.31535947, 0.32879123, 0.36238816],\n",
              "       dtype=float32),\n",
              " array([0.17636146, 0.18458778, 0.19154374, 0.2001307 , 0.21094958,\n",
              "        0.23362423, 0.24778835, 0.28463888, 0.28976646, 0.30117875],\n",
              "       dtype=float32),\n",
              " array([0.14041568, 0.18016592, 0.18537319, 0.22065553, 0.22730541,\n",
              "        0.27625677, 0.29711345, 0.31439766, 0.3384892 , 0.36459583],\n",
              "       dtype=float32),\n",
              " array([0.15616488, 0.18473378, 0.2031855 , 0.20872898, 0.22178754,\n",
              "        0.24285078, 0.2709909 , 0.2723092 , 0.29363453, 0.33900377],\n",
              "       dtype=float32),\n",
              " array([0.15616488, 0.18473378, 0.2031855 , 0.20872898, 0.22178754,\n",
              "        0.24285078, 0.2709909 , 0.2723092 , 0.29363453, 0.33900377],\n",
              "       dtype=float32),\n",
              " array([0.18419918, 0.22783539, 0.24713601, 0.24749708, 0.26663753,\n",
              "        0.3080009 , 0.31003228, 0.3117593 , 0.33556476, 0.3553457 ],\n",
              "       dtype=float32),\n",
              " array([0.22490042, 0.25437436, 0.27189663, 0.2726559 , 0.28751472,\n",
              "        0.30937514, 0.3295873 , 0.3333835 , 0.34054172, 0.34666356],\n",
              "       dtype=float32),\n",
              " array([0.09594342, 0.1781317 , 0.18645102, 0.19334581, 0.20844667,\n",
              "        0.23606409, 0.25526837, 0.25985742, 0.27655897, 0.27698117],\n",
              "       dtype=float32),\n",
              " array([0.20324545, 0.23231103, 0.2491324 , 0.25258192, 0.28573138,\n",
              "        0.31484297, 0.32144472, 0.33986738, 0.3769049 , 0.37763423],\n",
              "       dtype=float32),\n",
              " array([0.12946236, 0.18541604, 0.19299375, 0.20422526, 0.20590866,\n",
              "        0.23467934, 0.2354145 , 0.26705217, 0.27930057, 0.30524802],\n",
              "       dtype=float32),\n",
              " array([0.06556352, 0.08951735, 0.0902746 , 0.09374291, 0.09479123,\n",
              "        0.09768088, 0.10196934, 0.10522744, 0.11151434, 0.13923931],\n",
              "       dtype=float32),\n",
              " array([0.06803711, 0.08573688, 0.09565276, 0.09615251, 0.10586195,\n",
              "        0.10685367, 0.11529092, 0.12296963, 0.12745845, 0.1404637 ],\n",
              "       dtype=float32),\n",
              " array([0.05836648, 0.05969539, 0.0831416 , 0.08492692, 0.09172148,\n",
              "        0.10151462, 0.1121834 , 0.1142436 , 0.12163345, 0.12428749],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.03689082, 0.04146374, 0.08466323,\n",
              "        0.0877085 , 0.10573569, 0.13179891, 0.14780974, 0.206433  ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.06488566, 0.06983464, 0.08154298, 0.08730763,\n",
              "        0.09299158, 0.10523429, 0.11071112, 0.13693601, 0.15008426],\n",
              "       dtype=float32),\n",
              " array([0.05836648, 0.05969539, 0.0831416 , 0.08492692, 0.09172148,\n",
              "        0.10151462, 0.1121834 , 0.1142436 , 0.12163345, 0.12428749],\n",
              "       dtype=float32),\n",
              " array([0.19333382, 0.19506182, 0.2014209 , 0.20236774, 0.20701443,\n",
              "        0.2089353 , 0.23585571, 0.2377404 , 0.27966973, 0.3330931 ],\n",
              "       dtype=float32),\n",
              " array([0.0157596 , 0.07374678, 0.09410581, 0.09680266, 0.09813481,\n",
              "        0.10941751, 0.11730625, 0.13409543, 0.15735078, 0.16706795],\n",
              "       dtype=float32),\n",
              " array([0.34378627, 0.3466194 , 0.37693268, 0.3852014 , 0.39707062,\n",
              "        0.40668446, 0.45874324, 0.4734585 , 0.54200864, 0.5595708 ],\n",
              "       dtype=float32),\n",
              " array([0.14396359, 0.20166838, 0.20828213, 0.21071173, 0.24385846,\n",
              "        0.26019228, 0.261186  , 0.26353455, 0.27329522, 0.3401608 ],\n",
              "       dtype=float32),\n",
              " array([0.23639585, 0.2667095 , 0.268853  , 0.27659795, 0.29612267,\n",
              "        0.30667543, 0.3129521 , 0.32318464, 0.36694822, 0.46068886],\n",
              "       dtype=float32),\n",
              " array([0.26341724, 0.2664055 , 0.27214018, 0.30423108, 0.31246954,\n",
              "        0.3181647 , 0.32470402, 0.33283022, 0.35039657, 0.39240205],\n",
              "       dtype=float32),\n",
              " array([0.18531103, 0.2068042 , 0.20767188, 0.22158438, 0.22815695,\n",
              "        0.23395741, 0.2393746 , 0.24435014, 0.27279636, 0.35959423],\n",
              "       dtype=float32),\n",
              " array([0.20977874, 0.21246272, 0.21682732, 0.24722064, 0.25742584,\n",
              "        0.25888374, 0.25947168, 0.2599424 , 0.2607382 , 0.34182987],\n",
              "       dtype=float32),\n",
              " array([0.1161043 , 0.15862255, 0.16346869, 0.1796397 , 0.18079926,\n",
              "        0.19401447, 0.20525765, 0.21828009, 0.2185492 , 0.22843425],\n",
              "       dtype=float32),\n",
              " array([0.31480747, 0.318214  , 0.3563567 , 0.36017486, 0.38623127,\n",
              "        0.38696694, 0.40529138, 0.4123243 , 0.42785883, 0.4533345 ],\n",
              "       dtype=float32),\n",
              " array([0.27666932, 0.30708173, 0.3088184 , 0.32592675, 0.34799746,\n",
              "        0.34943578, 0.3903731 , 0.40919527, 0.4347644 , 0.50081426],\n",
              "       dtype=float32),\n",
              " array([0.08799633, 0.1245755 , 0.12850529, 0.13839927, 0.13907586,\n",
              "        0.14841355, 0.15690392, 0.1577108 , 0.16422103, 0.20139042],\n",
              "       dtype=float32),\n",
              " array([0.08799633, 0.1245755 , 0.12850529, 0.13839927, 0.13907586,\n",
              "        0.14841355, 0.15690392, 0.1577108 , 0.16422103, 0.20139042],\n",
              "       dtype=float32),\n",
              " array([0.11156125, 0.14619057, 0.15683642, 0.16618226, 0.17368957,\n",
              "        0.18387747, 0.1922535 , 0.19243121, 0.25706652, 0.34999725],\n",
              "       dtype=float32),\n",
              " array([0.20828797, 0.22480388, 0.26263148, 0.2670894 , 0.28897464,\n",
              "        0.29865646, 0.30197358, 0.32728893, 0.34717125, 0.4681142 ],\n",
              "       dtype=float32),\n",
              " array([0.09541519, 0.10004549, 0.10995199, 0.112647  , 0.11738978,\n",
              "        0.12359919, 0.12820828, 0.13142028, 0.13605382, 0.18326835],\n",
              "       dtype=float32),\n",
              " array([0.36546275, 0.39154038, 0.41010824, 0.42590797, 0.43071175,\n",
              "        0.44025385, 0.48357067, 0.51081663, 0.55801564, 0.56762624],\n",
              "       dtype=float32),\n",
              " array([0.1152511 , 0.12507631, 0.12841922, 0.13865292, 0.14787392,\n",
              "        0.15020998, 0.16298334, 0.16854899, 0.20820838, 0.22194204],\n",
              "       dtype=float32),\n",
              " array([0.09748918, 0.10871508, 0.11142534, 0.1277511 , 0.12884349,\n",
              "        0.13199602, 0.14691429, 0.15160456, 0.1603015 , 0.16672419],\n",
              "       dtype=float32),\n",
              " array([0.07804469, 0.08185279, 0.09231936, 0.10021997, 0.12018191,\n",
              "        0.13001418, 0.13486876, 0.14276962, 0.15781565, 0.16298372],\n",
              "       dtype=float32),\n",
              " array([0.12637244, 0.12639406, 0.13493809, 0.14716755, 0.15019368,\n",
              "        0.16313748, 0.16934736, 0.18209551, 0.1970076 , 0.19985652],\n",
              "       dtype=float32),\n",
              " array([0.13334155, 0.13845497, 0.14255641, 0.16770707, 0.1705948 ,\n",
              "        0.17791645, 0.1834552 , 0.18424979, 0.20026362, 0.20313945],\n",
              "       dtype=float32),\n",
              " array([0.07583714, 0.09099066, 0.10339143, 0.10557009, 0.10879544,\n",
              "        0.11540902, 0.11558535, 0.12437885, 0.12850133, 0.13972779],\n",
              "       dtype=float32),\n",
              " array([0.14041102, 0.14708097, 0.14925852, 0.15696001, 0.18138796,\n",
              "        0.19381852, 0.20298958, 0.20716728, 0.21601215, 0.22359107],\n",
              "       dtype=float32),\n",
              " array([0.34221277, 0.37222156, 0.37853643, 0.40050128, 0.4252813 ,\n",
              "        0.51087475, 0.5150193 , 0.5289422 , 0.5372463 , 0.57768387],\n",
              "       dtype=float32),\n",
              " array([0.09541519, 0.10004549, 0.10995199, 0.112647  , 0.11738978,\n",
              "        0.12359919, 0.12820828, 0.13142028, 0.13605382, 0.18326835],\n",
              "       dtype=float32),\n",
              " array([0.07916655, 0.08710389, 0.11431451, 0.11683404, 0.12632048,\n",
              "        0.12941484, 0.13771127, 0.15421364, 0.15751639, 0.19122335],\n",
              "       dtype=float32),\n",
              " array([0.10268316, 0.11442728, 0.12233957, 0.12243044, 0.14421286,\n",
              "        0.15744685, 0.15882933, 0.16250356, 0.17100453, 0.19939446],\n",
              "       dtype=float32),\n",
              " array([0.12324425, 0.13035275, 0.13281539, 0.1409664 , 0.14472783,\n",
              "        0.14902994, 0.1623765 , 0.16570385, 0.1675849 , 0.22100607],\n",
              "       dtype=float32),\n",
              " array([0.11313216, 0.13222289, 0.14166406, 0.15532218, 0.17276934,\n",
              "        0.18835932, 0.18916786, 0.19983716, 0.20078719, 0.24166094],\n",
              "       dtype=float32),\n",
              " array([0.12989514, 0.13319059, 0.15376419, 0.16276018, 0.16663998,\n",
              "        0.16850129, 0.16962142, 0.1716091 , 0.1929021 , 0.21505702],\n",
              "       dtype=float32),\n",
              " array([0.1225858 , 0.12922812, 0.13043016, 0.13548827, 0.1361855 ,\n",
              "        0.15827087, 0.16100968, 0.17094032, 0.20328213, 0.20864469],\n",
              "       dtype=float32),\n",
              " array([0.11313216, 0.13222289, 0.14166406, 0.15532218, 0.17276934,\n",
              "        0.18835932, 0.18916786, 0.19983716, 0.20078719, 0.24166094],\n",
              "       dtype=float32),\n",
              " array([0.11239262, 0.12544799, 0.13288192, 0.15856451, 0.16197328,\n",
              "        0.16778956, 0.1715031 , 0.18742764, 0.20543517, 0.24612112],\n",
              "       dtype=float32),\n",
              " array([0.1095145 , 0.11435261, 0.12367755, 0.1552387 , 0.16073625,\n",
              "        0.16363947, 0.1664737 , 0.18844217, 0.1979043 , 0.24410923],\n",
              "       dtype=float32),\n",
              " array([0.48377988, 0.5139347 , 0.5322559 , 0.55730677, 0.59377635,\n",
              "        0.61040044, 0.65095294, 0.6788908 , 0.7008108 , 0.7021959 ],\n",
              "       dtype=float32),\n",
              " array([0.3979332 , 0.41536686, 0.42304194, 0.4288573 , 0.45027855,\n",
              "        0.461209  , 0.5047024 , 0.5416575 , 0.55933887, 0.5672205 ],\n",
              "       dtype=float32),\n",
              " array([0.14651652, 0.17953214, 0.18309909, 0.18738876, 0.20753363,\n",
              "        0.21491376, 0.21584772, 0.25688878, 0.26854053, 0.28815317],\n",
              "       dtype=float32),\n",
              " array([0.12324425, 0.13035275, 0.13281539, 0.1409664 , 0.14472783,\n",
              "        0.14902994, 0.1623765 , 0.16570385, 0.1675849 , 0.22100607],\n",
              "       dtype=float32),\n",
              " array([0.14346024, 0.14657083, 0.1504967 , 0.15361588, 0.15420535,\n",
              "        0.15624723, 0.17217156, 0.1756025 , 0.18590657, 0.32776022],\n",
              "       dtype=float32),\n",
              " array([0.14346024, 0.14657083, 0.1504967 , 0.15361588, 0.15420535,\n",
              "        0.15624723, 0.17217156, 0.1756025 , 0.18590657, 0.32776022],\n",
              "       dtype=float32),\n",
              " array([0.15648308, 0.17952242, 0.18068194, 0.18950425, 0.19117081,\n",
              "        0.20596685, 0.20970331, 0.2177006 , 0.2289583 , 0.24127962],\n",
              "       dtype=float32),\n",
              " array([0.15854444, 0.1598531 , 0.16377085, 0.1723123 , 0.18181872,\n",
              "        0.18820839, 0.1885743 , 0.19522211, 0.21000431, 0.2971802 ],\n",
              "       dtype=float32),\n",
              " array([0.13494651, 0.15329936, 0.15406984, 0.15524511, 0.15811573,\n",
              "        0.16156864, 0.17328455, 0.17620726, 0.19343963, 0.22464554],\n",
              "       dtype=float32),\n",
              " array([0.25531715, 0.28328806, 0.2956193 , 0.3128081 , 0.31356606,\n",
              "        0.3172415 , 0.335948  , 0.3373655 , 0.35217723, 0.4300391 ],\n",
              "       dtype=float32),\n",
              " array([0.16374731, 0.17037196, 0.1755927 , 0.1782546 , 0.1879268 ,\n",
              "        0.20209093, 0.21107301, 0.22023988, 0.22914891, 0.22938037],\n",
              "       dtype=float32),\n",
              " array([0.13430226, 0.16667399, 0.1714943 , 0.17485803, 0.17822951,\n",
              "        0.19429137, 0.19922876, 0.20477703, 0.20575216, 0.21174182],\n",
              "       dtype=float32),\n",
              " array([0.1255268 , 0.13157187, 0.14970492, 0.1501578 , 0.1512073 ,\n",
              "        0.1530771 , 0.15689364, 0.18126786, 0.18988664, 0.21230344],\n",
              "       dtype=float32),\n",
              " array([0.17158955, 0.1735106 , 0.17459978, 0.17654376, 0.1827011 ,\n",
              "        0.21624348, 0.2238069 , 0.2282888 , 0.2302515 , 0.265582  ],\n",
              "       dtype=float32),\n",
              " array([0.16124442, 0.16504069, 0.17065144, 0.17170501, 0.17276181,\n",
              "        0.17912403, 0.19793853, 0.21519336, 0.22000574, 0.22901663],\n",
              "       dtype=float32),\n",
              " array([0.07500968, 0.08993829, 0.09254989, 0.0928529 , 0.09299447,\n",
              "        0.1013132 , 0.10878897, 0.10960634, 0.11737529, 0.12886614],\n",
              "       dtype=float32),\n",
              " array([0.07285149, 0.07504631, 0.07565486, 0.07741683, 0.08146838,\n",
              "        0.08186429, 0.08426531, 0.08611451, 0.09120015, 0.09621945],\n",
              "       dtype=float32),\n",
              " array([0.16671842, 0.1750059 , 0.18380661, 0.18792559, 0.21467613,\n",
              "        0.22342853, 0.23205777, 0.23343092, 0.25809056, 0.26190862],\n",
              "       dtype=float32),\n",
              " array([0.07907704, 0.08922614, 0.10237084, 0.10386561, 0.10477532,\n",
              "        0.10488252, 0.10810481, 0.10917141, 0.12129758, 0.12207524],\n",
              "       dtype=float32),\n",
              " array([0.03221704, 0.03835214, 0.04993146, 0.05679497, 0.05861067,\n",
              "        0.06627212, 0.07011268, 0.08160821, 0.09759653, 0.10883375],\n",
              "       dtype=float32),\n",
              " array([0.04655002, 0.0574474 , 0.06033842, 0.06333775, 0.07215254,\n",
              "        0.0747368 , 0.07787618, 0.08257518, 0.08476295, 0.09379656],\n",
              "       dtype=float32),\n",
              " array([0.07332568, 0.08210749, 0.08401111, 0.0854599 , 0.08733783,\n",
              "        0.09076899, 0.09364556, 0.0948897 , 0.10512889, 0.11334178],\n",
              "       dtype=float32),\n",
              " array([0.0611777 , 0.06768434, 0.07342971, 0.07520358, 0.07556613,\n",
              "        0.07781377, 0.07979087, 0.08318251, 0.09982931, 0.1014244 ],\n",
              "       dtype=float32),\n",
              " array([0.03166708, 0.0468766 , 0.04980316, 0.05550522, 0.06506414,\n",
              "        0.06524383, 0.07781559, 0.08735693, 0.10484272, 0.10838076],\n",
              "       dtype=float32),\n",
              " array([0.07061358, 0.07941078, 0.09397275, 0.10085092, 0.12073251,\n",
              "        0.13006996, 0.1352054 , 0.13550834, 0.17758305, 0.17782426],\n",
              "       dtype=float32),\n",
              " array([0.04917896, 0.07247986, 0.07543097, 0.07846878, 0.11757286,\n",
              "        0.11843772, 0.12405113, 0.13398859, 0.16516338, 0.17314062],\n",
              "       dtype=float32),\n",
              " array([0.01940355, 0.0211943 , 0.08098564, 0.08669288, 0.10972813,\n",
              "        0.11434704, 0.13051744, 0.139579  , 0.14052851, 0.14586672],\n",
              "       dtype=float32),\n",
              " array([0.02745848, 0.06057968, 0.06353236, 0.08880709, 0.11267334,\n",
              "        0.1246184 , 0.13554557, 0.14316751, 0.17147325, 0.17646486],\n",
              "       dtype=float32),\n",
              " array([0.12885503, 0.13236181, 0.1353096 , 0.15127271, 0.15631199,\n",
              "        0.18130465, 0.19429404, 0.20002587, 0.20010431, 0.20013307],\n",
              "       dtype=float32),\n",
              " array([0.09807457, 0.09858027, 0.10488391, 0.1251092 , 0.1295008 ,\n",
              "        0.13885748, 0.15468068, 0.15483874, 0.16713808, 0.23715974],\n",
              "       dtype=float32),\n",
              " array([0.06466332, 0.08731268, 0.13236207, 0.13505787, 0.13538356,\n",
              "        0.14738016, 0.19526595, 0.2031555 , 0.20876326, 0.21399775],\n",
              "       dtype=float32),\n",
              " array([0.11191847, 0.12692568, 0.13204984, 0.15694223, 0.17517717,\n",
              "        0.17927979, 0.1850866 , 0.19255811, 0.22094075, 0.24643813],\n",
              "       dtype=float32),\n",
              " array([0.01662663, 0.06253311, 0.08206875, 0.08217676, 0.08369797,\n",
              "        0.08603269, 0.1368645 , 0.14513865, 0.15247756, 0.17507596],\n",
              "       dtype=float32),\n",
              " array([0.11441282, 0.12529464, 0.12988001, 0.13479967, 0.15222359,\n",
              "        0.15590647, 0.15983729, 0.1648816 , 0.16812018, 0.19914825],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.01942317, 0.02865641, 0.04145804, 0.08004837, 0.1222363 ],\n",
              "       dtype=float32),\n",
              " array([0.06466178, 0.09275389, 0.10183879, 0.10779127, 0.12548365,\n",
              "        0.12671603, 0.12859932, 0.13777189, 0.1698481 , 0.2427067 ],\n",
              "       dtype=float32),\n",
              " array([0.07057603, 0.0745343 , 0.09339024, 0.10524701, 0.12158438,\n",
              "        0.14430082, 0.14763294, 0.1625353 , 0.17926963, 0.18250252],\n",
              "       dtype=float32),\n",
              " array([0.10308882, 0.10575764, 0.10909737, 0.11254219, 0.11507487,\n",
              "        0.11854757, 0.12578703, 0.1354991 , 0.13660574, 0.1624565 ],\n",
              "       dtype=float32),\n",
              " array([0.06413436, 0.06729174, 0.06807525, 0.07204323, 0.07772888,\n",
              "        0.09140746, 0.09502953, 0.11154591, 0.11323521, 0.14049345],\n",
              "       dtype=float32),\n",
              " array([0.08271825, 0.09724894, 0.10786119, 0.108303  , 0.11639215,\n",
              "        0.1212877 , 0.144203  , 0.14861134, 0.16242278, 0.19118224],\n",
              "       dtype=float32),\n",
              " array([0.08207627, 0.08546234, 0.08893717, 0.09355219, 0.10413818,\n",
              "        0.10550923, 0.11075883, 0.11438027, 0.12610626, 0.12796728],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.01942317, 0.02865641, 0.04145804, 0.08004837, 0.1222363 ],\n",
              "       dtype=float32),\n",
              " array([0.12228303, 0.12256353, 0.12295787, 0.13142891, 0.13557312,\n",
              "        0.13748617, 0.14707619, 0.15093857, 0.16490465, 0.17626533],\n",
              "       dtype=float32),\n",
              " array([0.06592318, 0.07055703, 0.0725934 , 0.07418984, 0.08295447,\n",
              "        0.09437209, 0.09720104, 0.10657054, 0.11723273, 0.14439227],\n",
              "       dtype=float32),\n",
              " array([0.08736885, 0.09045554, 0.09218553, 0.10104015, 0.10314494,\n",
              "        0.10373589, 0.10530204, 0.12372051, 0.13700409, 0.14001735],\n",
              "       dtype=float32),\n",
              " array([0.09352333, 0.11068329, 0.11851016, 0.12061309, 0.12560332,\n",
              "        0.12998451, 0.13193974, 0.15139438, 0.15504138, 0.17498922],\n",
              "       dtype=float32),\n",
              " array([0.06832679, 0.06900521, 0.07539132, 0.07935481, 0.08640986,\n",
              "        0.09104183, 0.10108334, 0.10680645, 0.12002254, 0.13315359],\n",
              "       dtype=float32),\n",
              " array([0.11278346, 0.11728211, 0.11766451, 0.12223907, 0.1225722 ,\n",
              "        0.13089323, 0.13343535, 0.14077128, 0.14339094, 0.1661683 ],\n",
              "       dtype=float32),\n",
              " array([0.05693837, 0.09348641, 0.09516559, 0.12066004, 0.14557599,\n",
              "        0.20527394, 0.20824023, 0.23277186, 0.2955812 , 0.30744243],\n",
              "       dtype=float32),\n",
              " array([0.02258263, 0.1030535 , 0.10597461, 0.12260215, 0.12426498,\n",
              "        0.1286362 , 0.13079642, 0.13123173, 0.13236967, 0.16130307],\n",
              "       dtype=float32),\n",
              " array([0.02659172, 0.08133695, 0.09581514, 0.10483976, 0.10498545,\n",
              "        0.10828108, 0.10982706, 0.1396094 , 0.15395014, 0.20478705],\n",
              "       dtype=float32),\n",
              " array([0.02288227, 0.11277266, 0.11732183, 0.11848241, 0.12498979,\n",
              "        0.12967256, 0.1324894 , 0.13986564, 0.1431565 , 0.15640815],\n",
              "       dtype=float32),\n",
              " array([0.10434197, 0.1506886 , 0.16025713, 0.16738647, 0.16754344,\n",
              "        0.19069102, 0.19355054, 0.19913614, 0.24346606, 0.24848405],\n",
              "       dtype=float32),\n",
              " array([0.07362619, 0.1490892 , 0.15705521, 0.16206262, 0.1647384 ,\n",
              "        0.17838378, 0.17844976, 0.18390499, 0.20251551, 0.2348678 ],\n",
              "       dtype=float32),\n",
              " array([0.12131713, 0.12742828, 0.12828599, 0.12960157, 0.13078153,\n",
              "        0.13516189, 0.14910646, 0.15165055, 0.15641949, 0.19626871],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.01942317, 0.02865641, 0.04145804, 0.08004837, 0.1222363 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.0521477 , 0.07848255, 0.07894305, 0.08220674,\n",
              "        0.10230234, 0.10337259, 0.10456184, 0.1295213 , 0.1950725 ],\n",
              "       dtype=float32),\n",
              " array([0.02659172, 0.08133695, 0.09581514, 0.10483976, 0.10498545,\n",
              "        0.10828108, 0.10982706, 0.1396094 , 0.15395014, 0.20478705],\n",
              "       dtype=float32),\n",
              " array([0.10434197, 0.1506886 , 0.16025713, 0.16738647, 0.16754344,\n",
              "        0.19069102, 0.19355054, 0.19913614, 0.24346606, 0.24848405],\n",
              "       dtype=float32),\n",
              " array([0.11058604, 0.11512755, 0.13526507, 0.13573076, 0.14467296,\n",
              "        0.15474173, 0.1588424 , 0.1958661 , 0.20613062, 0.2579576 ],\n",
              "       dtype=float32),\n",
              " array([0.06528036, 0.11234162, 0.11688265, 0.136396  , 0.14558701,\n",
              "        0.14682207, 0.16450134, 0.1645306 , 0.17275755, 0.17669722],\n",
              "       dtype=float32),\n",
              " array([0.12876222, 0.15140054, 0.166472  , 0.1699653 , 0.19392347,\n",
              "        0.19830127, 0.21326792, 0.21784647, 0.21817103, 0.29892215],\n",
              "       dtype=float32),\n",
              " array([0.10003214, 0.13561623, 0.15367155, 0.16458432, 0.17866775,\n",
              "        0.19963697, 0.21141714, 0.21162364, 0.32353133, 0.33605835],\n",
              "       dtype=float32),\n",
              " array([0.36395827, 0.37869102, 0.45285088, 0.4567552 , 0.46332517,\n",
              "        0.47326317, 0.4922184 , 0.49995732, 0.50440353, 0.5178369 ],\n",
              "       dtype=float32),\n",
              " array([0.11450102, 0.11498075, 0.1261845 , 0.1269118 , 0.1271875 ,\n",
              "        0.13007022, 0.14532486, 0.17091009, 0.17420523, 0.21112204],\n",
              "       dtype=float32),\n",
              " array([0.0369662 , 0.04401831, 0.10784427, 0.1134029 , 0.13079208,\n",
              "        0.13113156, 0.1375351 , 0.14018412, 0.14186338, 0.1714723 ],\n",
              "       dtype=float32),\n",
              " array([0.11551499, 0.11723144, 0.16399372, 0.2198845 , 0.23184446,\n",
              "        0.23398577, 0.2534996 , 0.2600922 , 0.33614063, 0.3628101 ],\n",
              "       dtype=float32),\n",
              " array([0.11450102, 0.11498075, 0.1261845 , 0.1269118 , 0.1271875 ,\n",
              "        0.13007022, 0.14532486, 0.17091009, 0.17420523, 0.21112204],\n",
              "       dtype=float32),\n",
              " array([0.09995015, 0.14074509, 0.15026626, 0.17382875, 0.19734979,\n",
              "        0.19776572, 0.20449348, 0.2114892 , 0.30879736, 0.32426533],\n",
              "       dtype=float32),\n",
              " array([0.11474829, 0.118433  , 0.13512039, 0.14251514, 0.15135834,\n",
              "        0.18783729, 0.1951042 , 0.19652343, 0.23048867, 0.2420187 ],\n",
              "       dtype=float32),\n",
              " array([0.11747343, 0.1281965 , 0.1437925 , 0.15604913, 0.16799898,\n",
              "        0.17276667, 0.1741361 , 0.20789166, 0.22865073, 0.23749255],\n",
              "       dtype=float32),\n",
              " array([0.34649342, 0.3750298 , 0.38544998, 0.4004258 , 0.4452152 ,\n",
              "        0.45377123, 0.46026003, 0.50591654, 0.5201384 , 0.5389049 ],\n",
              "       dtype=float32),\n",
              " array([0.12076676, 0.13051091, 0.13278489, 0.1365174 , 0.16868128,\n",
              "        0.17109008, 0.18181415, 0.18597825, 0.18932337, 0.2264919 ],\n",
              "       dtype=float32),\n",
              " array([0.10425076, 0.13289502, 0.13768777, 0.1378062 , 0.14812319,\n",
              "        0.1488636 , 0.16790633, 0.16981007, 0.20788845, 0.30720654],\n",
              "       dtype=float32),\n",
              " array([0.11052871, 0.12222608, 0.1309232 , 0.13253486, 0.16391444,\n",
              "        0.16716044, 0.19326887, 0.20094393, 0.20951971, 0.21787487],\n",
              "       dtype=float32),\n",
              " array([0.14294277, 0.14897351, 0.1510484 , 0.15165949, 0.1553457 ,\n",
              "        0.15630548, 0.15848607, 0.16670349, 0.1696462 , 0.21534829],\n",
              "       dtype=float32),\n",
              " array([0.13935238, 0.14474219, 0.14746223, 0.14770204, 0.15839893,\n",
              "        0.15852071, 0.16708294, 0.17038192, 0.18388571, 0.20481102],\n",
              "       dtype=float32),\n",
              " array([0.13297047, 0.1338115 , 0.13913065, 0.15719402, 0.17535506,\n",
              "        0.19494379, 0.20793194, 0.2142986 , 0.21554141, 0.2534267 ],\n",
              "       dtype=float32),\n",
              " array([0.50526637, 0.57772297, 0.58637047, 0.5893672 , 0.6204893 ,\n",
              "        0.6379574 , 0.6968517 , 0.6971014 , 0.7089285 , 0.73577267],\n",
              "       dtype=float32),\n",
              " array([0.6293805 , 0.6446383 , 0.71156114, 0.7264274 , 0.7524854 ,\n",
              "        0.8078884 , 0.80959415, 0.87986934, 0.9092626 , 0.9265263 ],\n",
              "       dtype=float32),\n",
              " array([0.11052871, 0.12222608, 0.1309232 , 0.13253486, 0.16391444,\n",
              "        0.16716044, 0.19326887, 0.20094393, 0.20951971, 0.21787487],\n",
              "       dtype=float32),\n",
              " array([0.09763499, 0.11941835, 0.1342033 , 0.13548183, 0.14285533,\n",
              "        0.16611624, 0.19880551, 0.20357944, 0.21980935, 0.24019332],\n",
              "       dtype=float32),\n",
              " array([0.10211015, 0.1324631 , 0.14379975, 0.14683367, 0.15002148,\n",
              "        0.15025961, 0.15434575, 0.15865713, 0.1621748 , 0.20206752],\n",
              "       dtype=float32),\n",
              " array([0.10541377, 0.11226997, 0.12987202, 0.14210519, 0.15181994,\n",
              "        0.16258857, 0.17735057, 0.2200248 , 0.22261956, 0.23179927],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.29603526, 0.3199168 , 0.36696586, 0.37349564, 0.43678612,\n",
              "        0.4551463 , 0.45764703, 0.47390532, 0.5240381 , 0.55101365],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.2445534 , 0.25771883, 0.26724645, 0.33070865, 0.38219747,\n",
              "        0.4039183 , 0.41456324, 0.43490353, 0.45219913, 0.5520804 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.26576936, 0.2916147 , 0.2932959 , 0.31316033, 0.35259145,\n",
              "        0.35508275, 0.37551907, 0.42552918, 0.44156864, 0.4672416 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.13412078, 0.17802128, 0.18929215, 0.20034038, 0.23526965,\n",
              "        0.24568556, 0.26312563, 0.31272948, 0.3257679 , 0.34291753],\n",
              "       dtype=float32),\n",
              " array([0.12552108, 0.15439996, 0.17650026, 0.17776354, 0.18664277,\n",
              "        0.18682498, 0.19876638, 0.20358276, 0.20468692, 0.21947695],\n",
              "       dtype=float32),\n",
              " array([0.15048128, 0.15601556, 0.16673192, 0.17984985, 0.18914522,\n",
              "        0.19291605, 0.21043633, 0.21468596, 0.2214138 , 0.2293735 ],\n",
              "       dtype=float32),\n",
              " array([0.18105102, 0.20053765, 0.21076661, 0.25982955, 0.27308038,\n",
              "        0.30892605, 0.3183567 , 0.3922843 , 0.44339418, 0.45484465],\n",
              "       dtype=float32),\n",
              " array([0.6628724 , 0.6669633 , 0.6788336 , 0.69236445, 0.7039559 ,\n",
              "        0.7140095 , 0.734781  , 0.742298  , 0.8040657 , 0.8439209 ],\n",
              "       dtype=float32),\n",
              " array([0.13412078, 0.17802128, 0.18929215, 0.20034038, 0.23526965,\n",
              "        0.24568556, 0.26312563, 0.31272948, 0.3257679 , 0.34291753],\n",
              "       dtype=float32),\n",
              " array([0.15027647, 0.16784213, 0.1700242 , 0.17605287, 0.18965286,\n",
              "        0.1953026 , 0.21397634, 0.2189502 , 0.23465775, 0.25170845],\n",
              "       dtype=float32),\n",
              " array([0.12311979, 0.15126514, 0.15626287, 0.16037229, 0.16673344,\n",
              "        0.16878307, 0.18487646, 0.18928424, 0.21945842, 0.2234218 ],\n",
              "       dtype=float32),\n",
              " array([0.16890448, 0.20411211, 0.2639879 , 0.2707173 , 0.27726382,\n",
              "        0.2853106 , 0.31565148, 0.3256955 , 0.34437087, 0.35462886],\n",
              "       dtype=float32),\n",
              " array([0.13567679, 0.1561046 , 0.16180538, 0.17202942, 0.20026773,\n",
              "        0.20125745, 0.20434952, 0.2166894 , 0.22629133, 0.2507517 ],\n",
              "       dtype=float32),\n",
              " array([0.16770442, 0.201145  , 0.20292485, 0.24234386, 0.25407228,\n",
              "        0.2541087 , 0.266494  , 0.29397902, 0.30677375, 0.32326722],\n",
              "       dtype=float32),\n",
              " array([0.11639179, 0.14782304, 0.1755234 , 0.20207822, 0.21807395,\n",
              "        0.22828619, 0.23133981, 0.25139904, 0.25888714, 0.31213224],\n",
              "       dtype=float32),\n",
              " array([0.16890448, 0.20411211, 0.2639879 , 0.2707173 , 0.27726382,\n",
              "        0.2853106 , 0.31565148, 0.3256955 , 0.34437087, 0.35462886],\n",
              "       dtype=float32),\n",
              " array([0.70839   , 0.71457636, 0.7238579 , 0.7585582 , 0.76162946,\n",
              "        0.7667548 , 0.8313999 , 0.8915487 , 0.9447568 , 0.9464337 ],\n",
              "       dtype=float32),\n",
              " array([0.16987446, 0.20642276, 0.21490626, 0.22539467, 0.24933627,\n",
              "        0.24968292, 0.25716403, 0.2639308 , 0.2761076 , 0.31137696],\n",
              "       dtype=float32),\n",
              " array([0.14391276, 0.16864464, 0.18633863, 0.19510086, 0.19556604,\n",
              "        0.19808893, 0.20006868, 0.20313828, 0.22554463, 0.2597252 ],\n",
              "       dtype=float32),\n",
              " array([0.13357583, 0.1481017 , 0.15270941, 0.15620717, 0.1657127 ,\n",
              "        0.1796841 , 0.19485936, 0.19727232, 0.20625728, 0.21232587],\n",
              "       dtype=float32),\n",
              " array([0.15641779, 0.16631933, 0.17576109, 0.18216032, 0.20830674,\n",
              "        0.20914437, 0.22105996, 0.23500253, 0.25150654, 0.30715185],\n",
              "       dtype=float32),\n",
              " array([0.17124191, 0.17266193, 0.17734286, 0.18699022, 0.18836683,\n",
              "        0.21675555, 0.217662  , 0.23320352, 0.2457957 , 0.24721956],\n",
              "       dtype=float32),\n",
              " array([0.12836315, 0.13192838, 0.15117678, 0.16325034, 0.17639947,\n",
              "        0.18847209, 0.19303675, 0.19667852, 0.20663317, 0.21005774],\n",
              "       dtype=float32),\n",
              " array([0.15879133, 0.17454375, 0.1895187 , 0.2033164 , 0.21218859,\n",
              "        0.25102058, 0.25909874, 0.26411426, 0.26447985, 0.27807155],\n",
              "       dtype=float32),\n",
              " array([0.08305629, 0.10133125, 0.10463521, 0.10589869, 0.12900165,\n",
              "        0.12987913, 0.1392096 , 0.14017713, 0.18249021, 0.19107307],\n",
              "       dtype=float32),\n",
              " array([0.6412328 , 0.71645397, 0.716469  , 0.7222924 , 0.7266394 ,\n",
              "        0.73444444, 0.7675188 , 0.8465975 , 0.8791172 , 0.9569973 ],\n",
              "       dtype=float32),\n",
              " array([0.1516298 , 0.16815823, 0.17434728, 0.18664078, 0.19539559,\n",
              "        0.19910909, 0.19919075, 0.22389245, 0.22877878, 0.2617159 ],\n",
              "       dtype=float32),\n",
              " array([0.16741374, 0.1681899 , 0.17150204, 0.18331012, 0.1866501 ,\n",
              "        0.20505227, 0.21302237, 0.23083033, 0.23136657, 0.23962528],\n",
              "       dtype=float32),\n",
              " array([0.06929693, 0.08601957, 0.08739949, 0.09686036, 0.10317662,\n",
              "        0.12227096, 0.12626131, 0.12646058, 0.17312333, 0.18664783],\n",
              "       dtype=float32),\n",
              " array([0.16245121, 0.17018692, 0.18832621, 0.19667235, 0.20172663,\n",
              "        0.20685686, 0.22843087, 0.23089974, 0.23901589, 0.2590184 ],\n",
              "       dtype=float32),\n",
              " array([0.06929693, 0.08601957, 0.08739949, 0.09686036, 0.10317662,\n",
              "        0.12227096, 0.12626131, 0.12646058, 0.17312333, 0.18664783],\n",
              "       dtype=float32),\n",
              " array([0.16388223, 0.17191708, 0.17385575, 0.1926979 , 0.19485554,\n",
              "        0.21757348, 0.21897545, 0.24292599, 0.24466945, 0.26013947],\n",
              "       dtype=float32),\n",
              " array([0.20275655, 0.22193292, 0.23374821, 0.29070023, 0.32706243,\n",
              "        0.32828143, 0.34943566, 0.36505887, 0.39046994, 0.41588438],\n",
              "       dtype=float32),\n",
              " array([0.6962413 , 0.7126839 , 0.7174507 , 0.73157865, 0.74401546,\n",
              "        0.765604  , 0.7846073 , 0.8071986 , 0.8510092 , 0.89048356],\n",
              "       dtype=float32),\n",
              " array([0.20950778, 0.26193404, 0.26271492, 0.29144526, 0.33163193,\n",
              "        0.37981573, 0.40367565, 0.41780066, 0.4178444 , 0.42765325],\n",
              "       dtype=float32),\n",
              " array([0.25640923, 0.2934298 , 0.33793357, 0.35403636, 0.39003977,\n",
              "        0.4070294 , 0.4178814 , 0.42457685, 0.43178755, 0.51029927],\n",
              "       dtype=float32),\n",
              " array([0.29032186, 0.30928916, 0.3253659 , 0.36778608, 0.37905517,\n",
              "        0.3791479 , 0.3982555 , 0.40201178, 0.4511716 , 0.50246775],\n",
              "       dtype=float32),\n",
              " array([0.2011215 , 0.24080236, 0.2432794 , 0.27655166, 0.3049942 ,\n",
              "        0.3381269 , 0.3391642 , 0.34894505, 0.3898412 , 0.41069797],\n",
              "       dtype=float32),\n",
              " array([0.27859828, 0.30258653, 0.3713204 , 0.38701618, 0.3968908 ,\n",
              "        0.42139482, 0.43013778, 0.44079843, 0.44377762, 0.5182339 ],\n",
              "       dtype=float32),\n",
              " array([0.2406466 , 0.26541924, 0.28626326, 0.34104165, 0.37518054,\n",
              "        0.388312  , 0.39529148, 0.41181955, 0.43000472, 0.44802043],\n",
              "       dtype=float32),\n",
              " array([0.33716848, 0.35506764, 0.35650408, 0.37405524, 0.38347062,\n",
              "        0.39591232, 0.3997809 , 0.422951  , 0.44799137, 0.5011814 ],\n",
              "       dtype=float32),\n",
              " array([0.10153097, 0.11573631, 0.12271605, 0.12571391, 0.12663326,\n",
              "        0.1297709 , 0.1335904 , 0.14905445, 0.15064274, 0.15760064],\n",
              "       dtype=float32),\n",
              " array([0.6808167 , 0.7272338 , 0.7454513 , 0.7458851 , 0.75039726,\n",
              "        0.81001455, 0.8216169 , 0.84073293, 0.84647113, 0.8953747 ],\n",
              "       dtype=float32),\n",
              " array([0.09679299, 0.12040137, 0.12523799, 0.12883718, 0.13845272,\n",
              "        0.14572406, 0.14695278, 0.15169026, 0.15218799, 0.15980719],\n",
              "       dtype=float32),\n",
              " array([0.12824076, 0.13109487, 0.13333003, 0.15788767, 0.15892442,\n",
              "        0.1818614 , 0.18506342, 0.19075897, 0.20961633, 0.21141516],\n",
              "       dtype=float32),\n",
              " array([0.15278552, 0.15453462, 0.15838227, 0.17918259, 0.18503629,\n",
              "        0.19388278, 0.21730152, 0.22742033, 0.24176003, 0.24906261],\n",
              "       dtype=float32),\n",
              " array([0.09569858, 0.12476421, 0.12877312, 0.1307667 , 0.13130662,\n",
              "        0.13233672, 0.13962264, 0.15450506, 0.15690018, 0.19900075],\n",
              "       dtype=float32),\n",
              " array([0.13169314, 0.13775122, 0.13851939, 0.14217108, 0.15860698,\n",
              "        0.15877186, 0.16242535, 0.17663881, 0.18577582, 0.19271772],\n",
              "       dtype=float32),\n",
              " array([0.13113537, 0.14478044, 0.15847169, 0.17496468, 0.19150728,\n",
              "        0.19187792, 0.192091  , 0.20574808, 0.2125219 , 0.21357481],\n",
              "       dtype=float32),\n",
              " array([0.08542092, 0.0901509 , 0.09719674, 0.1079894 , 0.10883661,\n",
              "        0.11772595, 0.11984548, 0.12383093, 0.12788886, 0.15642273],\n",
              "       dtype=float32),\n",
              " array([0.11685203, 0.11745519, 0.12618448, 0.12629327, 0.12948196,\n",
              "        0.13261728, 0.14951672, 0.15349317, 0.15649135, 0.16944638],\n",
              "       dtype=float32),\n",
              " array([0.13169314, 0.13775122, 0.13851939, 0.14217108, 0.15860698,\n",
              "        0.15877186, 0.16242535, 0.17663881, 0.18577582, 0.19271772],\n",
              "       dtype=float32),\n",
              " array([0.6682364 , 0.68787575, 0.74040115, 0.75394195, 0.7616458 ,\n",
              "        0.7719099 , 0.7892481 , 0.83231765, 0.9274387 , 0.92942   ],\n",
              "       dtype=float32),\n",
              " array([0.42978895, 0.43589115, 0.4699202 , 0.4951833 , 0.50610185,\n",
              "        0.52024364, 0.5405203 , 0.5460079 , 0.5489061 , 0.6324148 ],\n",
              "       dtype=float32),\n",
              " array([0.33425248, 0.38309726, 0.3975819 , 0.4182578 , 0.4397278 ,\n",
              "        0.4422161 , 0.4457326 , 0.46903062, 0.49159718, 0.58194757],\n",
              "       dtype=float32),\n",
              " array([0.35465094, 0.38237417, 0.40045518, 0.42197135, 0.4569682 ,\n",
              "        0.4786984 , 0.5395448 , 0.5436605 , 0.5484167 , 0.5671571 ],\n",
              "       dtype=float32),\n",
              " array([0.27082232, 0.28610185, 0.3227263 , 0.3264306 , 0.37222803,\n",
              "        0.39009154, 0.39197853, 0.44039634, 0.45927784, 0.4707977 ],\n",
              "       dtype=float32),\n",
              " array([0.39342472, 0.3961823 , 0.40306044, 0.41641754, 0.4362133 ,\n",
              "        0.4797074 , 0.48968872, 0.5027242 , 0.5383506 , 0.5836783 ],\n",
              "       dtype=float32),\n",
              " array([0.13460447, 0.16460434, 0.19038816, 0.19067067, 0.19147484,\n",
              "        0.21306151, 0.21348849, 0.21690063, 0.2393765 , 0.25541958],\n",
              "       dtype=float32),\n",
              " array([0.11017233, 0.16112307, 0.16611652, 0.1670665 , 0.17378955,\n",
              "        0.17998481, 0.18306533, 0.18427719, 0.19782701, 0.21624014],\n",
              "       dtype=float32),\n",
              " array([0.53769255, 0.55021644, 0.58477366, 0.58895385, 0.5914967 ,\n",
              "        0.60087895, 0.6504147 , 0.6779499 , 0.6976599 , 0.7054249 ],\n",
              "       dtype=float32),\n",
              " array([0.63573176, 0.70738596, 0.74714744, 0.7485438 , 0.7517851 ,\n",
              "        0.75719315, 0.7578456 , 0.78045624, 0.78191817, 0.83684987],\n",
              "       dtype=float32),\n",
              " array([0.15462084, 0.16252244, 0.1901962 , 0.20093907, 0.20792517,\n",
              "        0.20939103, 0.21991578, 0.22863068, 0.2739298 , 0.2813736 ],\n",
              "       dtype=float32),\n",
              " array([0.15404822, 0.15569605, 0.16667025, 0.17289999, 0.17563577,\n",
              "        0.19228052, 0.1935527 , 0.21692708, 0.25682408, 0.31285712],\n",
              "       dtype=float32),\n",
              " array([0.15404822, 0.15569605, 0.16667025, 0.17289999, 0.17563577,\n",
              "        0.19228052, 0.1935527 , 0.21692708, 0.25682408, 0.31285712],\n",
              "       dtype=float32),\n",
              " array([0.13259731, 0.15831171, 0.16374457, 0.17947899, 0.18177761,\n",
              "        0.2000445 , 0.20330006, 0.21561114, 0.21847636, 0.25657383],\n",
              "       dtype=float32),\n",
              " array([0.11017233, 0.16112307, 0.16611652, 0.1670665 , 0.17378955,\n",
              "        0.17998481, 0.18306533, 0.18427719, 0.19782701, 0.21624014],\n",
              "       dtype=float32),\n",
              " array([0.16573879, 0.16784094, 0.169414  , 0.17249203, 0.17400204,\n",
              "        0.19015189, 0.19096665, 0.22908427, 0.25847733, 0.28236872],\n",
              "       dtype=float32),\n",
              " array([0.6536325 , 0.6946095 , 0.69688976, 0.72423416, 0.7343193 ,\n",
              "        0.74633974, 0.7529823 , 0.8292442 , 0.90403414, 0.90725857],\n",
              "       dtype=float32),\n",
              " array([0.15462084, 0.16252244, 0.1901962 , 0.20093907, 0.20792517,\n",
              "        0.20939103, 0.21991578, 0.22863068, 0.2739298 , 0.2813736 ],\n",
              "       dtype=float32),\n",
              " array([0.1483082 , 0.14976819, 0.16205892, 0.16571622, 0.16979724,\n",
              "        0.17018048, 0.18806684, 0.1964619 , 0.22769737, 0.23029579],\n",
              "       dtype=float32),\n",
              " array([0.15275808, 0.15590265, 0.15992428, 0.16634364, 0.17119932,\n",
              "        0.19734406, 0.20143622, 0.20684895, 0.21818629, 0.22378942],\n",
              "       dtype=float32),\n",
              " array([0.4475008 , 0.57105297, 0.58184355, 0.59997445, 0.6036046 ,\n",
              "        0.6450711 , 0.6583157 , 0.68530387, 0.6891762 , 0.7539362 ],\n",
              "       dtype=float32),\n",
              " array([0.67851174, 0.67978877, 0.6805039 , 0.7032055 , 0.71333253,\n",
              "        0.75162965, 0.7690206 , 0.82886904, 0.83836836, 0.84514195],\n",
              "       dtype=float32),\n",
              " array([0.50856704, 0.5637261 , 0.6282546 , 0.7228706 , 0.72706246,\n",
              "        0.75019145, 0.7896517 , 0.80352104, 0.83352274, 0.908242  ],\n",
              "       dtype=float32),\n",
              " array([0.05108279, 0.08676618, 0.09993306, 0.10019577, 0.10407885,\n",
              "        0.11580056, 0.12574837, 0.13261981, 0.1728972 , 0.18793303],\n",
              "       dtype=float32),\n",
              " array([0.06592318, 0.07055703, 0.0725934 , 0.07418984, 0.08295447,\n",
              "        0.09437209, 0.09720104, 0.10657054, 0.11723273, 0.14439227],\n",
              "       dtype=float32),\n",
              " array([0.06600357, 0.07080423, 0.08895106, 0.09140627, 0.10244007,\n",
              "        0.1184437 , 0.16852862, 0.18207318, 0.18321215, 0.25692695],\n",
              "       dtype=float32),\n",
              " array([0.01398139, 0.06668518, 0.0682556 , 0.07200389, 0.07237459,\n",
              "        0.08711501, 0.09568148, 0.1162614 , 0.11763658, 0.15279722],\n",
              "       dtype=float32),\n",
              " array([0.06600357, 0.07080423, 0.08895106, 0.09140627, 0.10244007,\n",
              "        0.1184437 , 0.16852862, 0.18207318, 0.18321215, 0.25692695],\n",
              "       dtype=float32),\n",
              " array([0.6365874 , 0.6515184 , 0.65321255, 0.70946974, 0.71094465,\n",
              "        0.71481556, 0.78242993, 0.7971218 , 0.8715596 , 0.8753372 ],\n",
              "       dtype=float32),\n",
              " array([0.00232485, 0.07347839, 0.09494408, 0.10283232, 0.10581807,\n",
              "        0.10899896, 0.11200257, 0.11971396, 0.16051403, 0.18339668],\n",
              "       dtype=float32),\n",
              " array([0.09341651, 0.09452421, 0.12240942, 0.12554252, 0.14140493,\n",
              "        0.15134113, 0.1541915 , 0.17310396, 0.19169995, 0.19636467],\n",
              "       dtype=float32),\n",
              " array([0.02761461, 0.07238697, 0.07760569, 0.08855096, 0.09257122,\n",
              "        0.10534701, 0.10728003, 0.12341151, 0.13875993, 0.1599005 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.0774582 , 0.0782665 , 0.0810702 , 0.09831069,\n",
              "        0.11769049, 0.12120691, 0.14556403, 0.17412747, 0.18001145],\n",
              "       dtype=float32),\n",
              " array([0.06592318, 0.07055703, 0.0725934 , 0.07418984, 0.08295447,\n",
              "        0.09437209, 0.09720104, 0.10657054, 0.11723273, 0.14439227],\n",
              "       dtype=float32),\n",
              " array([0.01496613, 0.07199629, 0.07275663, 0.08093545, 0.1001687 ,\n",
              "        0.11744169, 0.12014085, 0.13525121, 0.16111211, 0.16889857],\n",
              "       dtype=float32),\n",
              " array([0.06592318, 0.07055703, 0.0725934 , 0.07418984, 0.08295447,\n",
              "        0.09437209, 0.09720104, 0.10657054, 0.11723273, 0.14439227],\n",
              "       dtype=float32),\n",
              " array([0.14491603, 0.15636753, 0.17162254, 0.18484959, 0.20154049,\n",
              "        0.2061573 , 0.2071078 , 0.21092793, 0.21328497, 0.22145276],\n",
              "       dtype=float32),\n",
              " array([0.13681695, 0.171564  , 0.18340728, 0.18943837, 0.19063367,\n",
              "        0.19084929, 0.2020817 , 0.23631552, 0.24257371, 0.24434057],\n",
              "       dtype=float32),\n",
              " array([0.700418  , 0.7040515 , 0.706066  , 0.7274259 , 0.7341534 ,\n",
              "        0.75177133, 0.7917244 , 0.80727965, 0.85186297, 0.90084505],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.00884893, 0.0107327 , 0.02551531,\n",
              "        0.03357906, 0.0486607 , 0.06471271, 0.07114346, 0.12569687],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.02237215, 0.02578702, 0.03786425, 0.05396033,\n",
              "        0.06826617, 0.08170188, 0.09697961, 0.11911638, 0.12083011],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.00359413, 0.00823308, 0.01928065,\n",
              "        0.02713417, 0.04105736, 0.05914967, 0.06407733, 0.12194838],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.03689485, 0.04514886, 0.05337493, 0.08424552,\n",
              "        0.09742758, 0.14704674, 0.1476577 , 0.19498336, 0.19782066],\n",
              "       dtype=float32),\n",
              " array([0.00040357, 0.02396579, 0.0290203 , 0.03561753, 0.03835531,\n",
              "        0.05730577, 0.08334582, 0.08356242, 0.09444403, 0.11212563],\n",
              "       dtype=float32),\n",
              " array([0.00040357, 0.02396579, 0.0290203 , 0.03561753, 0.03835531,\n",
              "        0.05730577, 0.08334582, 0.08356242, 0.09444403, 0.11212563],\n",
              "       dtype=float32),\n",
              " array([0.64455473, 0.66984797, 0.7334631 , 0.7344615 , 0.73674434,\n",
              "        0.7746872 , 0.7762455 , 0.85484093, 0.87524587, 0.8931164 ],\n",
              "       dtype=float32),\n",
              " array([0.01874324, 0.03186497, 0.0451705 , 0.05267894, 0.05875899,\n",
              "        0.06325026, 0.0764439 , 0.08176588, 0.089454  , 0.10406397],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.02610156, 0.02633275, 0.03614173, 0.03711465,\n",
              "        0.05691137, 0.08339159, 0.08715042, 0.09476775, 0.11723145],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.        , 0.00723976, 0.01288753,\n",
              "        0.03098889, 0.03589197, 0.0533332 , 0.0682961 , 0.12009251],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.00033041, 0.00113708, 0.01638287, 0.02499906,\n",
              "        0.03470326, 0.03582306, 0.05894023, 0.06753801, 0.12008899],\n",
              "       dtype=float32),\n",
              " array([0.01562159, 0.02404322, 0.03816715, 0.04198648, 0.04664164,\n",
              "        0.05339378, 0.07062806, 0.09397595, 0.09555151, 0.10762104],\n",
              "       dtype=float32),\n",
              " array([0.00871566, 0.01849959, 0.02486461, 0.02847519, 0.05653799,\n",
              "        0.06510352, 0.08450776, 0.08576934, 0.09474345, 0.1224362 ],\n",
              "       dtype=float32),\n",
              " array([0.00086653, 0.02368257, 0.0375507 , 0.05582306, 0.06669803,\n",
              "        0.08932503, 0.11647917, 0.11784106, 0.1458157 , 0.1722238 ],\n",
              "       dtype=float32),\n",
              " array([0.666465  , 0.66815627, 0.6900032 , 0.7313905 , 0.73898077,\n",
              "        0.74589944, 0.7909657 , 0.81303865, 0.8812593 , 0.8967048 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.00396355, 0.05390626, 0.06699319, 0.07041399,\n",
              "        0.10141166, 0.10755736, 0.109777  , 0.11667091, 0.15901522],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.00396355, 0.05390626, 0.06699319, 0.07041399,\n",
              "        0.10141166, 0.10755736, 0.109777  , 0.11667091, 0.15901522],\n",
              "       dtype=float32),\n",
              " array([0.00871566, 0.01849959, 0.02486461, 0.02847519, 0.05653799,\n",
              "        0.06510352, 0.08450776, 0.08576934, 0.09474345, 0.1224362 ],\n",
              "       dtype=float32),\n",
              " array([0.0000000e+00, 7.3885967e-05, 1.1970722e-02, 1.6227085e-02,\n",
              "        2.8577568e-02, 3.6059622e-02, 4.1098453e-02, 6.4458676e-02,\n",
              "        7.6733157e-02, 1.2394338e-01], dtype=float32),\n",
              " array([0.00040357, 0.02396579, 0.0290203 , 0.03561753, 0.03835531,\n",
              "        0.05730577, 0.08334582, 0.08356242, 0.09444403, 0.11212563],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.04256907, 0.0446906 , 0.05180315, 0.1021263 ,\n",
              "        0.10472155, 0.15026423, 0.16303375, 0.18315656, 0.20069645],\n",
              "       dtype=float32),\n",
              " array([0.73250735, 0.74678266, 0.75525165, 0.76186454, 0.76385224,\n",
              "        0.7706207 , 0.8543945 , 0.8584491 , 0.9122684 , 0.928716  ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.00747365, 0.01479416, 0.01887537,\n",
              "        0.04991214, 0.05358025, 0.06188846, 0.08124995, 0.11894725],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.00731678, 0.01896091, 0.02425185, 0.06927492,\n",
              "        0.07933722, 0.08100777, 0.09861296, 0.13101278, 0.14304012],\n",
              "       dtype=float32),\n",
              " array([0.01526302, 0.03572165, 0.0365225 , 0.03734922, 0.04632355,\n",
              "        0.05099083, 0.05126383, 0.05359028, 0.05813319, 0.06554119],\n",
              "       dtype=float32),\n",
              " array([0.73060334, 0.7435132 , 0.7506674 , 0.75362575, 0.75831115,\n",
              "        0.76223046, 0.8377015 , 0.85938054, 0.89627147, 0.9118447 ],\n",
              "       dtype=float32),\n",
              " array([0.03594402, 0.03760637, 0.05023756, 0.05946596, 0.06988766,\n",
              "        0.07763746, 0.07989959, 0.0809197 , 0.08239578, 0.09014185],\n",
              "       dtype=float32),\n",
              " array([0.68545365, 0.70457345, 0.7075111 , 0.74584395, 0.7505304 ,\n",
              "        0.7551237 , 0.83049667, 0.8652675 , 0.93374616, 0.95371026],\n",
              "       dtype=float32),\n",
              " array([0.02568095, 0.02602552, 0.03447527, 0.05343191, 0.05771041,\n",
              "        0.05863374, 0.06134275, 0.06285267, 0.07103397, 0.08376811],\n",
              "       dtype=float32),\n",
              " array([0.48356983, 0.5563294 , 0.5642396 , 0.5657183 , 0.6013583 ,\n",
              "        0.6124106 , 0.6543083 , 0.66764075, 0.6707758 , 0.7145355 ],\n",
              "       dtype=float32),\n",
              " array([0.4828576 , 0.53326887, 0.5507707 , 0.5699098 , 0.5802885 ,\n",
              "        0.60590154, 0.6740944 , 0.6777073 , 0.698205  , 0.72254145],\n",
              "       dtype=float32),\n",
              " array([0.6828726 , 0.69527084, 0.74059033, 0.75542074, 0.78109455,\n",
              "        0.7851558 , 0.8129533 , 0.8428136 , 0.8679219 , 0.9046629 ],\n",
              "       dtype=float32),\n",
              " array([0.67363226, 0.6837283 , 0.68385684, 0.6929601 , 0.74201256,\n",
              "        0.7464131 , 0.81956893, 0.86931795, 0.86938405, 0.8957842 ],\n",
              "       dtype=float32),\n",
              " array([0.03814831, 0.04681695, 0.0584808 , 0.05931504, 0.06748263,\n",
              "        0.08056798, 0.09113599, 0.09289474, 0.09981719, 0.10845356],\n",
              "       dtype=float32),\n",
              " array([0.6909928 , 0.7130716 , 0.7312564 , 0.7415708 , 0.75356346,\n",
              "        0.75889224, 0.781656  , 0.8449024 , 0.92069465, 0.92621475],\n",
              "       dtype=float32),\n",
              " array([0.03594402, 0.03760637, 0.05023756, 0.05946596, 0.06988766,\n",
              "        0.07763746, 0.07989959, 0.0809197 , 0.08239578, 0.09014185],\n",
              "       dtype=float32),\n",
              " array([0.6411013 , 0.7225145 , 0.7257387 , 0.74089634, 0.7520569 ,\n",
              "        0.7546949 , 0.76009226, 0.86725056, 0.868795  , 0.9570924 ],\n",
              "       dtype=float32),\n",
              " array([0.03015499, 0.04232758, 0.04429614, 0.0477514 , 0.05086067,\n",
              "        0.05123797, 0.05636577, 0.07560745, 0.0760994 , 0.07739214],\n",
              "       dtype=float32),\n",
              " array([0.67363226, 0.6837283 , 0.68385684, 0.6929601 , 0.74201256,\n",
              "        0.7464131 , 0.81956893, 0.86931795, 0.86938405, 0.8957842 ],\n",
              "       dtype=float32),\n",
              " array([0.05999134, 0.06755001, 0.07199862, 0.07279266, 0.07348931,\n",
              "        0.07567088, 0.08115228, 0.09048381, 0.10405351, 0.11268452],\n",
              "       dtype=float32),\n",
              " array([0.6962413 , 0.7126839 , 0.7174507 , 0.73157865, 0.74401546,\n",
              "        0.765604  , 0.7846073 , 0.8071986 , 0.8510092 , 0.89048356],\n",
              "       dtype=float32),\n",
              " array([0.04977402, 0.09119722, 0.11094741, 0.11292008, 0.11580295,\n",
              "        0.12026279, 0.12560157, 0.12591949, 0.12738694, 0.17264242],\n",
              "       dtype=float32),\n",
              " array([0.6909928 , 0.7130716 , 0.7312564 , 0.7415708 , 0.75356346,\n",
              "        0.75889224, 0.781656  , 0.8449024 , 0.92069465, 0.92621475],\n",
              "       dtype=float32),\n",
              " array([0.69645673, 0.71035177, 0.7223571 , 0.73392457, 0.74451834,\n",
              "        0.7824907 , 0.8152413 , 0.83943444, 0.8506789 , 0.9024483 ],\n",
              "       dtype=float32),\n",
              " array([0.05910121, 0.06180782, 0.07326133, 0.07610856, 0.07895803,\n",
              "        0.0839252 , 0.09229614, 0.09628621, 0.10534707, 0.11753219],\n",
              "       dtype=float32),\n",
              " array([0.64455473, 0.66984797, 0.7334631 , 0.7344615 , 0.73674434,\n",
              "        0.7746872 , 0.7762455 , 0.85484093, 0.87524587, 0.8931164 ],\n",
              "       dtype=float32),\n",
              " array([0.03814831, 0.04681695, 0.0584808 , 0.05931504, 0.06748263,\n",
              "        0.08056798, 0.09113599, 0.09289474, 0.09981719, 0.10845356],\n",
              "       dtype=float32),\n",
              " array([0.7342134 , 0.7347276 , 0.752706  , 0.758869  , 0.7632652 ,\n",
              "        0.76976323, 0.833818  , 0.850142  , 0.86874557, 0.9087377 ],\n",
              "       dtype=float32),\n",
              " array([0.05930354, 0.05969948, 0.06605262, 0.06706262, 0.07290141,\n",
              "        0.07554007, 0.09107725, 0.09853989, 0.10860707, 0.11553622],\n",
              "       dtype=float32),\n",
              " array([0.5058996 , 0.566275  , 0.5854475 , 0.58831173, 0.6129895 ,\n",
              "        0.63714194, 0.69975334, 0.7108858 , 0.71422917, 0.7387321 ],\n",
              "       dtype=float32),\n",
              " array([0.6808167 , 0.7272338 , 0.7454513 , 0.7458851 , 0.75039726,\n",
              "        0.81001455, 0.8216169 , 0.84073293, 0.84647113, 0.8953747 ],\n",
              "       dtype=float32),\n",
              " array([0.06289421, 0.0727127 , 0.08704434, 0.08717671, 0.08994367,\n",
              "        0.10454295, 0.10746728, 0.10900328, 0.10913779, 0.11146886],\n",
              "       dtype=float32),\n",
              " array([0.05930354, 0.05969948, 0.06605262, 0.06706262, 0.07290141,\n",
              "        0.07554007, 0.09107725, 0.09853989, 0.10860707, 0.11553622],\n",
              "       dtype=float32),\n",
              " array([0.6119316 , 0.68324494, 0.68508273, 0.70079136, 0.72511506,\n",
              "        0.74770725, 0.7494128 , 0.8071916 , 0.87588364, 0.94055927],\n",
              "       dtype=float32),\n",
              " array([0.04875119, 0.05407215, 0.05430719, 0.0575374 , 0.06417822,\n",
              "        0.07696443, 0.07920219, 0.080514  , 0.08060669, 0.09749568],\n",
              "       dtype=float32),\n",
              " array([0.6909928 , 0.7130716 , 0.7312564 , 0.7415708 , 0.75356346,\n",
              "        0.75889224, 0.781656  , 0.8449024 , 0.92069465, 0.92621475],\n",
              "       dtype=float32),\n",
              " array([0.06215434, 0.06515102, 0.06567651, 0.0891469 , 0.09328526,\n",
              "        0.09472284, 0.10251069, 0.10780262, 0.12289233, 0.12899296],\n",
              "       dtype=float32),\n",
              " array([0.03904741, 0.06047131, 0.06141404, 0.06226362, 0.0650226 ,\n",
              "        0.09248447, 0.09440107, 0.09834545, 0.10462517, 0.1124961 ],\n",
              "       dtype=float32),\n",
              " array([0.67363226, 0.6837283 , 0.68385684, 0.6929601 , 0.74201256,\n",
              "        0.7464131 , 0.81956893, 0.86931795, 0.86938405, 0.8957842 ],\n",
              "       dtype=float32),\n",
              " array([0.05226439, 0.06817939, 0.07013433, 0.07136504, 0.07150462,\n",
              "        0.07431267, 0.07817708, 0.08337688, 0.09948899, 0.11564656],\n",
              "       dtype=float32),\n",
              " array([0.04117059, 0.04494929, 0.04626551, 0.05284443, 0.05377585,\n",
              "        0.06675269, 0.06708646, 0.07497947, 0.07826399, 0.08685347],\n",
              "       dtype=float32),\n",
              " array([0.67725873, 0.7411275 , 0.75569224, 0.7694844 , 0.7782746 ,\n",
              "        0.795341  , 0.8121098 , 0.8244399 , 0.83834016, 0.91524744],\n",
              "       dtype=float32),\n",
              " array([0.05005644, 0.07113051, 0.07939114, 0.08170849, 0.08800682,\n",
              "        0.11670946, 0.12047144, 0.12803844, 0.12938933, 0.12972222],\n",
              "       dtype=float32),\n",
              " array([0.04675317, 0.05441315, 0.06237448, 0.06762163, 0.0677986 ,\n",
              "        0.07952893, 0.08247055, 0.08664317, 0.09423598, 0.09508977],\n",
              "       dtype=float32),\n",
              " array([0.6565165 , 0.6612095 , 0.67428887, 0.71544206, 0.721436  ,\n",
              "        0.73439956, 0.79457134, 0.83471495, 0.8555034 , 0.8787878 ],\n",
              "       dtype=float32),\n",
              " array([0.03015499, 0.04232758, 0.04429614, 0.0477514 , 0.05086067,\n",
              "        0.05123797, 0.05636577, 0.07560745, 0.0760994 , 0.07739214],\n",
              "       dtype=float32),\n",
              " array([0.6311462 , 0.7280998 , 0.7290376 , 0.7293254 , 0.7376319 ,\n",
              "        0.742432  , 0.756879  , 0.7599554 , 0.81948984, 0.84271586],\n",
              "       dtype=float32),\n",
              " array([0.04937664, 0.06316461, 0.07661248, 0.08031764, 0.09872627,\n",
              "        0.10170536, 0.10559187, 0.12495841, 0.12954032, 0.144763  ],\n",
              "       dtype=float32),\n",
              " array([0.02568095, 0.02602552, 0.03447527, 0.05343191, 0.05771041,\n",
              "        0.05863374, 0.06134275, 0.06285267, 0.07103397, 0.08376811],\n",
              "       dtype=float32),\n",
              " array([0.6119316 , 0.68324494, 0.68508273, 0.70079136, 0.72511506,\n",
              "        0.74770725, 0.7494128 , 0.8071916 , 0.87588364, 0.94055927],\n",
              "       dtype=float32),\n",
              " array([0.05904915, 0.06524692, 0.07289076, 0.07423873, 0.07600659,\n",
              "        0.08319303, 0.09118525, 0.11294066, 0.1136613 , 0.12128584],\n",
              "       dtype=float32),\n",
              " array([0.03892767, 0.03995461, 0.04365019, 0.04798555, 0.05771425,\n",
              "        0.0586693 , 0.06675943, 0.06932949, 0.07814158, 0.08913913],\n",
              "       dtype=float32),\n",
              " array([0.67725873, 0.7411275 , 0.75569224, 0.7694844 , 0.7782746 ,\n",
              "        0.795341  , 0.8121098 , 0.8244399 , 0.83834016, 0.91524744],\n",
              "       dtype=float32),\n",
              " array([0.04977402, 0.09119722, 0.11094741, 0.11292008, 0.11580295,\n",
              "        0.12026279, 0.12560157, 0.12591949, 0.12738694, 0.17264242],\n",
              "       dtype=float32),\n",
              " array([0.05910121, 0.06180782, 0.07326133, 0.07610856, 0.07895803,\n",
              "        0.0839252 , 0.09229614, 0.09628621, 0.10534707, 0.11753219],\n",
              "       dtype=float32),\n",
              " array([0.700418  , 0.7040515 , 0.706066  , 0.7274259 , 0.7341534 ,\n",
              "        0.75177133, 0.7917244 , 0.80727965, 0.85186297, 0.90084505],\n",
              "       dtype=float32),\n",
              " array([0.07419663, 0.07572023, 0.07937893, 0.09157071, 0.0966938 ,\n",
              "        0.09986916, 0.1191779 , 0.12260256, 0.12800442, 0.15816157],\n",
              "       dtype=float32),\n",
              " array([0.4663109 , 0.4922767 , 0.50752985, 0.51399356, 0.5222001 ,\n",
              "        0.5452429 , 0.5961433 , 0.6161043 , 0.62130785, 0.68085206],\n",
              "       dtype=float32),\n",
              " array([0.6365874 , 0.6515184 , 0.65321255, 0.70946974, 0.71094465,\n",
              "        0.71481556, 0.78242993, 0.7971218 , 0.8715596 , 0.8753372 ],\n",
              "       dtype=float32),\n",
              " array([0.03904741, 0.06047131, 0.06141404, 0.06226362, 0.0650226 ,\n",
              "        0.09248447, 0.09440107, 0.09834545, 0.10462517, 0.1124961 ],\n",
              "       dtype=float32),\n",
              " array([0.05154004, 0.05407924, 0.05479639, 0.06746095, 0.0731841 ,\n",
              "        0.08779603, 0.09083831, 0.09339965, 0.10853489, 0.10854626],\n",
              "       dtype=float32),\n",
              " array([0.6119316 , 0.68324494, 0.68508273, 0.70079136, 0.72511506,\n",
              "        0.74770725, 0.7494128 , 0.8071916 , 0.87588364, 0.94055927],\n",
              "       dtype=float32),\n",
              " array([0.05133462, 0.09389827, 0.10919605, 0.12036275, 0.12296867,\n",
              "        0.12748545, 0.13046218, 0.13265833, 0.13374726, 0.187366  ],\n",
              "       dtype=float32),\n",
              " array([0.02865848, 0.04177359, 0.06053586, 0.0633723 , 0.06521395,\n",
              "        0.06783246, 0.07269577, 0.07853349, 0.0877623 , 0.09299862],\n",
              "       dtype=float32),\n",
              " array([0.6411013 , 0.7225145 , 0.7257387 , 0.74089634, 0.7520569 ,\n",
              "        0.7546949 , 0.76009226, 0.86725056, 0.868795  , 0.9570924 ],\n",
              "       dtype=float32),\n",
              " array([0.05930354, 0.05969948, 0.06605262, 0.06706262, 0.07290141,\n",
              "        0.07554007, 0.09107725, 0.09853989, 0.10860707, 0.11553622],\n",
              "       dtype=float32),\n",
              " array([0.04875119, 0.05407215, 0.05430719, 0.0575374 , 0.06417822,\n",
              "        0.07696443, 0.07920219, 0.080514  , 0.08060669, 0.09749568],\n",
              "       dtype=float32),\n",
              " array([0.6887426 , 0.7334569 , 0.7397629 , 0.74468845, 0.7795389 ,\n",
              "        0.80171   , 0.8258114 , 0.8888159 , 0.90521264, 0.95581436],\n",
              "       dtype=float32),\n",
              " array([0.05226439, 0.06817939, 0.07013433, 0.07136504, 0.07150462,\n",
              "        0.07431267, 0.07817708, 0.08337688, 0.09948899, 0.11564656],\n",
              "       dtype=float32),\n",
              " array([0.04420384, 0.0506171 , 0.05259924, 0.05564152, 0.06747787,\n",
              "        0.06812262, 0.06996767, 0.07825148, 0.08061301, 0.0903117 ],\n",
              "       dtype=float32),\n",
              " array([0.69701236, 0.71360254, 0.7267848 , 0.73499936, 0.7415947 ,\n",
              "        0.7573232 , 0.81929374, 0.82513493, 0.84169006, 0.90660787],\n",
              "       dtype=float32),\n",
              " array([0.05226439, 0.06817939, 0.07013433, 0.07136504, 0.07150462,\n",
              "        0.07431267, 0.07817708, 0.08337688, 0.09948899, 0.11564656],\n",
              "       dtype=float32),\n",
              " array([0.64455473, 0.66984797, 0.7334631 , 0.7344615 , 0.73674434,\n",
              "        0.7746872 , 0.7762455 , 0.85484093, 0.87524587, 0.8931164 ],\n",
              "       dtype=float32),\n",
              " array([0.03904741, 0.06047131, 0.06141404, 0.06226362, 0.0650226 ,\n",
              "        0.09248447, 0.09440107, 0.09834545, 0.10462517, 0.1124961 ],\n",
              "       dtype=float32),\n",
              " array([0.04937664, 0.06316461, 0.07661248, 0.08031764, 0.09872627,\n",
              "        0.10170536, 0.10559187, 0.12495841, 0.12954032, 0.144763  ],\n",
              "       dtype=float32),\n",
              " array([0.68545365, 0.70457345, 0.7075111 , 0.74584395, 0.7505304 ,\n",
              "        0.7551237 , 0.83049667, 0.8652675 , 0.93374616, 0.95371026],\n",
              "       dtype=float32),\n",
              " array([0.01526302, 0.03572165, 0.0365225 , 0.03734922, 0.04632355,\n",
              "        0.05099083, 0.05126383, 0.05359028, 0.05813319, 0.06554119],\n",
              "       dtype=float32),\n",
              " array([0.05942081, 0.06236486, 0.06419785, 0.08379281, 0.08665924,\n",
              "        0.09513087, 0.10037876, 0.1024361 , 0.12102074, 0.12379631],\n",
              "       dtype=float32),\n",
              " array([0.6412328 , 0.71645397, 0.716469  , 0.7222924 , 0.7266394 ,\n",
              "        0.73444444, 0.7675188 , 0.8465975 , 0.8791172 , 0.9569973 ],\n",
              "       dtype=float32),\n",
              " array([0.05133462, 0.09389827, 0.10919605, 0.12036275, 0.12296867,\n",
              "        0.12748545, 0.13046218, 0.13265833, 0.13374726, 0.187366  ],\n",
              "       dtype=float32),\n",
              " array([0.700418  , 0.7040515 , 0.706066  , 0.7274259 , 0.7341534 ,\n",
              "        0.75177133, 0.7917244 , 0.80727965, 0.85186297, 0.90084505],\n",
              "       dtype=float32),\n",
              " array([0.04111193, 0.08012716, 0.09782619, 0.10104947, 0.11123216,\n",
              "        0.11350334, 0.11649367, 0.11795516, 0.11903968, 0.1320359 ],\n",
              "       dtype=float32),\n",
              " array([0.06289421, 0.0727127 , 0.08704434, 0.08717671, 0.08994367,\n",
              "        0.10454295, 0.10746728, 0.10900328, 0.10913779, 0.11146886],\n",
              "       dtype=float32),\n",
              " array([0.67725873, 0.7411275 , 0.75569224, 0.7694844 , 0.7782746 ,\n",
              "        0.795341  , 0.8121098 , 0.8244399 , 0.83834016, 0.91524744],\n",
              "       dtype=float32),\n",
              " array([0.0394901 , 0.05728879, 0.05981745, 0.06512769, 0.07345316,\n",
              "        0.08237638, 0.09145863, 0.09700045, 0.10592198, 0.1097214 ],\n",
              "       dtype=float32),\n",
              " array([0.02472675, 0.04273444, 0.07011598, 0.07132859, 0.07175877,\n",
              "        0.07279435, 0.08638533, 0.09737694, 0.1015614 , 0.11577246],\n",
              "       dtype=float32),\n",
              " array([0.52150273, 0.525639  , 0.5275571 , 0.5493337 , 0.5560017 ,\n",
              "        0.5575175 , 0.5842153 , 0.6375628 , 0.6418604 , 0.68332386],\n",
              "       dtype=float32),\n",
              " array([0.6628724 , 0.6669633 , 0.6788336 , 0.69236445, 0.7039559 ,\n",
              "        0.7140095 , 0.734781  , 0.742298  , 0.8040657 , 0.8439209 ],\n",
              "       dtype=float32),\n",
              " array([0.04977402, 0.09119722, 0.11094741, 0.11292008, 0.11580295,\n",
              "        0.12026279, 0.12560157, 0.12591949, 0.12738694, 0.17264242],\n",
              "       dtype=float32),\n",
              " array([0.64455473, 0.66984797, 0.7334631 , 0.7344615 , 0.73674434,\n",
              "        0.7746872 , 0.7762455 , 0.85484093, 0.87524587, 0.8931164 ],\n",
              "       dtype=float32),\n",
              " array([0.05930354, 0.05969948, 0.06605262, 0.06706262, 0.07290141,\n",
              "        0.07554007, 0.09107725, 0.09853989, 0.10860707, 0.11553622],\n",
              "       dtype=float32),\n",
              " array([0.04937664, 0.06316461, 0.07661248, 0.08031764, 0.09872627,\n",
              "        0.10170536, 0.10559187, 0.12495841, 0.12954032, 0.144763  ],\n",
              "       dtype=float32),\n",
              " array([0.66826487, 0.67694134, 0.69124204, 0.7184133 , 0.73929673,\n",
              "        0.7429344 , 0.7711531 , 0.80552006, 0.8231783 , 0.8417509 ],\n",
              "       dtype=float32),\n",
              " array([0.03814831, 0.04681695, 0.0584808 , 0.05931504, 0.06748263,\n",
              "        0.08056798, 0.09113599, 0.09289474, 0.09981719, 0.10845356],\n",
              "       dtype=float32),\n",
              " array([0.04420384, 0.0506171 , 0.05259924, 0.05564152, 0.06747787,\n",
              "        0.06812262, 0.06996767, 0.07825148, 0.08061301, 0.0903117 ],\n",
              "       dtype=float32),\n",
              " array([0.651245  , 0.71356595, 0.7184813 , 0.72791696, 0.762292  ,\n",
              "        0.7676213 , 0.77847964, 0.852154  , 0.92309636, 0.9621931 ],\n",
              "       dtype=float32),\n",
              " array([0.05904915, 0.06524692, 0.07289076, 0.07423873, 0.07600659,\n",
              "        0.08319303, 0.09118525, 0.11294066, 0.1136613 , 0.12128584],\n",
              "       dtype=float32),\n",
              " array([0.6518161 , 0.65831363, 0.6712252 , 0.6884728 , 0.73098344,\n",
              "        0.7324664 , 0.81170684, 0.82646406, 0.8622911 , 0.8792851 ],\n",
              "       dtype=float32),\n",
              " array([0.04117059, 0.04494929, 0.04626551, 0.05284443, 0.05377585,\n",
              "        0.06675269, 0.06708646, 0.07497947, 0.07826399, 0.08685347],\n",
              "       dtype=float32),\n",
              " array([0.04977402, 0.09119722, 0.11094741, 0.11292008, 0.11580295,\n",
              "        0.12026279, 0.12560157, 0.12591949, 0.12738694, 0.17264242],\n",
              "       dtype=float32),\n",
              " array([0.6565165 , 0.6612095 , 0.67428887, 0.71544206, 0.721436  ,\n",
              "        0.73439956, 0.79457134, 0.83471495, 0.8555034 , 0.8787878 ],\n",
              "       dtype=float32),\n",
              " array([0.03110538, 0.05523392, 0.05868883, 0.06289964, 0.07101431,\n",
              "        0.07204027, 0.07815931, 0.08096865, 0.09894367, 0.10268956],\n",
              "       dtype=float32),\n",
              " array([0.04420384, 0.0506171 , 0.05259924, 0.05564152, 0.06747787,\n",
              "        0.06812262, 0.06996767, 0.07825148, 0.08061301, 0.0903117 ],\n",
              "       dtype=float32),\n",
              " array([0.6119316 , 0.68324494, 0.68508273, 0.70079136, 0.72511506,\n",
              "        0.74770725, 0.7494128 , 0.8071916 , 0.87588364, 0.94055927],\n",
              "       dtype=float32),\n",
              " array([0.02568095, 0.02602552, 0.03447527, 0.05343191, 0.05771041,\n",
              "        0.05863374, 0.06134275, 0.06285267, 0.07103397, 0.08376811],\n",
              "       dtype=float32),\n",
              " array([0.04117059, 0.04494929, 0.04626551, 0.05284443, 0.05377585,\n",
              "        0.06675269, 0.06708646, 0.07497947, 0.07826399, 0.08685347],\n",
              "       dtype=float32),\n",
              " array([0.67363226, 0.6837283 , 0.68385684, 0.6929601 , 0.74201256,\n",
              "        0.7464131 , 0.81956893, 0.86931795, 0.86938405, 0.8957842 ],\n",
              "       dtype=float32),\n",
              " array([0.0394901 , 0.05728879, 0.05981745, 0.06512769, 0.07345316,\n",
              "        0.08237638, 0.09145863, 0.09700045, 0.10592198, 0.1097214 ],\n",
              "       dtype=float32),\n",
              " array([0.6565165 , 0.6612095 , 0.67428887, 0.71544206, 0.721436  ,\n",
              "        0.73439956, 0.79457134, 0.83471495, 0.8555034 , 0.8787878 ],\n",
              "       dtype=float32),\n",
              " array([0.07419663, 0.07572023, 0.07937893, 0.09157071, 0.0966938 ,\n",
              "        0.09986916, 0.1191779 , 0.12260256, 0.12800442, 0.15816157],\n",
              "       dtype=float32),\n",
              " array([0.6737126 , 0.6855761 , 0.71271354, 0.75843525, 0.76063806,\n",
              "        0.76557213, 0.7661454 , 0.805391  , 0.8524558 , 0.8786155 ],\n",
              "       dtype=float32),\n",
              " array([0.04755535, 0.05559886, 0.05771422, 0.06442664, 0.07045342,\n",
              "        0.07584417, 0.08393995, 0.08507461, 0.09342334, 0.10344973],\n",
              "       dtype=float32),\n",
              " array([0.01526302, 0.03572165, 0.0365225 , 0.03734922, 0.04632355,\n",
              "        0.05099083, 0.05126383, 0.05359028, 0.05813319, 0.06554119],\n",
              "       dtype=float32),\n",
              " array([0.57797664, 0.58949715, 0.60030985, 0.60406864, 0.6245985 ,\n",
              "        0.6397312 , 0.6479295 , 0.6798242 , 0.7112102 , 0.72727674],\n",
              "       dtype=float32),\n",
              " array([0.6311462 , 0.7280998 , 0.7290376 , 0.7293254 , 0.7376319 ,\n",
              "        0.742432  , 0.756879  , 0.7599554 , 0.81948984, 0.84271586],\n",
              "       dtype=float32),\n",
              " array([0.03556355, 0.04395736, 0.04410126, 0.06599544, 0.06641444,\n",
              "        0.07899428, 0.08617122, 0.08920588, 0.10081109, 0.11467993],\n",
              "       dtype=float32),\n",
              " array([0.06289421, 0.0727127 , 0.08704434, 0.08717671, 0.08994367,\n",
              "        0.10454295, 0.10746728, 0.10900328, 0.10913779, 0.11146886],\n",
              "       dtype=float32),\n",
              " array([0.68545365, 0.70457345, 0.7075111 , 0.74584395, 0.7505304 ,\n",
              "        0.7551237 , 0.83049667, 0.8652675 , 0.93374616, 0.95371026],\n",
              "       dtype=float32),\n",
              " array([0.03904741, 0.06047131, 0.06141404, 0.06226362, 0.0650226 ,\n",
              "        0.09248447, 0.09440107, 0.09834545, 0.10462517, 0.1124961 ],\n",
              "       dtype=float32),\n",
              " array([0.05904915, 0.06524692, 0.07289076, 0.07423873, 0.07600659,\n",
              "        0.08319303, 0.09118525, 0.11294066, 0.1136613 , 0.12128584],\n",
              "       dtype=float32),\n",
              " array([0.6475653 , 0.7292108 , 0.7329596 , 0.7431864 , 0.74728906,\n",
              "        0.7642266 , 0.7707417 , 0.8005214 , 0.82947487, 0.8759894 ],\n",
              "       dtype=float32),\n",
              " array([0.06120149, 0.06347702, 0.08133079, 0.08240309, 0.08924329,\n",
              "        0.10069474, 0.10725939, 0.11706071, 0.12148969, 0.1294093 ],\n",
              "       dtype=float32),\n",
              " array([0.3595525 , 0.4689984 , 0.5492728 , 0.5508873 , 0.60703415,\n",
              "        0.6231855 , 0.6326793 , 0.64165735, 0.6945084 , 0.70992595],\n",
              "       dtype=float32),\n",
              " array([0.04875119, 0.05407215, 0.05430719, 0.0575374 , 0.06417822,\n",
              "        0.07696443, 0.07920219, 0.080514  , 0.08060669, 0.09749568],\n",
              "       dtype=float32),\n",
              " array([0.04937664, 0.06316461, 0.07661248, 0.08031764, 0.09872627,\n",
              "        0.10170536, 0.10559187, 0.12495841, 0.12954032, 0.144763  ],\n",
              "       dtype=float32),\n",
              " array([0.22758071, 0.23643577, 0.24092947, 0.2519038 , 0.3397675 ,\n",
              "        0.3589244 , 0.36411256, 0.37872118, 0.41530192, 0.4238963 ],\n",
              "       dtype=float32),\n",
              " array([0.05930354, 0.05969948, 0.06605262, 0.06706262, 0.07290141,\n",
              "        0.07554007, 0.09107725, 0.09853989, 0.10860707, 0.11553622],\n",
              "       dtype=float32),\n",
              " array([0.04875119, 0.05407215, 0.05430719, 0.0575374 , 0.06417822,\n",
              "        0.07696443, 0.07920219, 0.080514  , 0.08060669, 0.09749568],\n",
              "       dtype=float32),\n",
              " array([0.61394286, 0.6682206 , 0.68605846, 0.730135  , 0.7304459 ,\n",
              "        0.7348381 , 0.7426425 , 0.7658907 , 0.775866  , 0.8519162 ],\n",
              "       dtype=float32),\n",
              " array([0.02568095, 0.02602552, 0.03447527, 0.05343191, 0.05771041,\n",
              "        0.05863374, 0.06134275, 0.06285267, 0.07103397, 0.08376811],\n",
              "       dtype=float32),\n",
              " array([0.14263766, 0.23477326, 0.26635772, 0.27155018, 0.27497086,\n",
              "        0.28004655, 0.29164866, 0.34196818, 0.36100814, 0.3659031 ],\n",
              "       dtype=float32),\n",
              " array([0.04755535, 0.05559886, 0.05771422, 0.06442664, 0.07045342,\n",
              "        0.07584417, 0.08393995, 0.08507461, 0.09342334, 0.10344973],\n",
              "       dtype=float32),\n",
              " array([0.04977402, 0.09119722, 0.11094741, 0.11292008, 0.11580295,\n",
              "        0.12026279, 0.12560157, 0.12591949, 0.12738694, 0.17264242],\n",
              "       dtype=float32),\n",
              " array([0.27433875, 0.29067227, 0.332004  , 0.3379333 , 0.33821815,\n",
              "        0.34712693, 0.35064477, 0.37059206, 0.44222707, 0.4741704 ],\n",
              "       dtype=float32),\n",
              " array([0.04977402, 0.09119722, 0.11094741, 0.11292008, 0.11580295,\n",
              "        0.12026279, 0.12560157, 0.12591949, 0.12738694, 0.17264242],\n",
              "       dtype=float32),\n",
              " array([0.10560615, 0.12165675, 0.19277632, 0.20985548, 0.21926244,\n",
              "        0.22331923, 0.2336544 , 0.2729459 , 0.2793186 , 0.281106  ],\n",
              "       dtype=float32),\n",
              " array([0.05154004, 0.05407924, 0.05479639, 0.06746095, 0.0731841 ,\n",
              "        0.08779603, 0.09083831, 0.09339965, 0.10853489, 0.10854626],\n",
              "       dtype=float32),\n",
              " array([0.0580192 , 0.07080278, 0.0744688 , 0.07492983, 0.07496885,\n",
              "        0.07536168, 0.07672622, 0.08018271, 0.0890839 , 0.09858414],\n",
              "       dtype=float32),\n",
              " array([0.03814831, 0.04681695, 0.0584808 , 0.05931504, 0.06748263,\n",
              "        0.08056798, 0.09113599, 0.09289474, 0.09981719, 0.10845356],\n",
              "       dtype=float32),\n",
              " array([0.18717054, 0.28762797, 0.3161892 , 0.3191279 , 0.3292677 ,\n",
              "        0.33785668, 0.34163603, 0.36136302, 0.39810103, 0.44045356],\n",
              "       dtype=float32),\n",
              " array([0.05606231, 0.08377093, 0.09062896, 0.09736743, 0.09779052,\n",
              "        0.10153185, 0.10928775, 0.11199576, 0.12171367, 0.12753132],\n",
              "       dtype=float32),\n",
              " array([0.19035804, 0.28868058, 0.2903613 , 0.3042367 , 0.30600545,\n",
              "        0.31099892, 0.35748634, 0.4024028 , 0.4077995 , 0.4513746 ],\n",
              "       dtype=float32),\n",
              " array([0.05942081, 0.06236486, 0.06419785, 0.08379281, 0.08665924,\n",
              "        0.09513087, 0.10037876, 0.1024361 , 0.12102074, 0.12379631],\n",
              "       dtype=float32),\n",
              " array([0.02865848, 0.04177359, 0.06053586, 0.0633723 , 0.06521395,\n",
              "        0.06783246, 0.07269577, 0.07853349, 0.0877623 , 0.09299862],\n",
              "       dtype=float32),\n",
              " array([0.3875087 , 0.44106117, 0.45806575, 0.46157178, 0.4957613 ,\n",
              "        0.49818617, 0.509997  , 0.5189847 , 0.58076775, 0.6366968 ],\n",
              "       dtype=float32),\n",
              " array([0.05930354, 0.05969948, 0.06605262, 0.06706262, 0.07290141,\n",
              "        0.07554007, 0.09107725, 0.09853989, 0.10860707, 0.11553622],\n",
              "       dtype=float32),\n",
              " array([0.04109774, 0.05239185, 0.0533382 , 0.05372601, 0.05413906,\n",
              "        0.05961097, 0.06497512, 0.08166321, 0.08565148, 0.08944339],\n",
              "       dtype=float32),\n",
              " array([0.46559906, 0.5260744 , 0.5293805 , 0.53276116, 0.5329933 ,\n",
              "        0.53643477, 0.6338604 , 0.6901738 , 0.69775385, 0.7006643 ],\n",
              "       dtype=float32),\n",
              " array([0.04875119, 0.05407215, 0.05430719, 0.0575374 , 0.06417822,\n",
              "        0.07696443, 0.07920219, 0.080514  , 0.08060669, 0.09749568],\n",
              "       dtype=float32),\n",
              " array([0.05999134, 0.06755001, 0.07199862, 0.07279266, 0.07348931,\n",
              "        0.07567088, 0.08115228, 0.09048381, 0.10405351, 0.11268452],\n",
              "       dtype=float32),\n",
              " array([0.03110538, 0.05523392, 0.05868883, 0.06289964, 0.07101431,\n",
              "        0.07204027, 0.07815931, 0.08096865, 0.09894367, 0.10268956],\n",
              "       dtype=float32),\n",
              " array([0.25647083, 0.26265177, 0.32276446, 0.33014357, 0.35436797,\n",
              "        0.3584413 , 0.36385334, 0.37672427, 0.40207404, 0.43912444],\n",
              "       dtype=float32),\n",
              " array([0.05334765, 0.0568121 , 0.05716136, 0.05758152, 0.06379414,\n",
              "        0.0751678 , 0.07601523, 0.08058987, 0.0819365 , 0.09467807],\n",
              "       dtype=float32),\n",
              " array([0.03015499, 0.04232758, 0.04429614, 0.0477514 , 0.05086067,\n",
              "        0.05123797, 0.05636577, 0.07560745, 0.0760994 , 0.07739214],\n",
              "       dtype=float32),\n",
              " array([0.35167626, 0.37310952, 0.38995412, 0.40679964, 0.42456684,\n",
              "        0.42743635, 0.44060007, 0.46137136, 0.48326567, 0.5048127 ],\n",
              "       dtype=float32),\n",
              " array([0.05942081, 0.06236486, 0.06419785, 0.08379281, 0.08665924,\n",
              "        0.09513087, 0.10037876, 0.1024361 , 0.12102074, 0.12379631],\n",
              "       dtype=float32),\n",
              " array([0.02865848, 0.04177359, 0.06053586, 0.0633723 , 0.06521395,\n",
              "        0.06783246, 0.07269577, 0.07853349, 0.0877623 , 0.09299862],\n",
              "       dtype=float32),\n",
              " array([0.32904986, 0.33069628, 0.3853449 , 0.42460892, 0.43334827,\n",
              "        0.4364354 , 0.4371671 , 0.442239  , 0.4599727 , 0.48305815],\n",
              "       dtype=float32),\n",
              " array([0.05005644, 0.07113051, 0.07939114, 0.08170849, 0.08800682,\n",
              "        0.11670946, 0.12047144, 0.12803844, 0.12938933, 0.12972222],\n",
              "       dtype=float32),\n",
              " array([0.30691686, 0.34084076, 0.36843625, 0.4327966 , 0.44802082,\n",
              "        0.47706145, 0.48429728, 0.5456194 , 0.5730527 , 0.5865727 ],\n",
              "       dtype=float32),\n",
              " array([0.04065849, 0.04137201, 0.04166633, 0.06486794, 0.07201005,\n",
              "        0.07396823, 0.08131431, 0.08684709, 0.09715573, 0.11695087],\n",
              "       dtype=float32),\n",
              " array([0.04065849, 0.04137201, 0.04166633, 0.06486794, 0.07201005,\n",
              "        0.07396823, 0.08131431, 0.08684709, 0.09715573, 0.11695087],\n",
              "       dtype=float32),\n",
              " array([0.22287819, 0.23480117, 0.2906777 , 0.36405587, 0.3828186 ,\n",
              "        0.47370693, 0.49036723, 0.5252808 , 0.5439755 , 0.6286489 ],\n",
              "       dtype=float32),\n",
              " array([0.05154004, 0.05407924, 0.05479639, 0.06746095, 0.0731841 ,\n",
              "        0.08779603, 0.09083831, 0.09339965, 0.10853489, 0.10854626],\n",
              "       dtype=float32),\n",
              " array([0.02297454, 0.05231469, 0.05716806, 0.06618994, 0.07060917,\n",
              "        0.0734593 , 0.07798728, 0.07929651, 0.08680948, 0.08744803],\n",
              "       dtype=float32),\n",
              " array([0.03677979, 0.06253562, 0.06373408, 0.06821726, 0.07452413,\n",
              "        0.08532189, 0.09966504, 0.10045809, 0.10712298, 0.11302641],\n",
              "       dtype=float32),\n",
              " array([0.60454154, 0.66381466, 0.70345855, 0.7397531 , 0.7468582 ,\n",
              "        0.8134151 , 0.8303186 , 0.89999706, 0.90777206, 0.9343086 ],\n",
              "       dtype=float32),\n",
              " array([0.0488321 , 0.05984178, 0.06117014, 0.06802861, 0.07371021,\n",
              "        0.08656756, 0.08887932, 0.0978427 , 0.10381987, 0.11492497],\n",
              "       dtype=float32),\n",
              " array([0.05606231, 0.08377093, 0.09062896, 0.09736743, 0.09779052,\n",
              "        0.10153185, 0.10928775, 0.11199576, 0.12171367, 0.12753132],\n",
              "       dtype=float32),\n",
              " array([0.5835885 , 0.6039242 , 0.71894145, 0.7285656 , 0.73410547,\n",
              "        0.74966955, 0.76085013, 0.8036331 , 0.8583972 , 0.86663973],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.5500755 , 0.6367639 , 0.6375871 , 0.6773677 , 0.677517  ,\n",
              "        0.6991246 , 0.71754384, 0.75710195, 0.7672651 , 0.858981  ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.6228769, 0.6577501, 0.7138787, 0.7205024, 0.7498759, 0.8003897,\n",
              "        0.8035381, 0.8513323, 0.9074215, 0.9118812], dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.40315813, 0.446539  , 0.45530882, 0.46127063, 0.46373186,\n",
              "        0.4976153 , 0.5771403 , 0.59817487, 0.62790203, 0.69772625],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.3915777 , 0.4629101 , 0.4997164 , 0.50154805, 0.5062236 ,\n",
              "        0.51775724, 0.6101942 , 0.6129144 , 0.6369499 , 0.7488561 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.3915777 , 0.4629101 , 0.4997164 , 0.50154805, 0.5062236 ,\n",
              "        0.51775724, 0.6101942 , 0.6129144 , 0.6369499 , 0.7488561 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.31941324, 0.3471246 , 0.3748527 , 0.38994217, 0.40153992,\n",
              "        0.43964124, 0.45798   , 0.51180017, 0.5707705 , 0.6062083 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.15702374, 0.1604148 , 0.23653172, 0.23662162, 0.25123033,\n",
              "        0.26562488, 0.2775601 , 0.2931964 , 0.35840428, 0.36647543],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.14739048, 0.16174479, 0.16346267, 0.19821182, 0.20450445,\n",
              "        0.21626294, 0.25887766, 0.2675531 , 0.3111755 , 0.31597134],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.00162578, 0.03396533, 0.07289448, 0.08383859, 0.08618366,\n",
              "        0.10767529, 0.11285032, 0.12030444, 0.12547024, 0.14089589],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.12158508, 0.15266941, 0.17657396, 0.18113008, 0.19517323,\n",
              "        0.2179296 , 0.22086641, 0.28112227, 0.29848787, 0.31824064],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.24504514, 0.24954581, 0.31408444, 0.33107436, 0.35236558,\n",
              "        0.3696714 , 0.37698027, 0.40594193, 0.42999712, 0.46579236],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.1875582 , 0.2519964 , 0.28234518, 0.2996557 , 0.30632097,\n",
              "        0.32065803, 0.32572904, 0.33043888, 0.39020973, 0.4071648 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.13355775, 0.14272729, 0.17049187, 0.19733673, 0.20143954,\n",
              "        0.21704388, 0.22012103, 0.22787528, 0.25752595, 0.26157278],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.15615623, 0.16102591, 0.22570133, 0.26875985, 0.26921347,\n",
              "        0.28028443, 0.30327734, 0.3265417 , 0.35236803, 0.47786218],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.2569661 , 0.27384713, 0.2790774 , 0.32738465, 0.34541392,\n",
              "        0.34952775, 0.36579442, 0.42451376, 0.43865916, 0.44875693],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.25642157, 0.28948   , 0.2955753 , 0.3034163 , 0.35242996,\n",
              "        0.36109972, 0.36373824, 0.414063  , 0.44009122, 0.4738728 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.25254688, 0.28753033, 0.29152328, 0.3086834 , 0.34382182,\n",
              "        0.3482206 , 0.36020663, 0.41477588, 0.42679593, 0.46865505],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.25820282, 0.27134052, 0.2741761 , 0.32957327, 0.347721  ,\n",
              "        0.34865293, 0.36864436, 0.42491484, 0.44235218, 0.44801334],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.2577642 , 0.27370393, 0.28268787, 0.32679498, 0.3485857 ,\n",
              "        0.35012186, 0.37095818, 0.43367785, 0.45178866, 0.4557903 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.25149307, 0.26827446, 0.28870156, 0.2952729 , 0.34556428,\n",
              "        0.3551446 , 0.35904652, 0.38896778, 0.42951283, 0.46857777],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.37755296, 0.38059184, 0.4235559 , 0.4583231 , 0.5015805 ,\n",
              "        0.50369716, 0.54270893, 0.5445288 , 0.5675851 , 0.57712126],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.37245843, 0.3949508 , 0.39993206, 0.40829158, 0.431573  ,\n",
              "        0.4512071 , 0.4741624 , 0.5046287 , 0.53470105, 0.5630865 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.49622214, 0.5726114 , 0.5948849 , 0.59669626, 0.6284968 ,\n",
              "        0.6376883 , 0.65165025, 0.6586273 , 0.67591643, 0.7090502 ],\n",
              "       dtype=float32),\n",
              " array([0.47988355, 0.5040653 , 0.50499135, 0.5183214 , 0.56172556,\n",
              "        0.569728  , 0.5958822 , 0.62573874, 0.6796791 , 0.71833414],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.45920774, 0.47460994, 0.4909391 , 0.5198348 , 0.523121  ,\n",
              "        0.5617982 , 0.56785583, 0.59488845, 0.6336281 , 0.6975449 ],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.4895254 , 0.51535726, 0.5249221 , 0.541501  , 0.56700593,\n",
              "        0.5717859 , 0.5919663 , 0.6284732 , 0.67996573, 0.68213004],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.4896056 , 0.5104007 , 0.60698265, 0.60861313, 0.6194994 ,\n",
              "        0.64621705, 0.6492199 , 0.6505063 , 0.6553425 , 0.66568804],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.02105712, 0.04705151, 0.07288459,\n",
              "        0.09451759, 0.1078577 , 0.11839718, 0.15527132, 0.16425946],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.01282659, 0.0337716 , 0.06899516,\n",
              "        0.07590712, 0.08219758, 0.09741063, 0.15048768, 0.16069457],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " array([0.        , 0.        , 0.0197088 , 0.02938866, 0.03878339,\n",
              "        0.04625907, 0.07370926, 0.077751  , 0.08210102, 0.10831274],\n",
              "       dtype=float32),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = norm_dist_array[1]\n",
        "# Generating y values as indices (percentiles in this context)\n",
        "y_values = np.linspace(1, 100, len(array))\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(array, y_values, marker='o', linestyle='-', color='b')\n",
        "plt.title('Index (Percentile) by Value')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Percentile')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(array, bins=len(array), edgecolor='black')\n",
        "plt.title('Histogram of Values')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "H6aozTg-MlAx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b66c0d87-33e8-45e9-d87a-143500a20c27"
      },
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "need to check the below code block to see if \"predictions\" is the right data to reference (was previously coded as pred_values)"
      ],
      "metadata": {
        "id": "RnOLMEmchV8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scaled_numeric_df"
      ],
      "metadata": {
        "id": "0i-8hXaDaQDD"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keep_cols = [21,22,23,24,25,26,27,28, 29, 31,32, 33,34,36,36,37,38,39,40,41,42,43,44,45,46,47, 48]\n",
        "\n",
        "numeric_cols = predictions.iloc[:,keep_cols]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaler.fit(numeric_cols)\n",
        "\n",
        "scaled_numeric_cols = scaler.transform(numeric_cols)\n",
        "\n",
        "scaled_numeric_df = pd.DataFrame(scaled_numeric_cols, columns=numeric_cols.columns, index=numeric_cols.index)\n",
        "\n",
        "scaled_numeric_df['norm_dist_array'] = norm_dist_array\n",
        "\n",
        "id_fields = predictions[['source_dataset', 'island', 'soil_column_id', 'unique_id', 'depth_top', 'depth_bottom', 'depth_adj_bottom', 'latitude', 'longitude']]\n",
        "\n",
        "numeric_df = pd.concat([id_fields, scaled_numeric_df], axis=1)\n"
      ],
      "metadata": {
        "id": "Lj497X6z0xD0"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_df.columns"
      ],
      "metadata": {
        "id": "X8jlUy3toQ1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2594c90-2c60-4c51-a4b5-eed85949eb67"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['source_dataset', 'island', 'soil_column_id', 'unique_id', 'depth_top',\n",
              "       'depth_bottom', 'depth_adj_bottom', 'latitude', 'longitude', 'bottom',\n",
              "       'water', 'trees', 'grass', 'flooded_vegetation', 'crops',\n",
              "       'shrub_and_scrub', 'built', 'bare', 'max', 'elevation', 'landform',\n",
              "       'SRTM_mTPI', 'def', 'def', 'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad',\n",
              "       'swe', 'tmmn', 'tmmx', 'vap', 'vpd', 'vs', 'norm_dist_array'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "def build_model(input_shape,output_shape):\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_dim=input_shape),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(512, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(1024, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(output_shape, activation='linear')  # Adjust output layer according to your needs\n",
        "    ])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "rz5Tcg7Esg5v"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_numeric_df['norm_dist_array'] = scaled_numeric_df['norm_dist_array'].to_list()"
      ],
      "metadata": {
        "id": "eqy808g-wfCK"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_numeric_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "6VrpQkurzXkM"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_dist_array = np.array([i for i in scaled_numeric_df['norm_dist_array']])"
      ],
      "metadata": {
        "id": "-Ozna2FyzfY4"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = scaled_numeric_df.iloc[:, :-1]\n",
        "y = scaled_numeric_df.iloc[:, -1]\n",
        "\n",
        "x = np.array(X)\n",
        "y = np.array(norm_dist_array)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "vwKB7nY7ox_U"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train.shape[1])\n",
        "model = build_model(X_train.shape[1],output_shape=10)"
      ],
      "metadata": {
        "id": "ZeOUqKnBo2Da"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "MPAE3MPbtH0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3068258a-f871-44e0-be2c-01efc2589891"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(654, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test"
      ],
      "metadata": {
        "id": "L1sPK2nF8vAp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = build_model((X_train.shape[1]))\n",
        "# model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error',metrics = ['mae'])\n",
        "# model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=128, verbose=1)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error',metrics = ['mae'])\n",
        "model.fit(X_train, y_train, validation_split=0.2, epochs=600, batch_size=128, verbose=1)\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss='mean_squared_error',metrics = ['mae'])\n",
        "model.fit(X_train, y_train, validation_split=0.2, epochs=600, batch_size=128, verbose=1)\n",
        "\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Predictions and Evaluation\n",
        "predictions = model.predict(X_test)\n",
        "# dummy_array = np.full((len(predictions), 28), fill_value=0.5)  # Example for reverse scaling\n",
        "# dummy_array[:, -1] = predictions\n",
        "# inversed_predictions = scaler.inverse_transform(dummy_array)[:, -1]\n",
        "# dummy_array[:, -1] = y_test\n",
        "# inversed_truth = scaler.inverse_transform(dummy_array)[:, -1]\n",
        "# r_squared = r2_score(inversed_truth, inversed_predictions)\n",
        "\n",
        "# return model, test_loss, r_squared, inversed_predictions, scaler"
      ],
      "metadata": {
        "id": "r-FTSxpvowpY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "530e56a5-d69e-401b-8b47-8048be7d8611"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "5/5 [==============================] - 2s 56ms/step - loss: 0.0829 - mae: 0.2025 - val_loss: 0.0035 - val_mae: 0.0436\n",
            "Epoch 2/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0799 - mae: 0.2000 - val_loss: 0.0042 - val_mae: 0.0470\n",
            "Epoch 3/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0805 - mae: 0.2003 - val_loss: 0.0032 - val_mae: 0.0416\n",
            "Epoch 4/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0763 - mae: 0.1960 - val_loss: 0.0029 - val_mae: 0.0406\n",
            "Epoch 5/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0797 - mae: 0.1977 - val_loss: 0.0037 - val_mae: 0.0450\n",
            "Epoch 6/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0765 - mae: 0.1959 - val_loss: 0.0039 - val_mae: 0.0460\n",
            "Epoch 7/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0759 - mae: 0.1947 - val_loss: 0.0034 - val_mae: 0.0423\n",
            "Epoch 8/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0776 - mae: 0.1952 - val_loss: 0.0035 - val_mae: 0.0431\n",
            "Epoch 9/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0749 - mae: 0.1932 - val_loss: 0.0031 - val_mae: 0.0414\n",
            "Epoch 10/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0736 - mae: 0.1919 - val_loss: 0.0036 - val_mae: 0.0455\n",
            "Epoch 11/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0750 - mae: 0.1922 - val_loss: 0.0039 - val_mae: 0.0457\n",
            "Epoch 12/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0776 - mae: 0.1963 - val_loss: 0.0031 - val_mae: 0.0400\n",
            "Epoch 13/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0756 - mae: 0.1923 - val_loss: 0.0029 - val_mae: 0.0398\n",
            "Epoch 14/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0751 - mae: 0.1937 - val_loss: 0.0028 - val_mae: 0.0396\n",
            "Epoch 15/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0739 - mae: 0.1909 - val_loss: 0.0027 - val_mae: 0.0391\n",
            "Epoch 16/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0727 - mae: 0.1916 - val_loss: 0.0026 - val_mae: 0.0382\n",
            "Epoch 17/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0732 - mae: 0.1882 - val_loss: 0.0032 - val_mae: 0.0420\n",
            "Epoch 18/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0739 - mae: 0.1916 - val_loss: 0.0039 - val_mae: 0.0459\n",
            "Epoch 19/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0710 - mae: 0.1865 - val_loss: 0.0046 - val_mae: 0.0508\n",
            "Epoch 20/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0748 - mae: 0.1935 - val_loss: 0.0044 - val_mae: 0.0492\n",
            "Epoch 21/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0717 - mae: 0.1888 - val_loss: 0.0036 - val_mae: 0.0444\n",
            "Epoch 22/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0689 - mae: 0.1857 - val_loss: 0.0038 - val_mae: 0.0456\n",
            "Epoch 23/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0700 - mae: 0.1873 - val_loss: 0.0043 - val_mae: 0.0490\n",
            "Epoch 24/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0725 - mae: 0.1907 - val_loss: 0.0037 - val_mae: 0.0452\n",
            "Epoch 25/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0700 - mae: 0.1868 - val_loss: 0.0033 - val_mae: 0.0429\n",
            "Epoch 26/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0680 - mae: 0.1861 - val_loss: 0.0033 - val_mae: 0.0431\n",
            "Epoch 27/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0707 - mae: 0.1869 - val_loss: 0.0044 - val_mae: 0.0501\n",
            "Epoch 28/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0686 - mae: 0.1845 - val_loss: 0.0037 - val_mae: 0.0457\n",
            "Epoch 29/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0672 - mae: 0.1845 - val_loss: 0.0025 - val_mae: 0.0379\n",
            "Epoch 30/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0680 - mae: 0.1855 - val_loss: 0.0026 - val_mae: 0.0382\n",
            "Epoch 31/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0648 - mae: 0.1801 - val_loss: 0.0028 - val_mae: 0.0401\n",
            "Epoch 32/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0639 - mae: 0.1798 - val_loss: 0.0033 - val_mae: 0.0417\n",
            "Epoch 33/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0630 - mae: 0.1774 - val_loss: 0.0044 - val_mae: 0.0468\n",
            "Epoch 34/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0662 - mae: 0.1808 - val_loss: 0.0030 - val_mae: 0.0410\n",
            "Epoch 35/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0675 - mae: 0.1834 - val_loss: 0.0026 - val_mae: 0.0387\n",
            "Epoch 36/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0674 - mae: 0.1833 - val_loss: 0.0033 - val_mae: 0.0437\n",
            "Epoch 37/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0664 - mae: 0.1836 - val_loss: 0.0028 - val_mae: 0.0392\n",
            "Epoch 38/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0645 - mae: 0.1767 - val_loss: 0.0024 - val_mae: 0.0355\n",
            "Epoch 39/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0684 - mae: 0.1839 - val_loss: 0.0029 - val_mae: 0.0391\n",
            "Epoch 40/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0650 - mae: 0.1778 - val_loss: 0.0036 - val_mae: 0.0432\n",
            "Epoch 41/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0620 - mae: 0.1750 - val_loss: 0.0036 - val_mae: 0.0442\n",
            "Epoch 42/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0623 - mae: 0.1786 - val_loss: 0.0030 - val_mae: 0.0397\n",
            "Epoch 43/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0627 - mae: 0.1764 - val_loss: 0.0025 - val_mae: 0.0362\n",
            "Epoch 44/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0636 - mae: 0.1773 - val_loss: 0.0030 - val_mae: 0.0403\n",
            "Epoch 45/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0628 - mae: 0.1764 - val_loss: 0.0028 - val_mae: 0.0392\n",
            "Epoch 46/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0629 - mae: 0.1758 - val_loss: 0.0030 - val_mae: 0.0423\n",
            "Epoch 47/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0613 - mae: 0.1762 - val_loss: 0.0048 - val_mae: 0.0515\n",
            "Epoch 48/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0594 - mae: 0.1729 - val_loss: 0.0039 - val_mae: 0.0441\n",
            "Epoch 49/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0602 - mae: 0.1762 - val_loss: 0.0033 - val_mae: 0.0421\n",
            "Epoch 50/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0567 - mae: 0.1700 - val_loss: 0.0029 - val_mae: 0.0391\n",
            "Epoch 51/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0605 - mae: 0.1763 - val_loss: 0.0028 - val_mae: 0.0383\n",
            "Epoch 52/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0603 - mae: 0.1739 - val_loss: 0.0038 - val_mae: 0.0451\n",
            "Epoch 53/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0609 - mae: 0.1733 - val_loss: 0.0039 - val_mae: 0.0450\n",
            "Epoch 54/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0584 - mae: 0.1722 - val_loss: 0.0030 - val_mae: 0.0406\n",
            "Epoch 55/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0597 - mae: 0.1714 - val_loss: 0.0028 - val_mae: 0.0399\n",
            "Epoch 56/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0616 - mae: 0.1725 - val_loss: 0.0029 - val_mae: 0.0412\n",
            "Epoch 57/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0587 - mae: 0.1721 - val_loss: 0.0032 - val_mae: 0.0407\n",
            "Epoch 58/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0568 - mae: 0.1684 - val_loss: 0.0022 - val_mae: 0.0343\n",
            "Epoch 59/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0542 - mae: 0.1646 - val_loss: 0.0021 - val_mae: 0.0348\n",
            "Epoch 60/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0542 - mae: 0.1664 - val_loss: 0.0028 - val_mae: 0.0396\n",
            "Epoch 61/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0575 - mae: 0.1685 - val_loss: 0.0026 - val_mae: 0.0372\n",
            "Epoch 62/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0555 - mae: 0.1674 - val_loss: 0.0022 - val_mae: 0.0345\n",
            "Epoch 63/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0548 - mae: 0.1667 - val_loss: 0.0019 - val_mae: 0.0332\n",
            "Epoch 64/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0580 - mae: 0.1684 - val_loss: 0.0023 - val_mae: 0.0359\n",
            "Epoch 65/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0550 - mae: 0.1657 - val_loss: 0.0023 - val_mae: 0.0352\n",
            "Epoch 66/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0526 - mae: 0.1623 - val_loss: 0.0026 - val_mae: 0.0375\n",
            "Epoch 67/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0547 - mae: 0.1658 - val_loss: 0.0026 - val_mae: 0.0379\n",
            "Epoch 68/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0534 - mae: 0.1660 - val_loss: 0.0023 - val_mae: 0.0359\n",
            "Epoch 69/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0521 - mae: 0.1640 - val_loss: 0.0025 - val_mae: 0.0365\n",
            "Epoch 70/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0530 - mae: 0.1612 - val_loss: 0.0019 - val_mae: 0.0328\n",
            "Epoch 71/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0495 - mae: 0.1581 - val_loss: 0.0018 - val_mae: 0.0317\n",
            "Epoch 72/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0513 - mae: 0.1623 - val_loss: 0.0021 - val_mae: 0.0336\n",
            "Epoch 73/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0503 - mae: 0.1603 - val_loss: 0.0021 - val_mae: 0.0344\n",
            "Epoch 74/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0525 - mae: 0.1625 - val_loss: 0.0024 - val_mae: 0.0370\n",
            "Epoch 75/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0523 - mae: 0.1619 - val_loss: 0.0022 - val_mae: 0.0353\n",
            "Epoch 76/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0518 - mae: 0.1617 - val_loss: 0.0026 - val_mae: 0.0381\n",
            "Epoch 77/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0547 - mae: 0.1634 - val_loss: 0.0032 - val_mae: 0.0415\n",
            "Epoch 78/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0529 - mae: 0.1607 - val_loss: 0.0027 - val_mae: 0.0377\n",
            "Epoch 79/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0515 - mae: 0.1589 - val_loss: 0.0024 - val_mae: 0.0364\n",
            "Epoch 80/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0486 - mae: 0.1563 - val_loss: 0.0025 - val_mae: 0.0373\n",
            "Epoch 81/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0486 - mae: 0.1548 - val_loss: 0.0027 - val_mae: 0.0373\n",
            "Epoch 82/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0509 - mae: 0.1586 - val_loss: 0.0031 - val_mae: 0.0402\n",
            "Epoch 83/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0503 - mae: 0.1564 - val_loss: 0.0029 - val_mae: 0.0374\n",
            "Epoch 84/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0484 - mae: 0.1555 - val_loss: 0.0021 - val_mae: 0.0331\n",
            "Epoch 85/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0504 - mae: 0.1579 - val_loss: 0.0025 - val_mae: 0.0363\n",
            "Epoch 86/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0482 - mae: 0.1557 - val_loss: 0.0019 - val_mae: 0.0323\n",
            "Epoch 87/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0477 - mae: 0.1531 - val_loss: 0.0018 - val_mae: 0.0323\n",
            "Epoch 88/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0480 - mae: 0.1545 - val_loss: 0.0018 - val_mae: 0.0319\n",
            "Epoch 89/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0477 - mae: 0.1533 - val_loss: 0.0019 - val_mae: 0.0330\n",
            "Epoch 90/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0480 - mae: 0.1534 - val_loss: 0.0020 - val_mae: 0.0330\n",
            "Epoch 91/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0483 - mae: 0.1554 - val_loss: 0.0022 - val_mae: 0.0343\n",
            "Epoch 92/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0461 - mae: 0.1503 - val_loss: 0.0026 - val_mae: 0.0366\n",
            "Epoch 93/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0467 - mae: 0.1538 - val_loss: 0.0025 - val_mae: 0.0370\n",
            "Epoch 94/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0450 - mae: 0.1503 - val_loss: 0.0022 - val_mae: 0.0345\n",
            "Epoch 95/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0489 - mae: 0.1528 - val_loss: 0.0022 - val_mae: 0.0336\n",
            "Epoch 96/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0474 - mae: 0.1530 - val_loss: 0.0023 - val_mae: 0.0354\n",
            "Epoch 97/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0441 - mae: 0.1495 - val_loss: 0.0027 - val_mae: 0.0379\n",
            "Epoch 98/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0452 - mae: 0.1497 - val_loss: 0.0025 - val_mae: 0.0375\n",
            "Epoch 99/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0465 - mae: 0.1517 - val_loss: 0.0021 - val_mae: 0.0343\n",
            "Epoch 100/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0463 - mae: 0.1513 - val_loss: 0.0021 - val_mae: 0.0343\n",
            "Epoch 101/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0451 - mae: 0.1481 - val_loss: 0.0018 - val_mae: 0.0322\n",
            "Epoch 102/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0439 - mae: 0.1488 - val_loss: 0.0014 - val_mae: 0.0272\n",
            "Epoch 103/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0413 - mae: 0.1447 - val_loss: 0.0019 - val_mae: 0.0315\n",
            "Epoch 104/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0424 - mae: 0.1457 - val_loss: 0.0024 - val_mae: 0.0358\n",
            "Epoch 105/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0440 - mae: 0.1478 - val_loss: 0.0020 - val_mae: 0.0331\n",
            "Epoch 106/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0436 - mae: 0.1467 - val_loss: 0.0019 - val_mae: 0.0322\n",
            "Epoch 107/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0439 - mae: 0.1473 - val_loss: 0.0019 - val_mae: 0.0323\n",
            "Epoch 108/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0409 - mae: 0.1441 - val_loss: 0.0019 - val_mae: 0.0329\n",
            "Epoch 109/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0420 - mae: 0.1446 - val_loss: 0.0019 - val_mae: 0.0306\n",
            "Epoch 110/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0423 - mae: 0.1453 - val_loss: 0.0019 - val_mae: 0.0308\n",
            "Epoch 111/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0415 - mae: 0.1444 - val_loss: 0.0017 - val_mae: 0.0303\n",
            "Epoch 112/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0406 - mae: 0.1425 - val_loss: 0.0020 - val_mae: 0.0330\n",
            "Epoch 113/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0417 - mae: 0.1449 - val_loss: 0.0020 - val_mae: 0.0335\n",
            "Epoch 114/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0394 - mae: 0.1410 - val_loss: 0.0019 - val_mae: 0.0332\n",
            "Epoch 115/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0421 - mae: 0.1457 - val_loss: 0.0027 - val_mae: 0.0387\n",
            "Epoch 116/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0407 - mae: 0.1427 - val_loss: 0.0017 - val_mae: 0.0317\n",
            "Epoch 117/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0395 - mae: 0.1392 - val_loss: 0.0016 - val_mae: 0.0287\n",
            "Epoch 118/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0391 - mae: 0.1402 - val_loss: 0.0017 - val_mae: 0.0299\n",
            "Epoch 119/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0379 - mae: 0.1390 - val_loss: 0.0019 - val_mae: 0.0328\n",
            "Epoch 120/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0388 - mae: 0.1387 - val_loss: 0.0018 - val_mae: 0.0303\n",
            "Epoch 121/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0408 - mae: 0.1412 - val_loss: 0.0017 - val_mae: 0.0299\n",
            "Epoch 122/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0401 - mae: 0.1398 - val_loss: 0.0016 - val_mae: 0.0296\n",
            "Epoch 123/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0382 - mae: 0.1374 - val_loss: 0.0017 - val_mae: 0.0304\n",
            "Epoch 124/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0390 - mae: 0.1388 - val_loss: 0.0017 - val_mae: 0.0308\n",
            "Epoch 125/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0387 - mae: 0.1399 - val_loss: 0.0014 - val_mae: 0.0280\n",
            "Epoch 126/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0377 - mae: 0.1352 - val_loss: 0.0015 - val_mae: 0.0285\n",
            "Epoch 127/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0373 - mae: 0.1362 - val_loss: 0.0017 - val_mae: 0.0305\n",
            "Epoch 128/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0383 - mae: 0.1366 - val_loss: 0.0013 - val_mae: 0.0270\n",
            "Epoch 129/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0382 - mae: 0.1371 - val_loss: 0.0013 - val_mae: 0.0274\n",
            "Epoch 130/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0359 - mae: 0.1328 - val_loss: 0.0014 - val_mae: 0.0283\n",
            "Epoch 131/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0378 - mae: 0.1356 - val_loss: 0.0016 - val_mae: 0.0301\n",
            "Epoch 132/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0363 - mae: 0.1349 - val_loss: 0.0022 - val_mae: 0.0331\n",
            "Epoch 133/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0369 - mae: 0.1353 - val_loss: 0.0021 - val_mae: 0.0326\n",
            "Epoch 134/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0345 - mae: 0.1323 - val_loss: 0.0017 - val_mae: 0.0299\n",
            "Epoch 135/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0375 - mae: 0.1370 - val_loss: 0.0013 - val_mae: 0.0274\n",
            "Epoch 136/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0372 - mae: 0.1352 - val_loss: 0.0013 - val_mae: 0.0278\n",
            "Epoch 137/600\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0357 - mae: 0.1348 - val_loss: 0.0014 - val_mae: 0.0277\n",
            "Epoch 138/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0355 - mae: 0.1339 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 139/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0347 - mae: 0.1317 - val_loss: 0.0016 - val_mae: 0.0294\n",
            "Epoch 140/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0346 - mae: 0.1321 - val_loss: 0.0021 - val_mae: 0.0355\n",
            "Epoch 141/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0347 - mae: 0.1333 - val_loss: 0.0018 - val_mae: 0.0316\n",
            "Epoch 142/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0354 - mae: 0.1334 - val_loss: 0.0014 - val_mae: 0.0267\n",
            "Epoch 143/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0352 - mae: 0.1322 - val_loss: 0.0014 - val_mae: 0.0270\n",
            "Epoch 144/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0341 - mae: 0.1316 - val_loss: 0.0014 - val_mae: 0.0267\n",
            "Epoch 145/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0346 - mae: 0.1319 - val_loss: 0.0013 - val_mae: 0.0268\n",
            "Epoch 146/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0312 - mae: 0.1262 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 147/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0345 - mae: 0.1310 - val_loss: 0.0018 - val_mae: 0.0318\n",
            "Epoch 148/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0336 - mae: 0.1290 - val_loss: 0.0017 - val_mae: 0.0311\n",
            "Epoch 149/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0330 - mae: 0.1271 - val_loss: 0.0014 - val_mae: 0.0291\n",
            "Epoch 150/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0331 - mae: 0.1270 - val_loss: 0.0012 - val_mae: 0.0262\n",
            "Epoch 151/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0332 - mae: 0.1293 - val_loss: 0.0012 - val_mae: 0.0261\n",
            "Epoch 152/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0337 - mae: 0.1277 - val_loss: 0.0013 - val_mae: 0.0274\n",
            "Epoch 153/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0321 - mae: 0.1271 - val_loss: 0.0019 - val_mae: 0.0321\n",
            "Epoch 154/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0321 - mae: 0.1261 - val_loss: 0.0018 - val_mae: 0.0310\n",
            "Epoch 155/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0317 - mae: 0.1258 - val_loss: 0.0017 - val_mae: 0.0306\n",
            "Epoch 156/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0315 - mae: 0.1242 - val_loss: 0.0015 - val_mae: 0.0283\n",
            "Epoch 157/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0315 - mae: 0.1242 - val_loss: 9.7525e-04 - val_mae: 0.0227\n",
            "Epoch 158/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0304 - mae: 0.1237 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 159/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0296 - mae: 0.1224 - val_loss: 0.0018 - val_mae: 0.0303\n",
            "Epoch 160/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0319 - mae: 0.1261 - val_loss: 0.0016 - val_mae: 0.0296\n",
            "Epoch 161/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0316 - mae: 0.1240 - val_loss: 0.0012 - val_mae: 0.0253\n",
            "Epoch 162/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0291 - mae: 0.1206 - val_loss: 0.0013 - val_mae: 0.0268\n",
            "Epoch 163/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0293 - mae: 0.1199 - val_loss: 0.0015 - val_mae: 0.0275\n",
            "Epoch 164/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0310 - mae: 0.1243 - val_loss: 0.0014 - val_mae: 0.0268\n",
            "Epoch 165/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0302 - mae: 0.1225 - val_loss: 0.0014 - val_mae: 0.0279\n",
            "Epoch 166/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0290 - mae: 0.1211 - val_loss: 0.0013 - val_mae: 0.0273\n",
            "Epoch 167/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0309 - mae: 0.1234 - val_loss: 0.0012 - val_mae: 0.0261\n",
            "Epoch 168/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0297 - mae: 0.1209 - val_loss: 0.0012 - val_mae: 0.0258\n",
            "Epoch 169/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0291 - mae: 0.1214 - val_loss: 0.0013 - val_mae: 0.0269\n",
            "Epoch 170/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0290 - mae: 0.1215 - val_loss: 0.0013 - val_mae: 0.0267\n",
            "Epoch 171/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0298 - mae: 0.1219 - val_loss: 0.0010 - val_mae: 0.0244\n",
            "Epoch 172/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0282 - mae: 0.1187 - val_loss: 7.5640e-04 - val_mae: 0.0210\n",
            "Epoch 173/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0280 - mae: 0.1185 - val_loss: 9.5312e-04 - val_mae: 0.0236\n",
            "Epoch 174/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0283 - mae: 0.1179 - val_loss: 0.0012 - val_mae: 0.0258\n",
            "Epoch 175/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0290 - mae: 0.1191 - val_loss: 0.0014 - val_mae: 0.0267\n",
            "Epoch 176/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0262 - mae: 0.1149 - val_loss: 0.0012 - val_mae: 0.0260\n",
            "Epoch 177/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0269 - mae: 0.1163 - val_loss: 0.0015 - val_mae: 0.0286\n",
            "Epoch 178/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0282 - mae: 0.1183 - val_loss: 0.0014 - val_mae: 0.0278\n",
            "Epoch 179/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0282 - mae: 0.1178 - val_loss: 9.0979e-04 - val_mae: 0.0228\n",
            "Epoch 180/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0261 - mae: 0.1137 - val_loss: 9.4721e-04 - val_mae: 0.0232\n",
            "Epoch 181/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0260 - mae: 0.1137 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 182/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0280 - mae: 0.1182 - val_loss: 0.0011 - val_mae: 0.0244\n",
            "Epoch 183/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0275 - mae: 0.1159 - val_loss: 9.0414e-04 - val_mae: 0.0222\n",
            "Epoch 184/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0272 - mae: 0.1157 - val_loss: 9.5312e-04 - val_mae: 0.0236\n",
            "Epoch 185/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0267 - mae: 0.1152 - val_loss: 0.0011 - val_mae: 0.0248\n",
            "Epoch 186/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0245 - mae: 0.1120 - val_loss: 9.6286e-04 - val_mae: 0.0239\n",
            "Epoch 187/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0259 - mae: 0.1147 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 188/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0260 - mae: 0.1142 - val_loss: 0.0011 - val_mae: 0.0247\n",
            "Epoch 189/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0253 - mae: 0.1126 - val_loss: 8.6058e-04 - val_mae: 0.0216\n",
            "Epoch 190/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0263 - mae: 0.1137 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 191/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0254 - mae: 0.1135 - val_loss: 9.3863e-04 - val_mae: 0.0226\n",
            "Epoch 192/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0249 - mae: 0.1104 - val_loss: 8.6820e-04 - val_mae: 0.0222\n",
            "Epoch 193/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0242 - mae: 0.1100 - val_loss: 8.6358e-04 - val_mae: 0.0223\n",
            "Epoch 194/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0261 - mae: 0.1131 - val_loss: 0.0018 - val_mae: 0.0311\n",
            "Epoch 195/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0253 - mae: 0.1122 - val_loss: 0.0013 - val_mae: 0.0268\n",
            "Epoch 196/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0248 - mae: 0.1114 - val_loss: 9.6647e-04 - val_mae: 0.0215\n",
            "Epoch 197/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0253 - mae: 0.1118 - val_loss: 0.0013 - val_mae: 0.0269\n",
            "Epoch 198/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0239 - mae: 0.1093 - val_loss: 0.0014 - val_mae: 0.0281\n",
            "Epoch 199/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0243 - mae: 0.1087 - val_loss: 9.7398e-04 - val_mae: 0.0234\n",
            "Epoch 200/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0239 - mae: 0.1097 - val_loss: 8.2654e-04 - val_mae: 0.0216\n",
            "Epoch 201/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0239 - mae: 0.1089 - val_loss: 9.9921e-04 - val_mae: 0.0234\n",
            "Epoch 202/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0233 - mae: 0.1079 - val_loss: 0.0010 - val_mae: 0.0224\n",
            "Epoch 203/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0237 - mae: 0.1086 - val_loss: 9.8366e-04 - val_mae: 0.0219\n",
            "Epoch 204/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0225 - mae: 0.1066 - val_loss: 9.5562e-04 - val_mae: 0.0229\n",
            "Epoch 205/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0238 - mae: 0.1085 - val_loss: 0.0012 - val_mae: 0.0257\n",
            "Epoch 206/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0231 - mae: 0.1075 - val_loss: 0.0015 - val_mae: 0.0283\n",
            "Epoch 207/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0236 - mae: 0.1082 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 208/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0223 - mae: 0.1050 - val_loss: 8.0301e-04 - val_mae: 0.0210\n",
            "Epoch 209/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0215 - mae: 0.1034 - val_loss: 9.2453e-04 - val_mae: 0.0220\n",
            "Epoch 210/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0234 - mae: 0.1076 - val_loss: 9.3972e-04 - val_mae: 0.0227\n",
            "Epoch 211/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0212 - mae: 0.1042 - val_loss: 8.6983e-04 - val_mae: 0.0220\n",
            "Epoch 212/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0218 - mae: 0.1038 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 213/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0219 - mae: 0.1048 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 214/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0227 - mae: 0.1053 - val_loss: 8.0052e-04 - val_mae: 0.0206\n",
            "Epoch 215/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0217 - mae: 0.1030 - val_loss: 9.3090e-04 - val_mae: 0.0224\n",
            "Epoch 216/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0206 - mae: 0.1014 - val_loss: 8.3316e-04 - val_mae: 0.0218\n",
            "Epoch 217/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0210 - mae: 0.1019 - val_loss: 8.4346e-04 - val_mae: 0.0216\n",
            "Epoch 218/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0211 - mae: 0.1027 - val_loss: 0.0011 - val_mae: 0.0236\n",
            "Epoch 219/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0219 - mae: 0.1042 - val_loss: 9.7422e-04 - val_mae: 0.0227\n",
            "Epoch 220/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0219 - mae: 0.1043 - val_loss: 8.3610e-04 - val_mae: 0.0217\n",
            "Epoch 221/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0211 - mae: 0.1016 - val_loss: 8.0801e-04 - val_mae: 0.0210\n",
            "Epoch 222/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0200 - mae: 0.1003 - val_loss: 9.4155e-04 - val_mae: 0.0231\n",
            "Epoch 223/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0199 - mae: 0.0992 - val_loss: 0.0011 - val_mae: 0.0250\n",
            "Epoch 224/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0217 - mae: 0.1032 - val_loss: 0.0010 - val_mae: 0.0235\n",
            "Epoch 225/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0202 - mae: 0.1001 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 226/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0207 - mae: 0.1011 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 227/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0211 - mae: 0.1020 - val_loss: 9.0322e-04 - val_mae: 0.0225\n",
            "Epoch 228/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0209 - mae: 0.1002 - val_loss: 8.0546e-04 - val_mae: 0.0210\n",
            "Epoch 229/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0197 - mae: 0.0988 - val_loss: 7.9078e-04 - val_mae: 0.0207\n",
            "Epoch 230/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0187 - mae: 0.0968 - val_loss: 7.0823e-04 - val_mae: 0.0198\n",
            "Epoch 231/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0185 - mae: 0.0969 - val_loss: 8.5250e-04 - val_mae: 0.0217\n",
            "Epoch 232/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0212 - mae: 0.1018 - val_loss: 8.4269e-04 - val_mae: 0.0210\n",
            "Epoch 233/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0188 - mae: 0.0974 - val_loss: 8.4842e-04 - val_mae: 0.0211\n",
            "Epoch 234/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0198 - mae: 0.0978 - val_loss: 8.0009e-04 - val_mae: 0.0212\n",
            "Epoch 235/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0188 - mae: 0.0972 - val_loss: 7.2337e-04 - val_mae: 0.0203\n",
            "Epoch 236/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0195 - mae: 0.0978 - val_loss: 6.4892e-04 - val_mae: 0.0190\n",
            "Epoch 237/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0187 - mae: 0.0962 - val_loss: 9.0656e-04 - val_mae: 0.0218\n",
            "Epoch 238/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0185 - mae: 0.0961 - val_loss: 9.3366e-04 - val_mae: 0.0224\n",
            "Epoch 239/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0188 - mae: 0.0958 - val_loss: 7.2057e-04 - val_mae: 0.0197\n",
            "Epoch 240/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0180 - mae: 0.0942 - val_loss: 5.9682e-04 - val_mae: 0.0181\n",
            "Epoch 241/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0182 - mae: 0.0938 - val_loss: 6.4467e-04 - val_mae: 0.0186\n",
            "Epoch 242/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0185 - mae: 0.0961 - val_loss: 5.7673e-04 - val_mae: 0.0174\n",
            "Epoch 243/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0172 - mae: 0.0933 - val_loss: 6.7521e-04 - val_mae: 0.0187\n",
            "Epoch 244/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0178 - mae: 0.0933 - val_loss: 8.0932e-04 - val_mae: 0.0208\n",
            "Epoch 245/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0179 - mae: 0.0944 - val_loss: 7.1343e-04 - val_mae: 0.0200\n",
            "Epoch 246/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0176 - mae: 0.0925 - val_loss: 7.9100e-04 - val_mae: 0.0212\n",
            "Epoch 247/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0175 - mae: 0.0930 - val_loss: 9.0801e-04 - val_mae: 0.0220\n",
            "Epoch 248/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0181 - mae: 0.0936 - val_loss: 8.0613e-04 - val_mae: 0.0209\n",
            "Epoch 249/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0171 - mae: 0.0923 - val_loss: 7.2628e-04 - val_mae: 0.0190\n",
            "Epoch 250/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0170 - mae: 0.0915 - val_loss: 7.6086e-04 - val_mae: 0.0202\n",
            "Epoch 251/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0172 - mae: 0.0930 - val_loss: 8.1379e-04 - val_mae: 0.0214\n",
            "Epoch 252/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0168 - mae: 0.0913 - val_loss: 6.7312e-04 - val_mae: 0.0199\n",
            "Epoch 253/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0173 - mae: 0.0928 - val_loss: 7.4486e-04 - val_mae: 0.0206\n",
            "Epoch 254/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0162 - mae: 0.0898 - val_loss: 6.5178e-04 - val_mae: 0.0189\n",
            "Epoch 255/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0177 - mae: 0.0928 - val_loss: 5.6415e-04 - val_mae: 0.0175\n",
            "Epoch 256/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0168 - mae: 0.0912 - val_loss: 8.4231e-04 - val_mae: 0.0214\n",
            "Epoch 257/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0163 - mae: 0.0908 - val_loss: 6.6023e-04 - val_mae: 0.0186\n",
            "Epoch 258/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0160 - mae: 0.0899 - val_loss: 5.5666e-04 - val_mae: 0.0175\n",
            "Epoch 259/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0161 - mae: 0.0897 - val_loss: 7.2448e-04 - val_mae: 0.0200\n",
            "Epoch 260/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0162 - mae: 0.0893 - val_loss: 6.5245e-04 - val_mae: 0.0188\n",
            "Epoch 261/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0152 - mae: 0.0867 - val_loss: 6.0596e-04 - val_mae: 0.0178\n",
            "Epoch 262/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0156 - mae: 0.0879 - val_loss: 5.3645e-04 - val_mae: 0.0172\n",
            "Epoch 263/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0158 - mae: 0.0877 - val_loss: 8.2775e-04 - val_mae: 0.0215\n",
            "Epoch 264/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0157 - mae: 0.0891 - val_loss: 8.4381e-04 - val_mae: 0.0211\n",
            "Epoch 265/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0150 - mae: 0.0873 - val_loss: 7.0799e-04 - val_mae: 0.0194\n",
            "Epoch 266/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0162 - mae: 0.0887 - val_loss: 7.8305e-04 - val_mae: 0.0206\n",
            "Epoch 267/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0155 - mae: 0.0879 - val_loss: 6.9905e-04 - val_mae: 0.0202\n",
            "Epoch 268/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0160 - mae: 0.0890 - val_loss: 5.6919e-04 - val_mae: 0.0174\n",
            "Epoch 269/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0151 - mae: 0.0861 - val_loss: 6.7999e-04 - val_mae: 0.0193\n",
            "Epoch 270/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0152 - mae: 0.0861 - val_loss: 6.4769e-04 - val_mae: 0.0189\n",
            "Epoch 271/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0150 - mae: 0.0863 - val_loss: 7.0710e-04 - val_mae: 0.0200\n",
            "Epoch 272/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0144 - mae: 0.0861 - val_loss: 7.0530e-04 - val_mae: 0.0195\n",
            "Epoch 273/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0146 - mae: 0.0850 - val_loss: 8.0410e-04 - val_mae: 0.0204\n",
            "Epoch 274/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0150 - mae: 0.0866 - val_loss: 6.5192e-04 - val_mae: 0.0183\n",
            "Epoch 275/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0142 - mae: 0.0848 - val_loss: 6.5227e-04 - val_mae: 0.0189\n",
            "Epoch 276/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0145 - mae: 0.0845 - val_loss: 5.2721e-04 - val_mae: 0.0171\n",
            "Epoch 277/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0139 - mae: 0.0838 - val_loss: 8.0873e-04 - val_mae: 0.0213\n",
            "Epoch 278/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0142 - mae: 0.0829 - val_loss: 0.0011 - val_mae: 0.0236\n",
            "Epoch 279/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0142 - mae: 0.0845 - val_loss: 9.3129e-04 - val_mae: 0.0223\n",
            "Epoch 280/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0152 - mae: 0.0852 - val_loss: 5.8899e-04 - val_mae: 0.0180\n",
            "Epoch 281/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0136 - mae: 0.0831 - val_loss: 7.1005e-04 - val_mae: 0.0192\n",
            "Epoch 282/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0137 - mae: 0.0832 - val_loss: 8.2908e-04 - val_mae: 0.0203\n",
            "Epoch 283/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0140 - mae: 0.0834 - val_loss: 5.4556e-04 - val_mae: 0.0168\n",
            "Epoch 284/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.0823 - val_loss: 4.8641e-04 - val_mae: 0.0165\n",
            "Epoch 285/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.0813 - val_loss: 4.8548e-04 - val_mae: 0.0165\n",
            "Epoch 286/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0136 - mae: 0.0823 - val_loss: 5.6219e-04 - val_mae: 0.0171\n",
            "Epoch 287/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0136 - mae: 0.0820 - val_loss: 6.1210e-04 - val_mae: 0.0182\n",
            "Epoch 288/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0133 - mae: 0.0810 - val_loss: 5.1574e-04 - val_mae: 0.0166\n",
            "Epoch 289/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0134 - mae: 0.0804 - val_loss: 5.0710e-04 - val_mae: 0.0160\n",
            "Epoch 290/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.0809 - val_loss: 6.1461e-04 - val_mae: 0.0183\n",
            "Epoch 291/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0131 - mae: 0.0799 - val_loss: 7.4465e-04 - val_mae: 0.0204\n",
            "Epoch 292/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0129 - mae: 0.0807 - val_loss: 9.4158e-04 - val_mae: 0.0210\n",
            "Epoch 293/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0131 - mae: 0.0812 - val_loss: 6.1593e-04 - val_mae: 0.0185\n",
            "Epoch 294/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0123 - mae: 0.0780 - val_loss: 6.0559e-04 - val_mae: 0.0179\n",
            "Epoch 295/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0132 - mae: 0.0820 - val_loss: 6.9465e-04 - val_mae: 0.0196\n",
            "Epoch 296/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0127 - mae: 0.0789 - val_loss: 4.9113e-04 - val_mae: 0.0161\n",
            "Epoch 297/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0137 - mae: 0.0815 - val_loss: 5.9943e-04 - val_mae: 0.0181\n",
            "Epoch 298/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0122 - mae: 0.0780 - val_loss: 6.5664e-04 - val_mae: 0.0193\n",
            "Epoch 299/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0122 - mae: 0.0779 - val_loss: 5.4614e-04 - val_mae: 0.0172\n",
            "Epoch 300/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0116 - mae: 0.0766 - val_loss: 4.0612e-04 - val_mae: 0.0153\n",
            "Epoch 301/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0120 - mae: 0.0767 - val_loss: 5.7699e-04 - val_mae: 0.0174\n",
            "Epoch 302/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0127 - mae: 0.0779 - val_loss: 7.5958e-04 - val_mae: 0.0191\n",
            "Epoch 303/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0128 - mae: 0.0792 - val_loss: 4.9978e-04 - val_mae: 0.0165\n",
            "Epoch 304/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0118 - mae: 0.0767 - val_loss: 8.1294e-04 - val_mae: 0.0200\n",
            "Epoch 305/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0120 - mae: 0.0781 - val_loss: 6.1524e-04 - val_mae: 0.0185\n",
            "Epoch 306/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0119 - mae: 0.0771 - val_loss: 3.5395e-04 - val_mae: 0.0139\n",
            "Epoch 307/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0112 - mae: 0.0747 - val_loss: 4.4621e-04 - val_mae: 0.0156\n",
            "Epoch 308/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0113 - mae: 0.0753 - val_loss: 5.4833e-04 - val_mae: 0.0168\n",
            "Epoch 309/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0111 - mae: 0.0750 - val_loss: 5.3682e-04 - val_mae: 0.0166\n",
            "Epoch 310/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0119 - mae: 0.0756 - val_loss: 4.4635e-04 - val_mae: 0.0157\n",
            "Epoch 311/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0113 - mae: 0.0752 - val_loss: 5.1908e-04 - val_mae: 0.0171\n",
            "Epoch 312/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0110 - mae: 0.0749 - val_loss: 5.7348e-04 - val_mae: 0.0183\n",
            "Epoch 313/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0108 - mae: 0.0729 - val_loss: 5.1326e-04 - val_mae: 0.0169\n",
            "Epoch 314/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0115 - mae: 0.0754 - val_loss: 4.9107e-04 - val_mae: 0.0160\n",
            "Epoch 315/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0113 - mae: 0.0751 - val_loss: 5.4710e-04 - val_mae: 0.0167\n",
            "Epoch 316/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.0724 - val_loss: 4.1046e-04 - val_mae: 0.0152\n",
            "Epoch 317/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0107 - mae: 0.0732 - val_loss: 3.1359e-04 - val_mae: 0.0131\n",
            "Epoch 318/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0102 - mae: 0.0715 - val_loss: 4.4937e-04 - val_mae: 0.0157\n",
            "Epoch 319/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0105 - mae: 0.0718 - val_loss: 5.2869e-04 - val_mae: 0.0168\n",
            "Epoch 320/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0108 - mae: 0.0731 - val_loss: 5.1916e-04 - val_mae: 0.0166\n",
            "Epoch 321/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0109 - mae: 0.0727 - val_loss: 5.2788e-04 - val_mae: 0.0170\n",
            "Epoch 322/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0105 - mae: 0.0717 - val_loss: 4.2560e-04 - val_mae: 0.0156\n",
            "Epoch 323/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0105 - mae: 0.0720 - val_loss: 4.0220e-04 - val_mae: 0.0153\n",
            "Epoch 324/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0106 - mae: 0.0723 - val_loss: 3.5836e-04 - val_mae: 0.0142\n",
            "Epoch 325/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0102 - mae: 0.0714 - val_loss: 3.7597e-04 - val_mae: 0.0146\n",
            "Epoch 326/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.0715 - val_loss: 4.7415e-04 - val_mae: 0.0166\n",
            "Epoch 327/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0105 - mae: 0.0720 - val_loss: 5.3286e-04 - val_mae: 0.0171\n",
            "Epoch 328/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0101 - mae: 0.0707 - val_loss: 4.0391e-04 - val_mae: 0.0143\n",
            "Epoch 329/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0102 - mae: 0.0702 - val_loss: 4.8849e-04 - val_mae: 0.0159\n",
            "Epoch 330/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0096 - mae: 0.0692 - val_loss: 3.3906e-04 - val_mae: 0.0136\n",
            "Epoch 331/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0097 - mae: 0.0693 - val_loss: 3.4130e-04 - val_mae: 0.0137\n",
            "Epoch 332/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0095 - mae: 0.0686 - val_loss: 3.9658e-04 - val_mae: 0.0152\n",
            "Epoch 333/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0096 - mae: 0.0698 - val_loss: 6.0594e-04 - val_mae: 0.0177\n",
            "Epoch 334/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0099 - mae: 0.0700 - val_loss: 5.1485e-04 - val_mae: 0.0168\n",
            "Epoch 335/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0097 - mae: 0.0686 - val_loss: 3.2763e-04 - val_mae: 0.0131\n",
            "Epoch 336/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0092 - mae: 0.0682 - val_loss: 3.8959e-04 - val_mae: 0.0144\n",
            "Epoch 337/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0097 - mae: 0.0687 - val_loss: 2.8355e-04 - val_mae: 0.0127\n",
            "Epoch 338/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0089 - mae: 0.0673 - val_loss: 5.0427e-04 - val_mae: 0.0164\n",
            "Epoch 339/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0098 - mae: 0.0688 - val_loss: 5.5157e-04 - val_mae: 0.0165\n",
            "Epoch 340/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0097 - mae: 0.0684 - val_loss: 4.8972e-04 - val_mae: 0.0163\n",
            "Epoch 341/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0093 - mae: 0.0675 - val_loss: 4.2273e-04 - val_mae: 0.0157\n",
            "Epoch 342/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0094 - mae: 0.0676 - val_loss: 3.7768e-04 - val_mae: 0.0146\n",
            "Epoch 343/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0089 - mae: 0.0666 - val_loss: 3.2323e-04 - val_mae: 0.0133\n",
            "Epoch 344/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0087 - mae: 0.0655 - val_loss: 3.4496e-04 - val_mae: 0.0133\n",
            "Epoch 345/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0088 - mae: 0.0655 - val_loss: 3.3664e-04 - val_mae: 0.0133\n",
            "Epoch 346/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0090 - mae: 0.0671 - val_loss: 3.7763e-04 - val_mae: 0.0146\n",
            "Epoch 347/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0085 - mae: 0.0651 - val_loss: 6.2454e-04 - val_mae: 0.0188\n",
            "Epoch 348/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0090 - mae: 0.0666 - val_loss: 4.9458e-04 - val_mae: 0.0168\n",
            "Epoch 349/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0081 - mae: 0.0639 - val_loss: 2.9487e-04 - val_mae: 0.0129\n",
            "Epoch 350/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0084 - mae: 0.0647 - val_loss: 3.3586e-04 - val_mae: 0.0138\n",
            "Epoch 351/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0086 - mae: 0.0648 - val_loss: 3.0033e-04 - val_mae: 0.0132\n",
            "Epoch 352/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0083 - mae: 0.0646 - val_loss: 4.8682e-04 - val_mae: 0.0162\n",
            "Epoch 353/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0085 - mae: 0.0655 - val_loss: 3.8599e-04 - val_mae: 0.0147\n",
            "Epoch 354/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0085 - mae: 0.0645 - val_loss: 3.0888e-04 - val_mae: 0.0131\n",
            "Epoch 355/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0084 - mae: 0.0643 - val_loss: 3.5132e-04 - val_mae: 0.0142\n",
            "Epoch 356/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0084 - mae: 0.0645 - val_loss: 2.7197e-04 - val_mae: 0.0124\n",
            "Epoch 357/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0078 - mae: 0.0630 - val_loss: 3.5013e-04 - val_mae: 0.0140\n",
            "Epoch 358/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0081 - mae: 0.0633 - val_loss: 5.0554e-04 - val_mae: 0.0163\n",
            "Epoch 359/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0082 - mae: 0.0642 - val_loss: 3.6859e-04 - val_mae: 0.0138\n",
            "Epoch 360/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0081 - mae: 0.0628 - val_loss: 2.3525e-04 - val_mae: 0.0113\n",
            "Epoch 361/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0078 - mae: 0.0623 - val_loss: 3.1605e-04 - val_mae: 0.0136\n",
            "Epoch 362/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0080 - mae: 0.0633 - val_loss: 3.0401e-04 - val_mae: 0.0134\n",
            "Epoch 363/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0076 - mae: 0.0611 - val_loss: 2.7056e-04 - val_mae: 0.0123\n",
            "Epoch 364/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0075 - mae: 0.0619 - val_loss: 2.4428e-04 - val_mae: 0.0116\n",
            "Epoch 365/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0077 - mae: 0.0614 - val_loss: 2.8129e-04 - val_mae: 0.0125\n",
            "Epoch 366/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0072 - mae: 0.0605 - val_loss: 6.4554e-04 - val_mae: 0.0185\n",
            "Epoch 367/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0076 - mae: 0.0613 - val_loss: 3.3980e-04 - val_mae: 0.0138\n",
            "Epoch 368/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0073 - mae: 0.0601 - val_loss: 3.3422e-04 - val_mae: 0.0133\n",
            "Epoch 369/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0079 - mae: 0.0612 - val_loss: 4.5159e-04 - val_mae: 0.0159\n",
            "Epoch 370/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0078 - mae: 0.0617 - val_loss: 3.7492e-04 - val_mae: 0.0144\n",
            "Epoch 371/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0073 - mae: 0.0602 - val_loss: 3.7539e-04 - val_mae: 0.0148\n",
            "Epoch 372/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0072 - mae: 0.0593 - val_loss: 3.3702e-04 - val_mae: 0.0134\n",
            "Epoch 373/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0074 - mae: 0.0605 - val_loss: 3.2238e-04 - val_mae: 0.0129\n",
            "Epoch 374/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0071 - mae: 0.0595 - val_loss: 2.7646e-04 - val_mae: 0.0121\n",
            "Epoch 375/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0071 - mae: 0.0592 - val_loss: 3.1489e-04 - val_mae: 0.0130\n",
            "Epoch 376/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0071 - mae: 0.0586 - val_loss: 4.6197e-04 - val_mae: 0.0161\n",
            "Epoch 377/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0072 - mae: 0.0594 - val_loss: 3.6162e-04 - val_mae: 0.0141\n",
            "Epoch 378/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0073 - mae: 0.0600 - val_loss: 4.8265e-04 - val_mae: 0.0163\n",
            "Epoch 379/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0072 - mae: 0.0601 - val_loss: 3.3196e-04 - val_mae: 0.0138\n",
            "Epoch 380/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0067 - mae: 0.0575 - val_loss: 3.1267e-04 - val_mae: 0.0137\n",
            "Epoch 381/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0068 - mae: 0.0584 - val_loss: 2.8939e-04 - val_mae: 0.0130\n",
            "Epoch 382/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0067 - mae: 0.0574 - val_loss: 3.2247e-04 - val_mae: 0.0134\n",
            "Epoch 383/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0066 - mae: 0.0571 - val_loss: 2.6108e-04 - val_mae: 0.0119\n",
            "Epoch 384/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0064 - mae: 0.0568 - val_loss: 2.0923e-04 - val_mae: 0.0108\n",
            "Epoch 385/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0063 - mae: 0.0555 - val_loss: 2.8506e-04 - val_mae: 0.0125\n",
            "Epoch 386/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0063 - mae: 0.0564 - val_loss: 2.8114e-04 - val_mae: 0.0126\n",
            "Epoch 387/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0067 - mae: 0.0572 - val_loss: 2.5689e-04 - val_mae: 0.0119\n",
            "Epoch 388/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0063 - mae: 0.0558 - val_loss: 3.3228e-04 - val_mae: 0.0134\n",
            "Epoch 389/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0068 - mae: 0.0574 - val_loss: 3.0372e-04 - val_mae: 0.0127\n",
            "Epoch 390/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0062 - mae: 0.0560 - val_loss: 1.9999e-04 - val_mae: 0.0106\n",
            "Epoch 391/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0063 - mae: 0.0559 - val_loss: 2.8296e-04 - val_mae: 0.0124\n",
            "Epoch 392/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0065 - mae: 0.0559 - val_loss: 2.4716e-04 - val_mae: 0.0117\n",
            "Epoch 393/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0061 - mae: 0.0549 - val_loss: 2.0049e-04 - val_mae: 0.0102\n",
            "Epoch 394/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0062 - mae: 0.0543 - val_loss: 2.3191e-04 - val_mae: 0.0111\n",
            "Epoch 395/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0060 - mae: 0.0545 - val_loss: 2.3353e-04 - val_mae: 0.0114\n",
            "Epoch 396/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0064 - mae: 0.0556 - val_loss: 2.1414e-04 - val_mae: 0.0108\n",
            "Epoch 397/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0059 - mae: 0.0539 - val_loss: 2.2206e-04 - val_mae: 0.0110\n",
            "Epoch 398/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0062 - mae: 0.0548 - val_loss: 2.9702e-04 - val_mae: 0.0128\n",
            "Epoch 399/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0058 - mae: 0.0536 - val_loss: 2.3232e-04 - val_mae: 0.0108\n",
            "Epoch 400/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0056 - mae: 0.0529 - val_loss: 2.3890e-04 - val_mae: 0.0109\n",
            "Epoch 401/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0056 - mae: 0.0527 - val_loss: 2.3011e-04 - val_mae: 0.0115\n",
            "Epoch 402/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0057 - mae: 0.0529 - val_loss: 2.3410e-04 - val_mae: 0.0114\n",
            "Epoch 403/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0503 - val_loss: 2.1567e-04 - val_mae: 0.0110\n",
            "Epoch 404/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0054 - mae: 0.0520 - val_loss: 2.0900e-04 - val_mae: 0.0108\n",
            "Epoch 405/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0055 - mae: 0.0527 - val_loss: 3.0840e-04 - val_mae: 0.0123\n",
            "Epoch 406/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0057 - mae: 0.0528 - val_loss: 2.3274e-04 - val_mae: 0.0111\n",
            "Epoch 407/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0509 - val_loss: 1.8292e-04 - val_mae: 0.0100\n",
            "Epoch 408/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0056 - mae: 0.0517 - val_loss: 2.2001e-04 - val_mae: 0.0108\n",
            "Epoch 409/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0054 - mae: 0.0516 - val_loss: 1.8914e-04 - val_mae: 0.0101\n",
            "Epoch 410/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0510 - val_loss: 3.1793e-04 - val_mae: 0.0132\n",
            "Epoch 411/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0056 - mae: 0.0523 - val_loss: 2.4772e-04 - val_mae: 0.0116\n",
            "Epoch 412/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0505 - val_loss: 1.6785e-04 - val_mae: 0.0097\n",
            "Epoch 413/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0052 - mae: 0.0506 - val_loss: 2.2033e-04 - val_mae: 0.0113\n",
            "Epoch 414/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0055 - mae: 0.0520 - val_loss: 2.6936e-04 - val_mae: 0.0121\n",
            "Epoch 415/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0498 - val_loss: 1.7662e-04 - val_mae: 0.0099\n",
            "Epoch 416/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0051 - mae: 0.0504 - val_loss: 2.1135e-04 - val_mae: 0.0107\n",
            "Epoch 417/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0050 - mae: 0.0497 - val_loss: 2.2052e-04 - val_mae: 0.0111\n",
            "Epoch 418/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0050 - mae: 0.0502 - val_loss: 1.6795e-04 - val_mae: 0.0095\n",
            "Epoch 419/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0051 - mae: 0.0494 - val_loss: 2.0024e-04 - val_mae: 0.0100\n",
            "Epoch 420/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0052 - mae: 0.0504 - val_loss: 2.0743e-04 - val_mae: 0.0104\n",
            "Epoch 421/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0050 - mae: 0.0498 - val_loss: 1.7241e-04 - val_mae: 0.0094\n",
            "Epoch 422/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0048 - mae: 0.0490 - val_loss: 1.8782e-04 - val_mae: 0.0101\n",
            "Epoch 423/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0478 - val_loss: 2.1640e-04 - val_mae: 0.0108\n",
            "Epoch 424/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0050 - mae: 0.0494 - val_loss: 2.3712e-04 - val_mae: 0.0109\n",
            "Epoch 425/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0048 - mae: 0.0484 - val_loss: 1.9434e-04 - val_mae: 0.0097\n",
            "Epoch 426/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0480 - val_loss: 1.8969e-04 - val_mae: 0.0098\n",
            "Epoch 427/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0048 - mae: 0.0473 - val_loss: 1.8954e-04 - val_mae: 0.0101\n",
            "Epoch 428/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0469 - val_loss: 2.1526e-04 - val_mae: 0.0109\n",
            "Epoch 429/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0481 - val_loss: 1.7018e-04 - val_mae: 0.0096\n",
            "Epoch 430/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0465 - val_loss: 1.8355e-04 - val_mae: 0.0104\n",
            "Epoch 431/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0470 - val_loss: 1.7585e-04 - val_mae: 0.0099\n",
            "Epoch 432/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0476 - val_loss: 1.6979e-04 - val_mae: 0.0097\n",
            "Epoch 433/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0465 - val_loss: 2.2390e-04 - val_mae: 0.0105\n",
            "Epoch 434/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0474 - val_loss: 1.7054e-04 - val_mae: 0.0096\n",
            "Epoch 435/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0458 - val_loss: 1.7807e-04 - val_mae: 0.0097\n",
            "Epoch 436/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0463 - val_loss: 1.6981e-04 - val_mae: 0.0093\n",
            "Epoch 437/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0463 - val_loss: 1.7011e-04 - val_mae: 0.0095\n",
            "Epoch 438/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0041 - mae: 0.0448 - val_loss: 1.7959e-04 - val_mae: 0.0097\n",
            "Epoch 439/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0460 - val_loss: 1.7511e-04 - val_mae: 0.0099\n",
            "Epoch 440/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0453 - val_loss: 2.0831e-04 - val_mae: 0.0110\n",
            "Epoch 441/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0455 - val_loss: 1.6609e-04 - val_mae: 0.0094\n",
            "Epoch 442/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0041 - mae: 0.0451 - val_loss: 2.0983e-04 - val_mae: 0.0103\n",
            "Epoch 443/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0039 - mae: 0.0444 - val_loss: 2.4185e-04 - val_mae: 0.0111\n",
            "Epoch 444/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0453 - val_loss: 1.9139e-04 - val_mae: 0.0103\n",
            "Epoch 445/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0039 - mae: 0.0446 - val_loss: 1.7836e-04 - val_mae: 0.0101\n",
            "Epoch 446/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0040 - mae: 0.0439 - val_loss: 1.8453e-04 - val_mae: 0.0101\n",
            "Epoch 447/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0041 - mae: 0.0447 - val_loss: 2.2539e-04 - val_mae: 0.0111\n",
            "Epoch 448/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0039 - mae: 0.0440 - val_loss: 1.5819e-04 - val_mae: 0.0095\n",
            "Epoch 449/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0039 - mae: 0.0435 - val_loss: 2.2311e-04 - val_mae: 0.0111\n",
            "Epoch 450/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0040 - mae: 0.0446 - val_loss: 2.3560e-04 - val_mae: 0.0108\n",
            "Epoch 451/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0039 - mae: 0.0443 - val_loss: 1.6479e-04 - val_mae: 0.0094\n",
            "Epoch 452/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0038 - mae: 0.0429 - val_loss: 2.0163e-04 - val_mae: 0.0102\n",
            "Epoch 453/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0038 - mae: 0.0430 - val_loss: 1.5941e-04 - val_mae: 0.0092\n",
            "Epoch 454/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0037 - mae: 0.0431 - val_loss: 1.9106e-04 - val_mae: 0.0101\n",
            "Epoch 455/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0037 - mae: 0.0427 - val_loss: 1.4500e-04 - val_mae: 0.0087\n",
            "Epoch 456/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0035 - mae: 0.0420 - val_loss: 1.5879e-04 - val_mae: 0.0092\n",
            "Epoch 457/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0035 - mae: 0.0419 - val_loss: 2.0887e-04 - val_mae: 0.0105\n",
            "Epoch 458/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0034 - mae: 0.0413 - val_loss: 2.0528e-04 - val_mae: 0.0104\n",
            "Epoch 459/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0035 - mae: 0.0418 - val_loss: 1.7482e-04 - val_mae: 0.0097\n",
            "Epoch 460/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 1.5878e-04 - val_mae: 0.0091\n",
            "Epoch 461/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0035 - mae: 0.0413 - val_loss: 1.5044e-04 - val_mae: 0.0089\n",
            "Epoch 462/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0035 - mae: 0.0416 - val_loss: 2.1904e-04 - val_mae: 0.0105\n",
            "Epoch 463/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0036 - mae: 0.0419 - val_loss: 2.0223e-04 - val_mae: 0.0104\n",
            "Epoch 464/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0035 - mae: 0.0419 - val_loss: 2.8230e-04 - val_mae: 0.0120\n",
            "Epoch 465/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0408 - val_loss: 2.3039e-04 - val_mae: 0.0113\n",
            "Epoch 466/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0409 - val_loss: 1.6466e-04 - val_mae: 0.0097\n",
            "Epoch 467/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0405 - val_loss: 1.2479e-04 - val_mae: 0.0080\n",
            "Epoch 468/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0411 - val_loss: 1.3702e-04 - val_mae: 0.0086\n",
            "Epoch 469/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0399 - val_loss: 1.5735e-04 - val_mae: 0.0092\n",
            "Epoch 470/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0033 - mae: 0.0404 - val_loss: 1.6137e-04 - val_mae: 0.0093\n",
            "Epoch 471/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0033 - mae: 0.0399 - val_loss: 1.4495e-04 - val_mae: 0.0087\n",
            "Epoch 472/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0392 - val_loss: 1.6199e-04 - val_mae: 0.0094\n",
            "Epoch 473/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0031 - mae: 0.0391 - val_loss: 1.3180e-04 - val_mae: 0.0084\n",
            "Epoch 474/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0031 - mae: 0.0388 - val_loss: 1.3565e-04 - val_mae: 0.0085\n",
            "Epoch 475/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0032 - mae: 0.0395 - val_loss: 1.5681e-04 - val_mae: 0.0091\n",
            "Epoch 476/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0387 - val_loss: 1.4232e-04 - val_mae: 0.0086\n",
            "Epoch 477/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0387 - val_loss: 1.4479e-04 - val_mae: 0.0086\n",
            "Epoch 478/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0382 - val_loss: 1.3792e-04 - val_mae: 0.0085\n",
            "Epoch 479/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0386 - val_loss: 1.7062e-04 - val_mae: 0.0096\n",
            "Epoch 480/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0031 - mae: 0.0388 - val_loss: 1.6696e-04 - val_mae: 0.0090\n",
            "Epoch 481/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0029 - mae: 0.0374 - val_loss: 1.5795e-04 - val_mae: 0.0092\n",
            "Epoch 482/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0029 - mae: 0.0374 - val_loss: 1.5996e-04 - val_mae: 0.0092\n",
            "Epoch 483/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0381 - val_loss: 1.6272e-04 - val_mae: 0.0090\n",
            "Epoch 484/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0381 - val_loss: 1.4424e-04 - val_mae: 0.0084\n",
            "Epoch 485/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0028 - mae: 0.0373 - val_loss: 1.8796e-04 - val_mae: 0.0101\n",
            "Epoch 486/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0029 - mae: 0.0375 - val_loss: 1.5622e-04 - val_mae: 0.0091\n",
            "Epoch 487/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0027 - mae: 0.0360 - val_loss: 2.0774e-04 - val_mae: 0.0106\n",
            "Epoch 488/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0029 - mae: 0.0380 - val_loss: 1.3655e-04 - val_mae: 0.0087\n",
            "Epoch 489/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0027 - mae: 0.0363 - val_loss: 1.3296e-04 - val_mae: 0.0084\n",
            "Epoch 490/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0029 - mae: 0.0375 - val_loss: 1.7080e-04 - val_mae: 0.0094\n",
            "Epoch 491/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0027 - mae: 0.0366 - val_loss: 1.0584e-04 - val_mae: 0.0075\n",
            "Epoch 492/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0026 - mae: 0.0362 - val_loss: 1.2980e-04 - val_mae: 0.0079\n",
            "Epoch 493/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - mae: 0.0354 - val_loss: 1.0943e-04 - val_mae: 0.0076\n",
            "Epoch 494/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0028 - mae: 0.0367 - val_loss: 1.0133e-04 - val_mae: 0.0074\n",
            "Epoch 495/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0025 - mae: 0.0354 - val_loss: 1.0635e-04 - val_mae: 0.0074\n",
            "Epoch 496/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0025 - mae: 0.0353 - val_loss: 1.2763e-04 - val_mae: 0.0084\n",
            "Epoch 497/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0027 - mae: 0.0363 - val_loss: 1.3494e-04 - val_mae: 0.0085\n",
            "Epoch 498/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0027 - mae: 0.0356 - val_loss: 1.0912e-04 - val_mae: 0.0076\n",
            "Epoch 499/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - mae: 0.0355 - val_loss: 1.2355e-04 - val_mae: 0.0080\n",
            "Epoch 500/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0026 - mae: 0.0356 - val_loss: 1.7103e-04 - val_mae: 0.0095\n",
            "Epoch 501/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - mae: 0.0342 - val_loss: 1.0923e-04 - val_mae: 0.0075\n",
            "Epoch 502/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0025 - mae: 0.0353 - val_loss: 1.2109e-04 - val_mae: 0.0078\n",
            "Epoch 503/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - mae: 0.0345 - val_loss: 1.2949e-04 - val_mae: 0.0083\n",
            "Epoch 504/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0024 - mae: 0.0345 - val_loss: 1.3020e-04 - val_mae: 0.0081\n",
            "Epoch 505/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0024 - mae: 0.0344 - val_loss: 1.1124e-04 - val_mae: 0.0077\n",
            "Epoch 506/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0023 - mae: 0.0335 - val_loss: 1.0183e-04 - val_mae: 0.0074\n",
            "Epoch 507/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 1.2522e-04 - val_mae: 0.0082\n",
            "Epoch 508/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - mae: 0.0330 - val_loss: 1.4120e-04 - val_mae: 0.0083\n",
            "Epoch 509/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0024 - mae: 0.0337 - val_loss: 1.6116e-04 - val_mae: 0.0091\n",
            "Epoch 510/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0024 - mae: 0.0340 - val_loss: 1.4140e-04 - val_mae: 0.0086\n",
            "Epoch 511/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - mae: 0.0331 - val_loss: 1.1609e-04 - val_mae: 0.0078\n",
            "Epoch 512/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0023 - mae: 0.0334 - val_loss: 1.2033e-04 - val_mae: 0.0081\n",
            "Epoch 513/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - mae: 0.0330 - val_loss: 1.1195e-04 - val_mae: 0.0076\n",
            "Epoch 514/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - mae: 0.0331 - val_loss: 9.4835e-05 - val_mae: 0.0069\n",
            "Epoch 515/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - mae: 0.0328 - val_loss: 1.0690e-04 - val_mae: 0.0077\n",
            "Epoch 516/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 1.0218e-04 - val_mae: 0.0073\n",
            "Epoch 517/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 1.1493e-04 - val_mae: 0.0077\n",
            "Epoch 518/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - mae: 0.0316 - val_loss: 1.0554e-04 - val_mae: 0.0075\n",
            "Epoch 519/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 1.1261e-04 - val_mae: 0.0079\n",
            "Epoch 520/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - mae: 0.0313 - val_loss: 1.3785e-04 - val_mae: 0.0085\n",
            "Epoch 521/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 1.6593e-04 - val_mae: 0.0085\n",
            "Epoch 522/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - mae: 0.0315 - val_loss: 1.2120e-04 - val_mae: 0.0076\n",
            "Epoch 523/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 1.1847e-04 - val_mae: 0.0078\n",
            "Epoch 524/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 1.1618e-04 - val_mae: 0.0080\n",
            "Epoch 525/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - mae: 0.0307 - val_loss: 1.0598e-04 - val_mae: 0.0074\n",
            "Epoch 526/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 1.2646e-04 - val_mae: 0.0083\n",
            "Epoch 527/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0019 - mae: 0.0303 - val_loss: 1.1730e-04 - val_mae: 0.0079\n",
            "Epoch 528/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 1.1576e-04 - val_mae: 0.0079\n",
            "Epoch 529/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 1.4251e-04 - val_mae: 0.0087\n",
            "Epoch 530/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0019 - mae: 0.0306 - val_loss: 1.1437e-04 - val_mae: 0.0077\n",
            "Epoch 531/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0019 - mae: 0.0306 - val_loss: 1.3323e-04 - val_mae: 0.0086\n",
            "Epoch 532/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 1.6593e-04 - val_mae: 0.0093\n",
            "Epoch 533/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 1.0571e-04 - val_mae: 0.0073\n",
            "Epoch 534/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - mae: 0.0294 - val_loss: 1.1203e-04 - val_mae: 0.0075\n",
            "Epoch 535/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - mae: 0.0294 - val_loss: 1.3046e-04 - val_mae: 0.0080\n",
            "Epoch 536/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - mae: 0.0299 - val_loss: 1.2075e-04 - val_mae: 0.0077\n",
            "Epoch 537/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - mae: 0.0295 - val_loss: 1.2887e-04 - val_mae: 0.0082\n",
            "Epoch 538/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 1.1090e-04 - val_mae: 0.0073\n",
            "Epoch 539/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 1.1568e-04 - val_mae: 0.0079\n",
            "Epoch 540/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 1.1548e-04 - val_mae: 0.0075\n",
            "Epoch 541/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 1.3082e-04 - val_mae: 0.0081\n",
            "Epoch 542/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 1.3921e-04 - val_mae: 0.0084\n",
            "Epoch 543/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0017 - mae: 0.0286 - val_loss: 9.8548e-05 - val_mae: 0.0071\n",
            "Epoch 544/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 8.2868e-05 - val_mae: 0.0063\n",
            "Epoch 545/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 1.0356e-04 - val_mae: 0.0072\n",
            "Epoch 546/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - mae: 0.0286 - val_loss: 9.5524e-05 - val_mae: 0.0068\n",
            "Epoch 547/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 8.0088e-05 - val_mae: 0.0063\n",
            "Epoch 548/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 7.8504e-05 - val_mae: 0.0062\n",
            "Epoch 549/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 8.2572e-05 - val_mae: 0.0062\n",
            "Epoch 550/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 9.1954e-05 - val_mae: 0.0067\n",
            "Epoch 551/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 8.4849e-05 - val_mae: 0.0065\n",
            "Epoch 552/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 9.7811e-05 - val_mae: 0.0068\n",
            "Epoch 553/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 9.4973e-05 - val_mae: 0.0069\n",
            "Epoch 554/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 1.2041e-04 - val_mae: 0.0076\n",
            "Epoch 555/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 8.3163e-05 - val_mae: 0.0067\n",
            "Epoch 556/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 8.6437e-05 - val_mae: 0.0066\n",
            "Epoch 557/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 9.0141e-05 - val_mae: 0.0068\n",
            "Epoch 558/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 9.0810e-05 - val_mae: 0.0065\n",
            "Epoch 559/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 1.0159e-04 - val_mae: 0.0066\n",
            "Epoch 560/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 1.7237e-04 - val_mae: 0.0093\n",
            "Epoch 561/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 8.4173e-05 - val_mae: 0.0067\n",
            "Epoch 562/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 1.2644e-04 - val_mae: 0.0080\n",
            "Epoch 563/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 1.0428e-04 - val_mae: 0.0068\n",
            "Epoch 564/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 7.7610e-05 - val_mae: 0.0064\n",
            "Epoch 565/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 8.9912e-05 - val_mae: 0.0068\n",
            "Epoch 566/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 1.2147e-04 - val_mae: 0.0078\n",
            "Epoch 567/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 7.8180e-05 - val_mae: 0.0062\n",
            "Epoch 568/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 7.8728e-05 - val_mae: 0.0062\n",
            "Epoch 569/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 8.7523e-05 - val_mae: 0.0066\n",
            "Epoch 570/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mae: 0.0251 - val_loss: 1.1558e-04 - val_mae: 0.0078\n",
            "Epoch 571/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 8.9438e-05 - val_mae: 0.0067\n",
            "Epoch 572/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 9.5748e-05 - val_mae: 0.0069\n",
            "Epoch 573/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0247 - val_loss: 7.8179e-05 - val_mae: 0.0062\n",
            "Epoch 574/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 5.9432e-05 - val_mae: 0.0051\n",
            "Epoch 575/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 8.6695e-05 - val_mae: 0.0066\n",
            "Epoch 576/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 8.7853e-05 - val_mae: 0.0066\n",
            "Epoch 577/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 8.5987e-05 - val_mae: 0.0068\n",
            "Epoch 578/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 7.8648e-05 - val_mae: 0.0061\n",
            "Epoch 579/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 9.3731e-05 - val_mae: 0.0066\n",
            "Epoch 580/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 8.0273e-05 - val_mae: 0.0062\n",
            "Epoch 581/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 7.1842e-05 - val_mae: 0.0062\n",
            "Epoch 582/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0236 - val_loss: 7.6369e-05 - val_mae: 0.0062\n",
            "Epoch 583/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 8.7369e-05 - val_mae: 0.0067\n",
            "Epoch 584/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 8.5309e-05 - val_mae: 0.0066\n",
            "Epoch 585/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 6.4040e-05 - val_mae: 0.0057\n",
            "Epoch 586/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 6.6748e-05 - val_mae: 0.0058\n",
            "Epoch 587/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0010 - mae: 0.0227 - val_loss: 7.0963e-05 - val_mae: 0.0061\n",
            "Epoch 588/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 7.4492e-05 - val_mae: 0.0060\n",
            "Epoch 589/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 8.3421e-05 - val_mae: 0.0065\n",
            "Epoch 590/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 6.6319e-05 - val_mae: 0.0058\n",
            "Epoch 591/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.6738e-04 - mae: 0.0217 - val_loss: 6.3911e-05 - val_mae: 0.0055\n",
            "Epoch 592/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 6.7326e-05 - val_mae: 0.0058\n",
            "Epoch 593/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.3027e-04 - mae: 0.0216 - val_loss: 9.0122e-05 - val_mae: 0.0069\n",
            "Epoch 594/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 8.7063e-05 - val_mae: 0.0065\n",
            "Epoch 595/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0010 - mae: 0.0219 - val_loss: 8.6726e-05 - val_mae: 0.0061\n",
            "Epoch 596/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0010 - mae: 0.0222 - val_loss: 9.0612e-05 - val_mae: 0.0063\n",
            "Epoch 597/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0010 - mae: 0.0222 - val_loss: 9.0856e-05 - val_mae: 0.0063\n",
            "Epoch 598/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.3112e-04 - mae: 0.0215 - val_loss: 8.7340e-05 - val_mae: 0.0061\n",
            "Epoch 599/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.9245e-04 - mae: 0.0217 - val_loss: 7.1746e-05 - val_mae: 0.0057\n",
            "Epoch 600/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.3859e-04 - mae: 0.0210 - val_loss: 6.8872e-05 - val_mae: 0.0056\n",
            "Epoch 1/600\n",
            "5/5 [==============================] - 4s 58ms/step - loss: 8.9454e-04 - mae: 0.0210 - val_loss: 6.2417e-05 - val_mae: 0.0051\n",
            "Epoch 2/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.9120e-04 - mae: 0.0208 - val_loss: 6.2262e-05 - val_mae: 0.0052\n",
            "Epoch 3/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.0677e-04 - mae: 0.0209 - val_loss: 5.6116e-05 - val_mae: 0.0048\n",
            "Epoch 4/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.7847e-04 - mae: 0.0207 - val_loss: 5.7343e-05 - val_mae: 0.0050\n",
            "Epoch 5/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.1848e-04 - mae: 0.0209 - val_loss: 5.2945e-05 - val_mae: 0.0048\n",
            "Epoch 6/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.9248e-04 - mae: 0.0208 - val_loss: 5.1065e-05 - val_mae: 0.0046\n",
            "Epoch 7/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.8388e-04 - mae: 0.0208 - val_loss: 5.0212e-05 - val_mae: 0.0046\n",
            "Epoch 8/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.6011e-04 - mae: 0.0204 - val_loss: 5.6475e-05 - val_mae: 0.0051\n",
            "Epoch 9/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.8469e-04 - mae: 0.0206 - val_loss: 6.5115e-05 - val_mae: 0.0055\n",
            "Epoch 10/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.0512e-04 - mae: 0.0201 - val_loss: 6.8471e-05 - val_mae: 0.0057\n",
            "Epoch 11/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.6059e-04 - mae: 0.0206 - val_loss: 6.1239e-05 - val_mae: 0.0052\n",
            "Epoch 12/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.9296e-04 - mae: 0.0209 - val_loss: 5.9052e-05 - val_mae: 0.0051\n",
            "Epoch 13/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.4907e-04 - mae: 0.0201 - val_loss: 5.6271e-05 - val_mae: 0.0049\n",
            "Epoch 14/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.8240e-04 - mae: 0.0207 - val_loss: 5.6171e-05 - val_mae: 0.0050\n",
            "Epoch 15/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.6041e-04 - mae: 0.0206 - val_loss: 6.0975e-05 - val_mae: 0.0053\n",
            "Epoch 16/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.4266e-04 - mae: 0.0203 - val_loss: 6.2618e-05 - val_mae: 0.0053\n",
            "Epoch 17/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.4416e-04 - mae: 0.0197 - val_loss: 6.1661e-05 - val_mae: 0.0052\n",
            "Epoch 18/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.4021e-04 - mae: 0.0203 - val_loss: 5.9103e-05 - val_mae: 0.0051\n",
            "Epoch 19/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.7462e-04 - mae: 0.0206 - val_loss: 5.7531e-05 - val_mae: 0.0052\n",
            "Epoch 20/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.0976e-04 - mae: 0.0202 - val_loss: 5.6925e-05 - val_mae: 0.0051\n",
            "Epoch 21/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.3156e-04 - mae: 0.0202 - val_loss: 5.2803e-05 - val_mae: 0.0048\n",
            "Epoch 22/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.2946e-04 - mae: 0.0199 - val_loss: 5.1664e-05 - val_mae: 0.0046\n",
            "Epoch 23/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.5735e-04 - mae: 0.0200 - val_loss: 4.9789e-05 - val_mae: 0.0045\n",
            "Epoch 24/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.1801e-04 - mae: 0.0196 - val_loss: 5.1151e-05 - val_mae: 0.0047\n",
            "Epoch 25/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.1716e-04 - mae: 0.0199 - val_loss: 5.0326e-05 - val_mae: 0.0046\n",
            "Epoch 26/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.8336e-04 - mae: 0.0197 - val_loss: 4.8438e-05 - val_mae: 0.0044\n",
            "Epoch 27/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.1476e-04 - mae: 0.0199 - val_loss: 4.9721e-05 - val_mae: 0.0044\n",
            "Epoch 28/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.3781e-04 - mae: 0.0199 - val_loss: 5.2811e-05 - val_mae: 0.0046\n",
            "Epoch 29/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.1370e-04 - mae: 0.0200 - val_loss: 5.4607e-05 - val_mae: 0.0047\n",
            "Epoch 30/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.7976e-04 - mae: 0.0194 - val_loss: 5.2829e-05 - val_mae: 0.0047\n",
            "Epoch 31/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.8683e-04 - mae: 0.0194 - val_loss: 5.5319e-05 - val_mae: 0.0049\n",
            "Epoch 32/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.8156e-04 - mae: 0.0196 - val_loss: 5.6553e-05 - val_mae: 0.0048\n",
            "Epoch 33/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.8603e-04 - mae: 0.0194 - val_loss: 5.7240e-05 - val_mae: 0.0048\n",
            "Epoch 34/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.9728e-04 - mae: 0.0196 - val_loss: 5.6850e-05 - val_mae: 0.0050\n",
            "Epoch 35/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.8696e-04 - mae: 0.0192 - val_loss: 5.1880e-05 - val_mae: 0.0048\n",
            "Epoch 36/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.1281e-04 - mae: 0.0197 - val_loss: 4.8982e-05 - val_mae: 0.0046\n",
            "Epoch 37/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.7398e-04 - mae: 0.0192 - val_loss: 4.9558e-05 - val_mae: 0.0046\n",
            "Epoch 38/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.0186e-04 - mae: 0.0196 - val_loss: 4.6905e-05 - val_mae: 0.0045\n",
            "Epoch 39/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.9009e-04 - mae: 0.0196 - val_loss: 5.1770e-05 - val_mae: 0.0047\n",
            "Epoch 40/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.7933e-04 - mae: 0.0194 - val_loss: 5.2745e-05 - val_mae: 0.0046\n",
            "Epoch 41/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.0120e-04 - mae: 0.0192 - val_loss: 4.9191e-05 - val_mae: 0.0045\n",
            "Epoch 42/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.6923e-04 - mae: 0.0190 - val_loss: 4.7781e-05 - val_mae: 0.0045\n",
            "Epoch 43/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.5351e-04 - mae: 0.0191 - val_loss: 4.5501e-05 - val_mae: 0.0044\n",
            "Epoch 44/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.9226e-04 - mae: 0.0194 - val_loss: 4.8046e-05 - val_mae: 0.0045\n",
            "Epoch 45/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.5727e-04 - mae: 0.0192 - val_loss: 5.0908e-05 - val_mae: 0.0047\n",
            "Epoch 46/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.9992e-04 - mae: 0.0186 - val_loss: 5.3162e-05 - val_mae: 0.0047\n",
            "Epoch 47/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.2037e-04 - mae: 0.0189 - val_loss: 5.3816e-05 - val_mae: 0.0046\n",
            "Epoch 48/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.5131e-04 - mae: 0.0190 - val_loss: 4.9330e-05 - val_mae: 0.0044\n",
            "Epoch 49/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.6416e-04 - mae: 0.0189 - val_loss: 4.5471e-05 - val_mae: 0.0043\n",
            "Epoch 50/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.3304e-04 - mae: 0.0187 - val_loss: 4.6249e-05 - val_mae: 0.0043\n",
            "Epoch 51/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.6667e-04 - mae: 0.0191 - val_loss: 4.9171e-05 - val_mae: 0.0046\n",
            "Epoch 52/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.4095e-04 - mae: 0.0187 - val_loss: 4.9151e-05 - val_mae: 0.0045\n",
            "Epoch 53/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.3585e-04 - mae: 0.0189 - val_loss: 5.1364e-05 - val_mae: 0.0045\n",
            "Epoch 54/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.4385e-04 - mae: 0.0188 - val_loss: 5.1762e-05 - val_mae: 0.0046\n",
            "Epoch 55/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.8859e-04 - mae: 0.0184 - val_loss: 5.1121e-05 - val_mae: 0.0047\n",
            "Epoch 56/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.5605e-04 - mae: 0.0190 - val_loss: 4.9808e-05 - val_mae: 0.0046\n",
            "Epoch 57/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.3783e-04 - mae: 0.0186 - val_loss: 4.9416e-05 - val_mae: 0.0046\n",
            "Epoch 58/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.0406e-04 - mae: 0.0186 - val_loss: 4.8108e-05 - val_mae: 0.0045\n",
            "Epoch 59/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.9348e-04 - mae: 0.0180 - val_loss: 4.8136e-05 - val_mae: 0.0044\n",
            "Epoch 60/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.5896e-04 - mae: 0.0190 - val_loss: 5.0136e-05 - val_mae: 0.0046\n",
            "Epoch 61/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.5675e-04 - mae: 0.0184 - val_loss: 5.2274e-05 - val_mae: 0.0047\n",
            "Epoch 62/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.2009e-04 - mae: 0.0187 - val_loss: 5.2211e-05 - val_mae: 0.0048\n",
            "Epoch 63/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.5095e-04 - mae: 0.0189 - val_loss: 5.1110e-05 - val_mae: 0.0047\n",
            "Epoch 64/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.1806e-04 - mae: 0.0186 - val_loss: 5.5075e-05 - val_mae: 0.0049\n",
            "Epoch 65/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.9741e-04 - mae: 0.0185 - val_loss: 5.3198e-05 - val_mae: 0.0048\n",
            "Epoch 66/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.4955e-04 - mae: 0.0190 - val_loss: 4.9809e-05 - val_mae: 0.0044\n",
            "Epoch 67/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.4784e-04 - mae: 0.0185 - val_loss: 5.4291e-05 - val_mae: 0.0048\n",
            "Epoch 68/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.4222e-04 - mae: 0.0188 - val_loss: 5.0773e-05 - val_mae: 0.0047\n",
            "Epoch 69/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.0966e-04 - mae: 0.0184 - val_loss: 4.6911e-05 - val_mae: 0.0043\n",
            "Epoch 70/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.7354e-04 - mae: 0.0181 - val_loss: 4.6913e-05 - val_mae: 0.0043\n",
            "Epoch 71/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.8547e-04 - mae: 0.0182 - val_loss: 4.8225e-05 - val_mae: 0.0045\n",
            "Epoch 72/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.8295e-04 - mae: 0.0184 - val_loss: 5.1902e-05 - val_mae: 0.0045\n",
            "Epoch 73/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.8087e-04 - mae: 0.0183 - val_loss: 5.6771e-05 - val_mae: 0.0045\n",
            "Epoch 74/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.0809e-04 - mae: 0.0183 - val_loss: 6.1103e-05 - val_mae: 0.0048\n",
            "Epoch 75/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.8659e-04 - mae: 0.0183 - val_loss: 5.9029e-05 - val_mae: 0.0049\n",
            "Epoch 76/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.9012e-04 - mae: 0.0183 - val_loss: 5.4159e-05 - val_mae: 0.0048\n",
            "Epoch 77/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.6895e-04 - mae: 0.0182 - val_loss: 4.7584e-05 - val_mae: 0.0043\n",
            "Epoch 78/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.7494e-04 - mae: 0.0179 - val_loss: 4.6741e-05 - val_mae: 0.0044\n",
            "Epoch 79/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.7949e-04 - mae: 0.0182 - val_loss: 4.6370e-05 - val_mae: 0.0044\n",
            "Epoch 80/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.4196e-04 - mae: 0.0179 - val_loss: 4.3575e-05 - val_mae: 0.0042\n",
            "Epoch 81/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.7288e-04 - mae: 0.0181 - val_loss: 4.4128e-05 - val_mae: 0.0042\n",
            "Epoch 82/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.0832e-04 - mae: 0.0173 - val_loss: 4.8156e-05 - val_mae: 0.0045\n",
            "Epoch 83/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.7159e-04 - mae: 0.0181 - val_loss: 5.3258e-05 - val_mae: 0.0049\n",
            "Epoch 84/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.7082e-04 - mae: 0.0180 - val_loss: 5.5182e-05 - val_mae: 0.0048\n",
            "Epoch 85/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.5650e-04 - mae: 0.0177 - val_loss: 5.1798e-05 - val_mae: 0.0046\n",
            "Epoch 86/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.4529e-04 - mae: 0.0177 - val_loss: 5.0719e-05 - val_mae: 0.0046\n",
            "Epoch 87/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.4652e-04 - mae: 0.0177 - val_loss: 4.8240e-05 - val_mae: 0.0043\n",
            "Epoch 88/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.1879e-04 - mae: 0.0171 - val_loss: 4.6073e-05 - val_mae: 0.0043\n",
            "Epoch 89/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.3308e-04 - mae: 0.0173 - val_loss: 4.6250e-05 - val_mae: 0.0044\n",
            "Epoch 90/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.1447e-04 - mae: 0.0173 - val_loss: 4.6847e-05 - val_mae: 0.0044\n",
            "Epoch 91/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.2690e-04 - mae: 0.0174 - val_loss: 4.8798e-05 - val_mae: 0.0044\n",
            "Epoch 92/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.2128e-04 - mae: 0.0172 - val_loss: 5.1722e-05 - val_mae: 0.0046\n",
            "Epoch 93/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.0353e-04 - mae: 0.0172 - val_loss: 5.9449e-05 - val_mae: 0.0049\n",
            "Epoch 94/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.7354e-04 - mae: 0.0176 - val_loss: 5.9431e-05 - val_mae: 0.0050\n",
            "Epoch 95/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.2434e-04 - mae: 0.0175 - val_loss: 5.4276e-05 - val_mae: 0.0048\n",
            "Epoch 96/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.6298e-04 - mae: 0.0177 - val_loss: 4.7533e-05 - val_mae: 0.0044\n",
            "Epoch 97/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.1521e-04 - mae: 0.0173 - val_loss: 4.8582e-05 - val_mae: 0.0044\n",
            "Epoch 98/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.4717e-04 - mae: 0.0175 - val_loss: 5.0693e-05 - val_mae: 0.0045\n",
            "Epoch 99/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.3760e-04 - mae: 0.0175 - val_loss: 4.6691e-05 - val_mae: 0.0044\n",
            "Epoch 100/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.9227e-04 - mae: 0.0169 - val_loss: 4.6549e-05 - val_mae: 0.0044\n",
            "Epoch 101/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.6908e-04 - mae: 0.0176 - val_loss: 4.6313e-05 - val_mae: 0.0043\n",
            "Epoch 102/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.9779e-04 - mae: 0.0172 - val_loss: 4.5862e-05 - val_mae: 0.0044\n",
            "Epoch 103/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.2136e-04 - mae: 0.0171 - val_loss: 4.8036e-05 - val_mae: 0.0044\n",
            "Epoch 104/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.3305e-04 - mae: 0.0170 - val_loss: 5.0443e-05 - val_mae: 0.0044\n",
            "Epoch 105/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.2799e-04 - mae: 0.0174 - val_loss: 4.7092e-05 - val_mae: 0.0043\n",
            "Epoch 106/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.7979e-04 - mae: 0.0168 - val_loss: 4.6327e-05 - val_mae: 0.0044\n",
            "Epoch 107/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.7959e-04 - mae: 0.0168 - val_loss: 4.6820e-05 - val_mae: 0.0044\n",
            "Epoch 108/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.0933e-04 - mae: 0.0169 - val_loss: 4.4634e-05 - val_mae: 0.0043\n",
            "Epoch 109/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.2710e-04 - mae: 0.0174 - val_loss: 4.4137e-05 - val_mae: 0.0041\n",
            "Epoch 110/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 5.8123e-04 - mae: 0.0168 - val_loss: 4.5900e-05 - val_mae: 0.0043\n",
            "Epoch 111/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.8825e-04 - mae: 0.0166 - val_loss: 4.6321e-05 - val_mae: 0.0045\n",
            "Epoch 112/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.1899e-04 - mae: 0.0168 - val_loss: 4.5381e-05 - val_mae: 0.0044\n",
            "Epoch 113/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.9930e-04 - mae: 0.0169 - val_loss: 4.4298e-05 - val_mae: 0.0043\n",
            "Epoch 114/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.1147e-04 - mae: 0.0171 - val_loss: 4.9161e-05 - val_mae: 0.0046\n",
            "Epoch 115/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.8921e-04 - mae: 0.0170 - val_loss: 4.9110e-05 - val_mae: 0.0045\n",
            "Epoch 116/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.7833e-04 - mae: 0.0166 - val_loss: 4.6007e-05 - val_mae: 0.0043\n",
            "Epoch 117/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.9154e-04 - mae: 0.0165 - val_loss: 4.4608e-05 - val_mae: 0.0041\n",
            "Epoch 118/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.9535e-04 - mae: 0.0168 - val_loss: 4.7386e-05 - val_mae: 0.0043\n",
            "Epoch 119/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.4640e-04 - mae: 0.0162 - val_loss: 4.7457e-05 - val_mae: 0.0043\n",
            "Epoch 120/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.5211e-04 - mae: 0.0168 - val_loss: 4.6566e-05 - val_mae: 0.0043\n",
            "Epoch 121/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.4493e-04 - mae: 0.0162 - val_loss: 4.2908e-05 - val_mae: 0.0041\n",
            "Epoch 122/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.7943e-04 - mae: 0.0166 - val_loss: 4.0069e-05 - val_mae: 0.0039\n",
            "Epoch 123/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.8925e-04 - mae: 0.0167 - val_loss: 4.3624e-05 - val_mae: 0.0042\n",
            "Epoch 124/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.6622e-04 - mae: 0.0163 - val_loss: 4.9399e-05 - val_mae: 0.0043\n",
            "Epoch 125/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.0098e-04 - mae: 0.0167 - val_loss: 5.1511e-05 - val_mae: 0.0045\n",
            "Epoch 126/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.4917e-04 - mae: 0.0163 - val_loss: 5.2205e-05 - val_mae: 0.0044\n",
            "Epoch 127/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.7271e-04 - mae: 0.0163 - val_loss: 5.0921e-05 - val_mae: 0.0043\n",
            "Epoch 128/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.8953e-04 - mae: 0.0164 - val_loss: 4.9222e-05 - val_mae: 0.0043\n",
            "Epoch 129/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.4754e-04 - mae: 0.0162 - val_loss: 4.4858e-05 - val_mae: 0.0041\n",
            "Epoch 130/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.4516e-04 - mae: 0.0163 - val_loss: 4.6916e-05 - val_mae: 0.0044\n",
            "Epoch 131/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.7274e-04 - mae: 0.0163 - val_loss: 4.8741e-05 - val_mae: 0.0045\n",
            "Epoch 132/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.1986e-04 - mae: 0.0159 - val_loss: 4.8743e-05 - val_mae: 0.0046\n",
            "Epoch 133/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.2505e-04 - mae: 0.0161 - val_loss: 4.7925e-05 - val_mae: 0.0045\n",
            "Epoch 134/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.6439e-04 - mae: 0.0162 - val_loss: 4.7134e-05 - val_mae: 0.0044\n",
            "Epoch 135/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.6061e-04 - mae: 0.0164 - val_loss: 4.6587e-05 - val_mae: 0.0043\n",
            "Epoch 136/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.2366e-04 - mae: 0.0156 - val_loss: 4.7929e-05 - val_mae: 0.0042\n",
            "Epoch 137/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.3569e-04 - mae: 0.0160 - val_loss: 4.9635e-05 - val_mae: 0.0042\n",
            "Epoch 138/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.5830e-04 - mae: 0.0162 - val_loss: 4.9769e-05 - val_mae: 0.0042\n",
            "Epoch 139/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.4393e-04 - mae: 0.0162 - val_loss: 4.8655e-05 - val_mae: 0.0043\n",
            "Epoch 140/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.4910e-04 - mae: 0.0161 - val_loss: 5.1554e-05 - val_mae: 0.0045\n",
            "Epoch 141/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.5725e-04 - mae: 0.0162 - val_loss: 5.0945e-05 - val_mae: 0.0044\n",
            "Epoch 142/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.6317e-04 - mae: 0.0163 - val_loss: 5.2204e-05 - val_mae: 0.0044\n",
            "Epoch 143/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.1038e-04 - mae: 0.0158 - val_loss: 5.0289e-05 - val_mae: 0.0044\n",
            "Epoch 144/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.6574e-04 - mae: 0.0163 - val_loss: 5.1082e-05 - val_mae: 0.0046\n",
            "Epoch 145/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.3235e-04 - mae: 0.0158 - val_loss: 4.7917e-05 - val_mae: 0.0044\n",
            "Epoch 146/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.1196e-04 - mae: 0.0157 - val_loss: 4.8511e-05 - val_mae: 0.0044\n",
            "Epoch 147/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.0420e-04 - mae: 0.0155 - val_loss: 4.9458e-05 - val_mae: 0.0045\n",
            "Epoch 148/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.1604e-04 - mae: 0.0156 - val_loss: 4.8127e-05 - val_mae: 0.0043\n",
            "Epoch 149/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.2218e-04 - mae: 0.0158 - val_loss: 4.7202e-05 - val_mae: 0.0043\n",
            "Epoch 150/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.9228e-04 - mae: 0.0154 - val_loss: 4.6064e-05 - val_mae: 0.0042\n",
            "Epoch 151/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.0751e-04 - mae: 0.0156 - val_loss: 4.4652e-05 - val_mae: 0.0041\n",
            "Epoch 152/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9504e-04 - mae: 0.0152 - val_loss: 4.6238e-05 - val_mae: 0.0042\n",
            "Epoch 153/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.1528e-04 - mae: 0.0157 - val_loss: 4.4616e-05 - val_mae: 0.0042\n",
            "Epoch 154/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9382e-04 - mae: 0.0155 - val_loss: 4.3104e-05 - val_mae: 0.0041\n",
            "Epoch 155/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9304e-04 - mae: 0.0153 - val_loss: 4.0783e-05 - val_mae: 0.0039\n",
            "Epoch 156/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9192e-04 - mae: 0.0153 - val_loss: 4.0081e-05 - val_mae: 0.0039\n",
            "Epoch 157/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.0149e-04 - mae: 0.0154 - val_loss: 4.2422e-05 - val_mae: 0.0041\n",
            "Epoch 158/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.2499e-04 - mae: 0.0155 - val_loss: 4.5289e-05 - val_mae: 0.0043\n",
            "Epoch 159/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9937e-04 - mae: 0.0155 - val_loss: 4.6890e-05 - val_mae: 0.0043\n",
            "Epoch 160/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.8639e-04 - mae: 0.0152 - val_loss: 4.9093e-05 - val_mae: 0.0044\n",
            "Epoch 161/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.6949e-04 - mae: 0.0150 - val_loss: 4.7223e-05 - val_mae: 0.0044\n",
            "Epoch 162/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.8282e-04 - mae: 0.0153 - val_loss: 4.4101e-05 - val_mae: 0.0042\n",
            "Epoch 163/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.8608e-04 - mae: 0.0153 - val_loss: 4.2885e-05 - val_mae: 0.0041\n",
            "Epoch 164/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.0341e-04 - mae: 0.0154 - val_loss: 4.3968e-05 - val_mae: 0.0042\n",
            "Epoch 165/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.5317e-04 - mae: 0.0154 - val_loss: 4.5245e-05 - val_mae: 0.0043\n",
            "Epoch 166/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.6990e-04 - mae: 0.0150 - val_loss: 4.5386e-05 - val_mae: 0.0044\n",
            "Epoch 167/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.7037e-04 - mae: 0.0149 - val_loss: 3.9319e-05 - val_mae: 0.0039\n",
            "Epoch 168/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.7809e-04 - mae: 0.0151 - val_loss: 3.9049e-05 - val_mae: 0.0039\n",
            "Epoch 169/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.6750e-04 - mae: 0.0150 - val_loss: 4.0749e-05 - val_mae: 0.0040\n",
            "Epoch 170/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.7004e-04 - mae: 0.0150 - val_loss: 4.1439e-05 - val_mae: 0.0040\n",
            "Epoch 171/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9299e-04 - mae: 0.0152 - val_loss: 4.4527e-05 - val_mae: 0.0042\n",
            "Epoch 172/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.1102e-04 - mae: 0.0153 - val_loss: 4.2615e-05 - val_mae: 0.0040\n",
            "Epoch 173/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.6640e-04 - mae: 0.0149 - val_loss: 3.9859e-05 - val_mae: 0.0040\n",
            "Epoch 174/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9120e-04 - mae: 0.0152 - val_loss: 3.9681e-05 - val_mae: 0.0040\n",
            "Epoch 175/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.7694e-04 - mae: 0.0150 - val_loss: 4.4678e-05 - val_mae: 0.0043\n",
            "Epoch 176/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.4214e-04 - mae: 0.0147 - val_loss: 4.6961e-05 - val_mae: 0.0043\n",
            "Epoch 177/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.5731e-04 - mae: 0.0148 - val_loss: 4.6049e-05 - val_mae: 0.0041\n",
            "Epoch 178/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.3507e-04 - mae: 0.0146 - val_loss: 4.4661e-05 - val_mae: 0.0040\n",
            "Epoch 179/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.2467e-04 - mae: 0.0145 - val_loss: 4.4583e-05 - val_mae: 0.0041\n",
            "Epoch 180/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.6484e-04 - mae: 0.0148 - val_loss: 4.2365e-05 - val_mae: 0.0040\n",
            "Epoch 181/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.7048e-04 - mae: 0.0149 - val_loss: 4.1307e-05 - val_mae: 0.0040\n",
            "Epoch 182/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.2380e-04 - mae: 0.0147 - val_loss: 4.1929e-05 - val_mae: 0.0041\n",
            "Epoch 183/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.6953e-04 - mae: 0.0148 - val_loss: 4.1508e-05 - val_mae: 0.0041\n",
            "Epoch 184/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.6043e-04 - mae: 0.0146 - val_loss: 4.3996e-05 - val_mae: 0.0042\n",
            "Epoch 185/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.4735e-04 - mae: 0.0145 - val_loss: 4.6626e-05 - val_mae: 0.0042\n",
            "Epoch 186/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.2889e-04 - mae: 0.0144 - val_loss: 5.1698e-05 - val_mae: 0.0042\n",
            "Epoch 187/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.6489e-04 - mae: 0.0147 - val_loss: 5.3088e-05 - val_mae: 0.0042\n",
            "Epoch 188/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.6121e-04 - mae: 0.0147 - val_loss: 5.2047e-05 - val_mae: 0.0043\n",
            "Epoch 189/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9971e-04 - mae: 0.0146 - val_loss: 4.7764e-05 - val_mae: 0.0042\n",
            "Epoch 190/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.6284e-04 - mae: 0.0146 - val_loss: 4.2476e-05 - val_mae: 0.0040\n",
            "Epoch 191/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.2849e-04 - mae: 0.0144 - val_loss: 4.1124e-05 - val_mae: 0.0040\n",
            "Epoch 192/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.3140e-04 - mae: 0.0143 - val_loss: 4.0593e-05 - val_mae: 0.0040\n",
            "Epoch 193/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.4494e-04 - mae: 0.0146 - val_loss: 4.0333e-05 - val_mae: 0.0040\n",
            "Epoch 194/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.5105e-04 - mae: 0.0145 - val_loss: 4.1390e-05 - val_mae: 0.0040\n",
            "Epoch 195/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.4228e-04 - mae: 0.0143 - val_loss: 4.2248e-05 - val_mae: 0.0040\n",
            "Epoch 196/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.1805e-04 - mae: 0.0142 - val_loss: 4.4215e-05 - val_mae: 0.0041\n",
            "Epoch 197/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.3267e-04 - mae: 0.0145 - val_loss: 4.5404e-05 - val_mae: 0.0041\n",
            "Epoch 198/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.4160e-04 - mae: 0.0141 - val_loss: 4.6227e-05 - val_mae: 0.0041\n",
            "Epoch 199/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.2992e-04 - mae: 0.0139 - val_loss: 4.3813e-05 - val_mae: 0.0039\n",
            "Epoch 200/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.1815e-04 - mae: 0.0142 - val_loss: 4.1547e-05 - val_mae: 0.0040\n",
            "Epoch 201/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.1467e-04 - mae: 0.0140 - val_loss: 4.0053e-05 - val_mae: 0.0040\n",
            "Epoch 202/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.3202e-04 - mae: 0.0141 - val_loss: 4.0032e-05 - val_mae: 0.0040\n",
            "Epoch 203/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.4100e-04 - mae: 0.0142 - val_loss: 4.0803e-05 - val_mae: 0.0040\n",
            "Epoch 204/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.1888e-04 - mae: 0.0139 - val_loss: 4.3782e-05 - val_mae: 0.0042\n",
            "Epoch 205/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.3488e-04 - mae: 0.0144 - val_loss: 4.1833e-05 - val_mae: 0.0041\n",
            "Epoch 206/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.9495e-04 - mae: 0.0137 - val_loss: 4.1535e-05 - val_mae: 0.0041\n",
            "Epoch 207/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.1352e-04 - mae: 0.0138 - val_loss: 4.3327e-05 - val_mae: 0.0042\n",
            "Epoch 208/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.1659e-04 - mae: 0.0139 - val_loss: 4.1517e-05 - val_mae: 0.0040\n",
            "Epoch 209/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.0295e-04 - mae: 0.0138 - val_loss: 4.0003e-05 - val_mae: 0.0039\n",
            "Epoch 210/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.0175e-04 - mae: 0.0139 - val_loss: 4.5378e-05 - val_mae: 0.0042\n",
            "Epoch 211/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.8827e-04 - mae: 0.0135 - val_loss: 4.6238e-05 - val_mae: 0.0043\n",
            "Epoch 212/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.2160e-04 - mae: 0.0139 - val_loss: 4.5771e-05 - val_mae: 0.0043\n",
            "Epoch 213/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.1077e-04 - mae: 0.0139 - val_loss: 4.4198e-05 - val_mae: 0.0042\n",
            "Epoch 214/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.1697e-04 - mae: 0.0140 - val_loss: 4.2603e-05 - val_mae: 0.0041\n",
            "Epoch 215/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.7365e-04 - mae: 0.0134 - val_loss: 4.2327e-05 - val_mae: 0.0041\n",
            "Epoch 216/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.0668e-04 - mae: 0.0138 - val_loss: 4.3530e-05 - val_mae: 0.0042\n",
            "Epoch 217/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.0293e-04 - mae: 0.0137 - val_loss: 4.0292e-05 - val_mae: 0.0039\n",
            "Epoch 218/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.1916e-04 - mae: 0.0138 - val_loss: 3.8827e-05 - val_mae: 0.0039\n",
            "Epoch 219/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.8896e-04 - mae: 0.0137 - val_loss: 3.7933e-05 - val_mae: 0.0037\n",
            "Epoch 220/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.8784e-04 - mae: 0.0134 - val_loss: 4.2105e-05 - val_mae: 0.0041\n",
            "Epoch 221/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.8581e-04 - mae: 0.0136 - val_loss: 4.1103e-05 - val_mae: 0.0039\n",
            "Epoch 222/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.9173e-04 - mae: 0.0135 - val_loss: 3.9865e-05 - val_mae: 0.0038\n",
            "Epoch 223/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.9633e-04 - mae: 0.0135 - val_loss: 4.0183e-05 - val_mae: 0.0040\n",
            "Epoch 224/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.1966e-04 - mae: 0.0138 - val_loss: 3.8382e-05 - val_mae: 0.0039\n",
            "Epoch 225/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.6754e-04 - mae: 0.0132 - val_loss: 3.7600e-05 - val_mae: 0.0038\n",
            "Epoch 226/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.8168e-04 - mae: 0.0134 - val_loss: 3.8506e-05 - val_mae: 0.0038\n",
            "Epoch 227/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.8741e-04 - mae: 0.0133 - val_loss: 3.9744e-05 - val_mae: 0.0038\n",
            "Epoch 228/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.6150e-04 - mae: 0.0132 - val_loss: 4.0656e-05 - val_mae: 0.0038\n",
            "Epoch 229/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.8200e-04 - mae: 0.0131 - val_loss: 4.2841e-05 - val_mae: 0.0041\n",
            "Epoch 230/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.8498e-04 - mae: 0.0135 - val_loss: 4.4612e-05 - val_mae: 0.0042\n",
            "Epoch 231/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.9712e-04 - mae: 0.0135 - val_loss: 4.1080e-05 - val_mae: 0.0039\n",
            "Epoch 232/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.7578e-04 - mae: 0.0132 - val_loss: 3.9086e-05 - val_mae: 0.0038\n",
            "Epoch 233/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.6582e-04 - mae: 0.0133 - val_loss: 3.9493e-05 - val_mae: 0.0038\n",
            "Epoch 234/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.6553e-04 - mae: 0.0131 - val_loss: 4.1379e-05 - val_mae: 0.0039\n",
            "Epoch 235/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.7684e-04 - mae: 0.0132 - val_loss: 4.0461e-05 - val_mae: 0.0039\n",
            "Epoch 236/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.5249e-04 - mae: 0.0130 - val_loss: 4.0393e-05 - val_mae: 0.0039\n",
            "Epoch 237/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.8775e-04 - mae: 0.0132 - val_loss: 3.9342e-05 - val_mae: 0.0039\n",
            "Epoch 238/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.6594e-04 - mae: 0.0131 - val_loss: 3.9813e-05 - val_mae: 0.0039\n",
            "Epoch 239/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.3472e-04 - mae: 0.0128 - val_loss: 4.0556e-05 - val_mae: 0.0039\n",
            "Epoch 240/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.6265e-04 - mae: 0.0130 - val_loss: 4.1880e-05 - val_mae: 0.0040\n",
            "Epoch 241/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.7876e-04 - mae: 0.0129 - val_loss: 4.1746e-05 - val_mae: 0.0039\n",
            "Epoch 242/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.4457e-04 - mae: 0.0126 - val_loss: 3.9043e-05 - val_mae: 0.0036\n",
            "Epoch 243/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.5690e-04 - mae: 0.0129 - val_loss: 3.6305e-05 - val_mae: 0.0036\n",
            "Epoch 244/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.4665e-04 - mae: 0.0127 - val_loss: 3.6527e-05 - val_mae: 0.0036\n",
            "Epoch 245/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.4682e-04 - mae: 0.0128 - val_loss: 3.7266e-05 - val_mae: 0.0037\n",
            "Epoch 246/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.6407e-04 - mae: 0.0128 - val_loss: 3.7516e-05 - val_mae: 0.0037\n",
            "Epoch 247/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.6475e-04 - mae: 0.0129 - val_loss: 3.9672e-05 - val_mae: 0.0039\n",
            "Epoch 248/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.4545e-04 - mae: 0.0128 - val_loss: 4.1756e-05 - val_mae: 0.0040\n",
            "Epoch 249/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.6972e-04 - mae: 0.0130 - val_loss: 4.8514e-05 - val_mae: 0.0044\n",
            "Epoch 250/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.5402e-04 - mae: 0.0129 - val_loss: 4.1962e-05 - val_mae: 0.0040\n",
            "Epoch 251/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.5621e-04 - mae: 0.0127 - val_loss: 4.0045e-05 - val_mae: 0.0038\n",
            "Epoch 252/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.3836e-04 - mae: 0.0125 - val_loss: 3.8689e-05 - val_mae: 0.0038\n",
            "Epoch 253/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.4512e-04 - mae: 0.0126 - val_loss: 3.4987e-05 - val_mae: 0.0036\n",
            "Epoch 254/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.3240e-04 - mae: 0.0125 - val_loss: 3.5037e-05 - val_mae: 0.0036\n",
            "Epoch 255/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.4763e-04 - mae: 0.0125 - val_loss: 3.4395e-05 - val_mae: 0.0035\n",
            "Epoch 256/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.4262e-04 - mae: 0.0127 - val_loss: 3.4844e-05 - val_mae: 0.0035\n",
            "Epoch 257/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.5987e-04 - mae: 0.0126 - val_loss: 3.8272e-05 - val_mae: 0.0038\n",
            "Epoch 258/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.5324e-04 - mae: 0.0127 - val_loss: 4.0511e-05 - val_mae: 0.0039\n",
            "Epoch 259/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.4824e-04 - mae: 0.0126 - val_loss: 4.0978e-05 - val_mae: 0.0040\n",
            "Epoch 260/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.2567e-04 - mae: 0.0124 - val_loss: 3.6851e-05 - val_mae: 0.0037\n",
            "Epoch 261/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.3986e-04 - mae: 0.0124 - val_loss: 3.5610e-05 - val_mae: 0.0036\n",
            "Epoch 262/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.2655e-04 - mae: 0.0124 - val_loss: 3.9705e-05 - val_mae: 0.0040\n",
            "Epoch 263/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.4658e-04 - mae: 0.0125 - val_loss: 3.7157e-05 - val_mae: 0.0037\n",
            "Epoch 264/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.3886e-04 - mae: 0.0124 - val_loss: 3.7558e-05 - val_mae: 0.0038\n",
            "Epoch 265/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.3152e-04 - mae: 0.0123 - val_loss: 3.9451e-05 - val_mae: 0.0041\n",
            "Epoch 266/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.2773e-04 - mae: 0.0123 - val_loss: 4.0931e-05 - val_mae: 0.0042\n",
            "Epoch 267/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.4849e-04 - mae: 0.0126 - val_loss: 3.9712e-05 - val_mae: 0.0041\n",
            "Epoch 268/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.2959e-04 - mae: 0.0124 - val_loss: 3.9516e-05 - val_mae: 0.0039\n",
            "Epoch 269/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.0707e-04 - mae: 0.0121 - val_loss: 3.6890e-05 - val_mae: 0.0036\n",
            "Epoch 270/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.3672e-04 - mae: 0.0121 - val_loss: 3.6421e-05 - val_mae: 0.0036\n",
            "Epoch 271/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.1186e-04 - mae: 0.0120 - val_loss: 3.7642e-05 - val_mae: 0.0036\n",
            "Epoch 272/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.3090e-04 - mae: 0.0123 - val_loss: 3.8496e-05 - val_mae: 0.0037\n",
            "Epoch 273/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.2418e-04 - mae: 0.0121 - val_loss: 4.0026e-05 - val_mae: 0.0039\n",
            "Epoch 274/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0764e-04 - mae: 0.0119 - val_loss: 4.4140e-05 - val_mae: 0.0042\n",
            "Epoch 275/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.2929e-04 - mae: 0.0123 - val_loss: 4.2692e-05 - val_mae: 0.0041\n",
            "Epoch 276/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.0922e-04 - mae: 0.0121 - val_loss: 4.0159e-05 - val_mae: 0.0038\n",
            "Epoch 277/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0883e-04 - mae: 0.0119 - val_loss: 3.8241e-05 - val_mae: 0.0038\n",
            "Epoch 278/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.2167e-04 - mae: 0.0120 - val_loss: 3.6646e-05 - val_mae: 0.0036\n",
            "Epoch 279/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0231e-04 - mae: 0.0118 - val_loss: 3.6867e-05 - val_mae: 0.0036\n",
            "Epoch 280/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.1924e-04 - mae: 0.0119 - val_loss: 3.7186e-05 - val_mae: 0.0037\n",
            "Epoch 281/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.3773e-04 - mae: 0.0123 - val_loss: 3.7291e-05 - val_mae: 0.0038\n",
            "Epoch 282/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.0565e-04 - mae: 0.0120 - val_loss: 3.7973e-05 - val_mae: 0.0039\n",
            "Epoch 283/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.0038e-04 - mae: 0.0119 - val_loss: 3.9668e-05 - val_mae: 0.0040\n",
            "Epoch 284/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.9738e-04 - mae: 0.0118 - val_loss: 3.8716e-05 - val_mae: 0.0039\n",
            "Epoch 285/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.1803e-04 - mae: 0.0119 - val_loss: 3.7370e-05 - val_mae: 0.0038\n",
            "Epoch 286/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.3393e-04 - mae: 0.0119 - val_loss: 3.6227e-05 - val_mae: 0.0036\n",
            "Epoch 287/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.0603e-04 - mae: 0.0118 - val_loss: 3.5333e-05 - val_mae: 0.0035\n",
            "Epoch 288/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.6498e-04 - mae: 0.0117 - val_loss: 3.8055e-05 - val_mae: 0.0037\n",
            "Epoch 289/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.8340e-04 - mae: 0.0116 - val_loss: 3.8345e-05 - val_mae: 0.0037\n",
            "Epoch 290/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.0455e-04 - mae: 0.0117 - val_loss: 3.8575e-05 - val_mae: 0.0037\n",
            "Epoch 291/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.1483e-04 - mae: 0.0119 - val_loss: 3.6894e-05 - val_mae: 0.0036\n",
            "Epoch 292/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0984e-04 - mae: 0.0120 - val_loss: 3.5817e-05 - val_mae: 0.0035\n",
            "Epoch 293/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.8348e-04 - mae: 0.0114 - val_loss: 3.8304e-05 - val_mae: 0.0037\n",
            "Epoch 294/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0307e-04 - mae: 0.0118 - val_loss: 3.9343e-05 - val_mae: 0.0037\n",
            "Epoch 295/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.9847e-04 - mae: 0.0119 - val_loss: 3.6749e-05 - val_mae: 0.0035\n",
            "Epoch 296/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.7325e-04 - mae: 0.0113 - val_loss: 3.8819e-05 - val_mae: 0.0036\n",
            "Epoch 297/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.8273e-04 - mae: 0.0114 - val_loss: 4.1322e-05 - val_mae: 0.0038\n",
            "Epoch 298/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.8058e-04 - mae: 0.0114 - val_loss: 4.1500e-05 - val_mae: 0.0038\n",
            "Epoch 299/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.8500e-04 - mae: 0.0114 - val_loss: 3.9822e-05 - val_mae: 0.0037\n",
            "Epoch 300/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.8970e-04 - mae: 0.0114 - val_loss: 3.6454e-05 - val_mae: 0.0036\n",
            "Epoch 301/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.8369e-04 - mae: 0.0115 - val_loss: 3.6067e-05 - val_mae: 0.0037\n",
            "Epoch 302/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.9563e-04 - mae: 0.0117 - val_loss: 3.6354e-05 - val_mae: 0.0036\n",
            "Epoch 303/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.8696e-04 - mae: 0.0113 - val_loss: 3.7931e-05 - val_mae: 0.0036\n",
            "Epoch 304/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.8106e-04 - mae: 0.0113 - val_loss: 4.0784e-05 - val_mae: 0.0037\n",
            "Epoch 305/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.8389e-04 - mae: 0.0112 - val_loss: 3.7538e-05 - val_mae: 0.0036\n",
            "Epoch 306/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.7557e-04 - mae: 0.0113 - val_loss: 3.6399e-05 - val_mae: 0.0036\n",
            "Epoch 307/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.6936e-04 - mae: 0.0113 - val_loss: 3.6502e-05 - val_mae: 0.0036\n",
            "Epoch 308/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.6995e-04 - mae: 0.0111 - val_loss: 3.7795e-05 - val_mae: 0.0036\n",
            "Epoch 309/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.9625e-04 - mae: 0.0111 - val_loss: 4.0026e-05 - val_mae: 0.0038\n",
            "Epoch 310/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.8345e-04 - mae: 0.0114 - val_loss: 4.0392e-05 - val_mae: 0.0038\n",
            "Epoch 311/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.7345e-04 - mae: 0.0112 - val_loss: 3.9195e-05 - val_mae: 0.0037\n",
            "Epoch 312/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.8210e-04 - mae: 0.0113 - val_loss: 4.0011e-05 - val_mae: 0.0038\n",
            "Epoch 313/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.7127e-04 - mae: 0.0111 - val_loss: 3.9306e-05 - val_mae: 0.0037\n",
            "Epoch 314/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.9102e-04 - mae: 0.0111 - val_loss: 3.9861e-05 - val_mae: 0.0037\n",
            "Epoch 315/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.8226e-04 - mae: 0.0110 - val_loss: 4.2020e-05 - val_mae: 0.0038\n",
            "Epoch 316/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.4408e-04 - mae: 0.0107 - val_loss: 4.1252e-05 - val_mae: 0.0038\n",
            "Epoch 317/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.5992e-04 - mae: 0.0108 - val_loss: 3.8637e-05 - val_mae: 0.0037\n",
            "Epoch 318/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.7810e-04 - mae: 0.0111 - val_loss: 3.6832e-05 - val_mae: 0.0036\n",
            "Epoch 319/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.8935e-04 - mae: 0.0112 - val_loss: 3.7010e-05 - val_mae: 0.0036\n",
            "Epoch 320/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.8780e-04 - mae: 0.0112 - val_loss: 3.6560e-05 - val_mae: 0.0036\n",
            "Epoch 321/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.5736e-04 - mae: 0.0107 - val_loss: 4.0832e-05 - val_mae: 0.0039\n",
            "Epoch 322/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.7956e-04 - mae: 0.0111 - val_loss: 4.1860e-05 - val_mae: 0.0038\n",
            "Epoch 323/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.6636e-04 - mae: 0.0110 - val_loss: 4.0813e-05 - val_mae: 0.0038\n",
            "Epoch 324/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.6578e-04 - mae: 0.0109 - val_loss: 4.0379e-05 - val_mae: 0.0038\n",
            "Epoch 325/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.6239e-04 - mae: 0.0109 - val_loss: 3.9546e-05 - val_mae: 0.0039\n",
            "Epoch 326/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.7029e-04 - mae: 0.0110 - val_loss: 3.7609e-05 - val_mae: 0.0037\n",
            "Epoch 327/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.8851e-04 - mae: 0.0112 - val_loss: 3.7888e-05 - val_mae: 0.0037\n",
            "Epoch 328/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5206e-04 - mae: 0.0108 - val_loss: 3.9011e-05 - val_mae: 0.0039\n",
            "Epoch 329/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5298e-04 - mae: 0.0108 - val_loss: 4.1129e-05 - val_mae: 0.0039\n",
            "Epoch 330/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.7928e-04 - mae: 0.0110 - val_loss: 4.3017e-05 - val_mae: 0.0039\n",
            "Epoch 331/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.6634e-04 - mae: 0.0109 - val_loss: 3.9848e-05 - val_mae: 0.0036\n",
            "Epoch 332/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5053e-04 - mae: 0.0107 - val_loss: 3.7510e-05 - val_mae: 0.0035\n",
            "Epoch 333/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.4942e-04 - mae: 0.0105 - val_loss: 3.8394e-05 - val_mae: 0.0038\n",
            "Epoch 334/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.7700e-04 - mae: 0.0108 - val_loss: 3.6368e-05 - val_mae: 0.0036\n",
            "Epoch 335/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.9807e-04 - mae: 0.0109 - val_loss: 3.6179e-05 - val_mae: 0.0034\n",
            "Epoch 336/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4376e-04 - mae: 0.0105 - val_loss: 4.0986e-05 - val_mae: 0.0038\n",
            "Epoch 337/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4132e-04 - mae: 0.0105 - val_loss: 4.1390e-05 - val_mae: 0.0037\n",
            "Epoch 338/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3797e-04 - mae: 0.0104 - val_loss: 4.0187e-05 - val_mae: 0.0036\n",
            "Epoch 339/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2916e-04 - mae: 0.0103 - val_loss: 4.0673e-05 - val_mae: 0.0037\n",
            "Epoch 340/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4321e-04 - mae: 0.0106 - val_loss: 4.0750e-05 - val_mae: 0.0038\n",
            "Epoch 341/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5369e-04 - mae: 0.0106 - val_loss: 3.8718e-05 - val_mae: 0.0036\n",
            "Epoch 342/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3695e-04 - mae: 0.0104 - val_loss: 3.6430e-05 - val_mae: 0.0034\n",
            "Epoch 343/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3219e-04 - mae: 0.0103 - val_loss: 3.5062e-05 - val_mae: 0.0034\n",
            "Epoch 344/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3774e-04 - mae: 0.0103 - val_loss: 3.3524e-05 - val_mae: 0.0034\n",
            "Epoch 345/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4086e-04 - mae: 0.0105 - val_loss: 3.3095e-05 - val_mae: 0.0034\n",
            "Epoch 346/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2703e-04 - mae: 0.0102 - val_loss: 3.3542e-05 - val_mae: 0.0034\n",
            "Epoch 347/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.3649e-04 - mae: 0.0104 - val_loss: 3.5488e-05 - val_mae: 0.0036\n",
            "Epoch 348/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4293e-04 - mae: 0.0103 - val_loss: 3.7175e-05 - val_mae: 0.0036\n",
            "Epoch 349/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.3002e-04 - mae: 0.0103 - val_loss: 3.9375e-05 - val_mae: 0.0036\n",
            "Epoch 350/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2816e-04 - mae: 0.0102 - val_loss: 3.9604e-05 - val_mae: 0.0037\n",
            "Epoch 351/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4625e-04 - mae: 0.0103 - val_loss: 3.8296e-05 - val_mae: 0.0036\n",
            "Epoch 352/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4810e-04 - mae: 0.0103 - val_loss: 3.8889e-05 - val_mae: 0.0038\n",
            "Epoch 353/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4565e-04 - mae: 0.0104 - val_loss: 3.6525e-05 - val_mae: 0.0036\n",
            "Epoch 354/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.3734e-04 - mae: 0.0101 - val_loss: 3.4949e-05 - val_mae: 0.0035\n",
            "Epoch 355/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2227e-04 - mae: 0.0100 - val_loss: 3.6721e-05 - val_mae: 0.0036\n",
            "Epoch 356/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2458e-04 - mae: 0.0101 - val_loss: 3.8355e-05 - val_mae: 0.0036\n",
            "Epoch 357/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5345e-04 - mae: 0.0103 - val_loss: 3.8354e-05 - val_mae: 0.0036\n",
            "Epoch 358/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2905e-04 - mae: 0.0101 - val_loss: 3.9705e-05 - val_mae: 0.0038\n",
            "Epoch 359/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3342e-04 - mae: 0.0099 - val_loss: 4.1603e-05 - val_mae: 0.0039\n",
            "Epoch 360/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3868e-04 - mae: 0.0101 - val_loss: 4.6905e-05 - val_mae: 0.0041\n",
            "Epoch 361/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2129e-04 - mae: 0.0100 - val_loss: 4.5323e-05 - val_mae: 0.0039\n",
            "Epoch 362/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.6046e-04 - mae: 0.0101 - val_loss: 4.2489e-05 - val_mae: 0.0037\n",
            "Epoch 363/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2263e-04 - mae: 0.0099 - val_loss: 3.9721e-05 - val_mae: 0.0037\n",
            "Epoch 364/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2585e-04 - mae: 0.0098 - val_loss: 3.8918e-05 - val_mae: 0.0036\n",
            "Epoch 365/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.1383e-04 - mae: 0.0098 - val_loss: 3.8001e-05 - val_mae: 0.0037\n",
            "Epoch 366/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3862e-04 - mae: 0.0101 - val_loss: 3.5958e-05 - val_mae: 0.0035\n",
            "Epoch 367/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2213e-04 - mae: 0.0099 - val_loss: 3.3429e-05 - val_mae: 0.0033\n",
            "Epoch 368/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2527e-04 - mae: 0.0099 - val_loss: 3.5973e-05 - val_mae: 0.0034\n",
            "Epoch 369/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0381e-04 - mae: 0.0096 - val_loss: 3.7414e-05 - val_mae: 0.0035\n",
            "Epoch 370/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2143e-04 - mae: 0.0099 - val_loss: 3.7426e-05 - val_mae: 0.0035\n",
            "Epoch 371/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0093e-04 - mae: 0.0096 - val_loss: 3.9373e-05 - val_mae: 0.0037\n",
            "Epoch 372/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3027e-04 - mae: 0.0100 - val_loss: 3.9978e-05 - val_mae: 0.0038\n",
            "Epoch 373/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3693e-04 - mae: 0.0100 - val_loss: 3.6146e-05 - val_mae: 0.0036\n",
            "Epoch 374/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1893e-04 - mae: 0.0098 - val_loss: 3.4383e-05 - val_mae: 0.0033\n",
            "Epoch 375/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0849e-04 - mae: 0.0096 - val_loss: 3.5560e-05 - val_mae: 0.0034\n",
            "Epoch 376/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2046e-04 - mae: 0.0098 - val_loss: 3.5948e-05 - val_mae: 0.0035\n",
            "Epoch 377/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.0886e-04 - mae: 0.0096 - val_loss: 3.5296e-05 - val_mae: 0.0034\n",
            "Epoch 378/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9792e-04 - mae: 0.0094 - val_loss: 3.5574e-05 - val_mae: 0.0034\n",
            "Epoch 379/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0528e-04 - mae: 0.0096 - val_loss: 3.7278e-05 - val_mae: 0.0035\n",
            "Epoch 380/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0130e-04 - mae: 0.0095 - val_loss: 3.7021e-05 - val_mae: 0.0034\n",
            "Epoch 381/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.0455e-04 - mae: 0.0096 - val_loss: 3.7639e-05 - val_mae: 0.0035\n",
            "Epoch 382/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.1519e-04 - mae: 0.0096 - val_loss: 3.9580e-05 - val_mae: 0.0036\n",
            "Epoch 383/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2511e-04 - mae: 0.0097 - val_loss: 3.8407e-05 - val_mae: 0.0036\n",
            "Epoch 384/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.0404e-04 - mae: 0.0094 - val_loss: 3.8959e-05 - val_mae: 0.0037\n",
            "Epoch 385/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5297e-04 - mae: 0.0096 - val_loss: 3.6651e-05 - val_mae: 0.0035\n",
            "Epoch 386/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0292e-04 - mae: 0.0095 - val_loss: 3.5219e-05 - val_mae: 0.0034\n",
            "Epoch 387/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0621e-04 - mae: 0.0097 - val_loss: 3.5336e-05 - val_mae: 0.0034\n",
            "Epoch 388/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9157e-04 - mae: 0.0094 - val_loss: 3.5384e-05 - val_mae: 0.0035\n",
            "Epoch 389/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.0875e-04 - mae: 0.0095 - val_loss: 3.6063e-05 - val_mae: 0.0035\n",
            "Epoch 390/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.0625e-04 - mae: 0.0094 - val_loss: 3.6397e-05 - val_mae: 0.0035\n",
            "Epoch 391/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0405e-04 - mae: 0.0094 - val_loss: 3.9332e-05 - val_mae: 0.0036\n",
            "Epoch 392/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9969e-04 - mae: 0.0094 - val_loss: 4.1859e-05 - val_mae: 0.0036\n",
            "Epoch 393/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9143e-04 - mae: 0.0093 - val_loss: 3.8946e-05 - val_mae: 0.0034\n",
            "Epoch 394/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.1308e-04 - mae: 0.0095 - val_loss: 3.9904e-05 - val_mae: 0.0036\n",
            "Epoch 395/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2898e-04 - mae: 0.0095 - val_loss: 4.0806e-05 - val_mae: 0.0037\n",
            "Epoch 396/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9845e-04 - mae: 0.0092 - val_loss: 3.7805e-05 - val_mae: 0.0035\n",
            "Epoch 397/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.9591e-04 - mae: 0.0092 - val_loss: 3.6671e-05 - val_mae: 0.0035\n",
            "Epoch 398/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.9885e-04 - mae: 0.0093 - val_loss: 3.4997e-05 - val_mae: 0.0035\n",
            "Epoch 399/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.8783e-04 - mae: 0.0092 - val_loss: 3.6023e-05 - val_mae: 0.0036\n",
            "Epoch 400/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.9926e-04 - mae: 0.0092 - val_loss: 4.0142e-05 - val_mae: 0.0037\n",
            "Epoch 401/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.0219e-04 - mae: 0.0092 - val_loss: 4.0794e-05 - val_mae: 0.0036\n",
            "Epoch 402/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0314e-04 - mae: 0.0092 - val_loss: 4.1174e-05 - val_mae: 0.0036\n",
            "Epoch 403/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8376e-04 - mae: 0.0093 - val_loss: 3.9468e-05 - val_mae: 0.0036\n",
            "Epoch 404/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9445e-04 - mae: 0.0092 - val_loss: 3.7913e-05 - val_mae: 0.0035\n",
            "Epoch 405/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.1606e-04 - mae: 0.0094 - val_loss: 3.6397e-05 - val_mae: 0.0034\n",
            "Epoch 406/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0518e-04 - mae: 0.0092 - val_loss: 3.5761e-05 - val_mae: 0.0033\n",
            "Epoch 407/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8145e-04 - mae: 0.0089 - val_loss: 3.6571e-05 - val_mae: 0.0034\n",
            "Epoch 408/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8667e-04 - mae: 0.0091 - val_loss: 3.7221e-05 - val_mae: 0.0034\n",
            "Epoch 409/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.4301e-04 - mae: 0.0090 - val_loss: 3.7863e-05 - val_mae: 0.0034\n",
            "Epoch 410/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9041e-04 - mae: 0.0090 - val_loss: 3.6734e-05 - val_mae: 0.0036\n",
            "Epoch 411/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8813e-04 - mae: 0.0090 - val_loss: 3.6635e-05 - val_mae: 0.0035\n",
            "Epoch 412/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8140e-04 - mae: 0.0091 - val_loss: 3.7434e-05 - val_mae: 0.0035\n",
            "Epoch 413/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8700e-04 - mae: 0.0088 - val_loss: 4.1212e-05 - val_mae: 0.0036\n",
            "Epoch 414/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.1743e-04 - mae: 0.0091 - val_loss: 4.4442e-05 - val_mae: 0.0036\n",
            "Epoch 415/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7601e-04 - mae: 0.0089 - val_loss: 4.5286e-05 - val_mae: 0.0037\n",
            "Epoch 416/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.8528e-04 - mae: 0.0089 - val_loss: 4.3121e-05 - val_mae: 0.0036\n",
            "Epoch 417/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.8378e-04 - mae: 0.0089 - val_loss: 4.0913e-05 - val_mae: 0.0036\n",
            "Epoch 418/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0253e-04 - mae: 0.0089 - val_loss: 3.9448e-05 - val_mae: 0.0036\n",
            "Epoch 419/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7770e-04 - mae: 0.0087 - val_loss: 3.6827e-05 - val_mae: 0.0035\n",
            "Epoch 420/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.7474e-04 - mae: 0.0087 - val_loss: 3.6553e-05 - val_mae: 0.0034\n",
            "Epoch 421/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9053e-04 - mae: 0.0089 - val_loss: 3.7526e-05 - val_mae: 0.0034\n",
            "Epoch 422/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7030e-04 - mae: 0.0087 - val_loss: 4.1223e-05 - val_mae: 0.0036\n",
            "Epoch 423/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7185e-04 - mae: 0.0087 - val_loss: 4.2156e-05 - val_mae: 0.0036\n",
            "Epoch 424/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9162e-04 - mae: 0.0088 - val_loss: 3.9886e-05 - val_mae: 0.0035\n",
            "Epoch 425/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6722e-04 - mae: 0.0086 - val_loss: 3.8889e-05 - val_mae: 0.0034\n",
            "Epoch 426/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8120e-04 - mae: 0.0087 - val_loss: 3.8860e-05 - val_mae: 0.0034\n",
            "Epoch 427/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8146e-04 - mae: 0.0088 - val_loss: 3.9562e-05 - val_mae: 0.0035\n",
            "Epoch 428/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6871e-04 - mae: 0.0085 - val_loss: 3.6609e-05 - val_mae: 0.0033\n",
            "Epoch 429/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9142e-04 - mae: 0.0087 - val_loss: 3.4935e-05 - val_mae: 0.0033\n",
            "Epoch 430/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7661e-04 - mae: 0.0086 - val_loss: 3.5335e-05 - val_mae: 0.0033\n",
            "Epoch 431/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7057e-04 - mae: 0.0086 - val_loss: 3.5062e-05 - val_mae: 0.0033\n",
            "Epoch 432/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6190e-04 - mae: 0.0084 - val_loss: 3.5237e-05 - val_mae: 0.0033\n",
            "Epoch 433/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7057e-04 - mae: 0.0086 - val_loss: 3.6729e-05 - val_mae: 0.0034\n",
            "Epoch 434/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.7373e-04 - mae: 0.0086 - val_loss: 3.9799e-05 - val_mae: 0.0035\n",
            "Epoch 435/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.8377e-04 - mae: 0.0084 - val_loss: 3.9807e-05 - val_mae: 0.0035\n",
            "Epoch 436/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8276e-04 - mae: 0.0087 - val_loss: 3.6932e-05 - val_mae: 0.0033\n",
            "Epoch 437/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6922e-04 - mae: 0.0084 - val_loss: 3.6668e-05 - val_mae: 0.0035\n",
            "Epoch 438/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6771e-04 - mae: 0.0086 - val_loss: 3.6183e-05 - val_mae: 0.0034\n",
            "Epoch 439/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6016e-04 - mae: 0.0083 - val_loss: 3.7517e-05 - val_mae: 0.0034\n",
            "Epoch 440/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8196e-04 - mae: 0.0085 - val_loss: 3.9935e-05 - val_mae: 0.0036\n",
            "Epoch 441/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4882e-04 - mae: 0.0082 - val_loss: 4.0193e-05 - val_mae: 0.0036\n",
            "Epoch 442/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6277e-04 - mae: 0.0083 - val_loss: 3.7510e-05 - val_mae: 0.0034\n",
            "Epoch 443/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6823e-04 - mae: 0.0085 - val_loss: 3.5553e-05 - val_mae: 0.0034\n",
            "Epoch 444/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6893e-04 - mae: 0.0083 - val_loss: 3.5223e-05 - val_mae: 0.0033\n",
            "Epoch 445/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7566e-04 - mae: 0.0083 - val_loss: 3.7331e-05 - val_mae: 0.0034\n",
            "Epoch 446/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5302e-04 - mae: 0.0082 - val_loss: 3.8810e-05 - val_mae: 0.0035\n",
            "Epoch 447/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.6286e-04 - mae: 0.0084 - val_loss: 4.0399e-05 - val_mae: 0.0036\n",
            "Epoch 448/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.8561e-04 - mae: 0.0085 - val_loss: 4.0359e-05 - val_mae: 0.0035\n",
            "Epoch 449/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.6627e-04 - mae: 0.0082 - val_loss: 3.9869e-05 - val_mae: 0.0034\n",
            "Epoch 450/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.5272e-04 - mae: 0.0081 - val_loss: 4.0394e-05 - val_mae: 0.0034\n",
            "Epoch 451/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.6492e-04 - mae: 0.0082 - val_loss: 3.8036e-05 - val_mae: 0.0034\n",
            "Epoch 452/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6255e-04 - mae: 0.0082 - val_loss: 3.6019e-05 - val_mae: 0.0033\n",
            "Epoch 453/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6738e-04 - mae: 0.0082 - val_loss: 3.6405e-05 - val_mae: 0.0033\n",
            "Epoch 454/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5058e-04 - mae: 0.0081 - val_loss: 3.8073e-05 - val_mae: 0.0035\n",
            "Epoch 455/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5386e-04 - mae: 0.0081 - val_loss: 3.8482e-05 - val_mae: 0.0035\n",
            "Epoch 456/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6701e-04 - mae: 0.0083 - val_loss: 3.6817e-05 - val_mae: 0.0033\n",
            "Epoch 457/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5393e-04 - mae: 0.0080 - val_loss: 3.4505e-05 - val_mae: 0.0033\n",
            "Epoch 458/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6100e-04 - mae: 0.0080 - val_loss: 3.4070e-05 - val_mae: 0.0032\n",
            "Epoch 459/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5712e-04 - mae: 0.0081 - val_loss: 3.6803e-05 - val_mae: 0.0034\n",
            "Epoch 460/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7793e-04 - mae: 0.0081 - val_loss: 3.7868e-05 - val_mae: 0.0035\n",
            "Epoch 461/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7209e-04 - mae: 0.0082 - val_loss: 3.6418e-05 - val_mae: 0.0035\n",
            "Epoch 462/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4561e-04 - mae: 0.0080 - val_loss: 3.4538e-05 - val_mae: 0.0033\n",
            "Epoch 463/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5488e-04 - mae: 0.0081 - val_loss: 3.4259e-05 - val_mae: 0.0033\n",
            "Epoch 464/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7156e-04 - mae: 0.0082 - val_loss: 3.3366e-05 - val_mae: 0.0032\n",
            "Epoch 465/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4955e-04 - mae: 0.0078 - val_loss: 3.4547e-05 - val_mae: 0.0033\n",
            "Epoch 466/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.7344e-04 - mae: 0.0079 - val_loss: 3.5877e-05 - val_mae: 0.0034\n",
            "Epoch 467/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4732e-04 - mae: 0.0079 - val_loss: 3.6639e-05 - val_mae: 0.0034\n",
            "Epoch 468/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4554e-04 - mae: 0.0079 - val_loss: 3.7982e-05 - val_mae: 0.0035\n",
            "Epoch 469/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4871e-04 - mae: 0.0079 - val_loss: 3.7655e-05 - val_mae: 0.0035\n",
            "Epoch 470/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3985e-04 - mae: 0.0076 - val_loss: 3.5607e-05 - val_mae: 0.0034\n",
            "Epoch 471/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.1578e-04 - mae: 0.0080 - val_loss: 3.4346e-05 - val_mae: 0.0033\n",
            "Epoch 472/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5979e-04 - mae: 0.0079 - val_loss: 3.2323e-05 - val_mae: 0.0032\n",
            "Epoch 473/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5719e-04 - mae: 0.0080 - val_loss: 3.2330e-05 - val_mae: 0.0031\n",
            "Epoch 474/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6564e-04 - mae: 0.0079 - val_loss: 3.6513e-05 - val_mae: 0.0034\n",
            "Epoch 475/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5133e-04 - mae: 0.0080 - val_loss: 4.4914e-05 - val_mae: 0.0037\n",
            "Epoch 476/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4882e-04 - mae: 0.0079 - val_loss: 4.7446e-05 - val_mae: 0.0038\n",
            "Epoch 477/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5449e-04 - mae: 0.0079 - val_loss: 4.4285e-05 - val_mae: 0.0035\n",
            "Epoch 478/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3888e-04 - mae: 0.0077 - val_loss: 4.1442e-05 - val_mae: 0.0033\n",
            "Epoch 479/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4267e-04 - mae: 0.0078 - val_loss: 4.0290e-05 - val_mae: 0.0035\n",
            "Epoch 480/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4499e-04 - mae: 0.0077 - val_loss: 3.7333e-05 - val_mae: 0.0035\n",
            "Epoch 481/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4886e-04 - mae: 0.0078 - val_loss: 3.4205e-05 - val_mae: 0.0033\n",
            "Epoch 482/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5413e-04 - mae: 0.0077 - val_loss: 3.4176e-05 - val_mae: 0.0032\n",
            "Epoch 483/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3774e-04 - mae: 0.0075 - val_loss: 3.5103e-05 - val_mae: 0.0032\n",
            "Epoch 484/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3912e-04 - mae: 0.0077 - val_loss: 3.6108e-05 - val_mae: 0.0032\n",
            "Epoch 485/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.5703e-04 - mae: 0.0076 - val_loss: 3.7412e-05 - val_mae: 0.0033\n",
            "Epoch 486/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4873e-04 - mae: 0.0078 - val_loss: 3.9518e-05 - val_mae: 0.0034\n",
            "Epoch 487/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3301e-04 - mae: 0.0075 - val_loss: 3.8520e-05 - val_mae: 0.0033\n",
            "Epoch 488/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.4117e-04 - mae: 0.0076 - val_loss: 3.8854e-05 - val_mae: 0.0034\n",
            "Epoch 489/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3767e-04 - mae: 0.0076 - val_loss: 3.7533e-05 - val_mae: 0.0034\n",
            "Epoch 490/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5268e-04 - mae: 0.0077 - val_loss: 3.4931e-05 - val_mae: 0.0032\n",
            "Epoch 491/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3254e-04 - mae: 0.0074 - val_loss: 3.3790e-05 - val_mae: 0.0032\n",
            "Epoch 492/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3333e-04 - mae: 0.0074 - val_loss: 3.4187e-05 - val_mae: 0.0033\n",
            "Epoch 493/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3450e-04 - mae: 0.0075 - val_loss: 3.5763e-05 - val_mae: 0.0033\n",
            "Epoch 494/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3974e-04 - mae: 0.0075 - val_loss: 3.6150e-05 - val_mae: 0.0033\n",
            "Epoch 495/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4003e-04 - mae: 0.0076 - val_loss: 3.6224e-05 - val_mae: 0.0034\n",
            "Epoch 496/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2857e-04 - mae: 0.0074 - val_loss: 3.7447e-05 - val_mae: 0.0035\n",
            "Epoch 497/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2478e-04 - mae: 0.0073 - val_loss: 3.7887e-05 - val_mae: 0.0034\n",
            "Epoch 498/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2863e-04 - mae: 0.0073 - val_loss: 3.7125e-05 - val_mae: 0.0034\n",
            "Epoch 499/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6092e-04 - mae: 0.0074 - val_loss: 3.5546e-05 - val_mae: 0.0033\n",
            "Epoch 500/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3585e-04 - mae: 0.0074 - val_loss: 3.4943e-05 - val_mae: 0.0032\n",
            "Epoch 501/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2916e-04 - mae: 0.0073 - val_loss: 3.5026e-05 - val_mae: 0.0033\n",
            "Epoch 502/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4556e-04 - mae: 0.0073 - val_loss: 3.6538e-05 - val_mae: 0.0033\n",
            "Epoch 503/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3262e-04 - mae: 0.0074 - val_loss: 3.5261e-05 - val_mae: 0.0033\n",
            "Epoch 504/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.4791e-04 - mae: 0.0074 - val_loss: 3.4397e-05 - val_mae: 0.0032\n",
            "Epoch 505/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3254e-04 - mae: 0.0073 - val_loss: 3.2920e-05 - val_mae: 0.0031\n",
            "Epoch 506/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3514e-04 - mae: 0.0074 - val_loss: 3.3606e-05 - val_mae: 0.0032\n",
            "Epoch 507/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3989e-04 - mae: 0.0074 - val_loss: 3.4817e-05 - val_mae: 0.0032\n",
            "Epoch 508/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1895e-04 - mae: 0.0071 - val_loss: 3.6991e-05 - val_mae: 0.0033\n",
            "Epoch 509/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4013e-04 - mae: 0.0072 - val_loss: 3.6679e-05 - val_mae: 0.0033\n",
            "Epoch 510/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2956e-04 - mae: 0.0073 - val_loss: 3.5985e-05 - val_mae: 0.0033\n",
            "Epoch 511/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3229e-04 - mae: 0.0072 - val_loss: 3.6283e-05 - val_mae: 0.0034\n",
            "Epoch 512/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2799e-04 - mae: 0.0072 - val_loss: 3.4977e-05 - val_mae: 0.0033\n",
            "Epoch 513/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3865e-04 - mae: 0.0073 - val_loss: 3.5323e-05 - val_mae: 0.0034\n",
            "Epoch 514/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3393e-04 - mae: 0.0073 - val_loss: 3.5636e-05 - val_mae: 0.0034\n",
            "Epoch 515/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2895e-04 - mae: 0.0072 - val_loss: 3.5778e-05 - val_mae: 0.0034\n",
            "Epoch 516/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2972e-04 - mae: 0.0072 - val_loss: 3.4019e-05 - val_mae: 0.0032\n",
            "Epoch 517/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1492e-04 - mae: 0.0070 - val_loss: 3.4427e-05 - val_mae: 0.0032\n",
            "Epoch 518/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1730e-04 - mae: 0.0069 - val_loss: 3.5219e-05 - val_mae: 0.0033\n",
            "Epoch 519/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2251e-04 - mae: 0.0071 - val_loss: 3.6659e-05 - val_mae: 0.0033\n",
            "Epoch 520/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2678e-04 - mae: 0.0072 - val_loss: 3.7467e-05 - val_mae: 0.0035\n",
            "Epoch 521/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2254e-04 - mae: 0.0069 - val_loss: 3.5832e-05 - val_mae: 0.0034\n",
            "Epoch 522/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3379e-04 - mae: 0.0070 - val_loss: 3.2965e-05 - val_mae: 0.0031\n",
            "Epoch 523/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2271e-04 - mae: 0.0069 - val_loss: 3.2198e-05 - val_mae: 0.0031\n",
            "Epoch 524/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2102e-04 - mae: 0.0070 - val_loss: 3.2668e-05 - val_mae: 0.0032\n",
            "Epoch 525/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1464e-04 - mae: 0.0069 - val_loss: 3.3160e-05 - val_mae: 0.0032\n",
            "Epoch 526/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1480e-04 - mae: 0.0069 - val_loss: 3.3694e-05 - val_mae: 0.0032\n",
            "Epoch 527/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2611e-04 - mae: 0.0068 - val_loss: 3.5507e-05 - val_mae: 0.0033\n",
            "Epoch 528/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3931e-04 - mae: 0.0069 - val_loss: 3.4414e-05 - val_mae: 0.0032\n",
            "Epoch 529/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2239e-04 - mae: 0.0069 - val_loss: 3.2798e-05 - val_mae: 0.0031\n",
            "Epoch 530/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1985e-04 - mae: 0.0068 - val_loss: 3.1716e-05 - val_mae: 0.0032\n",
            "Epoch 531/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2350e-04 - mae: 0.0068 - val_loss: 3.1492e-05 - val_mae: 0.0031\n",
            "Epoch 532/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2218e-04 - mae: 0.0068 - val_loss: 3.2187e-05 - val_mae: 0.0031\n",
            "Epoch 533/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2532e-04 - mae: 0.0069 - val_loss: 3.4198e-05 - val_mae: 0.0032\n",
            "Epoch 534/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1458e-04 - mae: 0.0067 - val_loss: 3.5079e-05 - val_mae: 0.0032\n",
            "Epoch 535/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1774e-04 - mae: 0.0068 - val_loss: 3.4812e-05 - val_mae: 0.0032\n",
            "Epoch 536/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2556e-04 - mae: 0.0069 - val_loss: 3.5881e-05 - val_mae: 0.0033\n",
            "Epoch 537/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1450e-04 - mae: 0.0067 - val_loss: 3.4790e-05 - val_mae: 0.0032\n",
            "Epoch 538/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0886e-04 - mae: 0.0068 - val_loss: 3.3803e-05 - val_mae: 0.0032\n",
            "Epoch 539/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2900e-04 - mae: 0.0070 - val_loss: 3.4572e-05 - val_mae: 0.0031\n",
            "Epoch 540/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1065e-04 - mae: 0.0066 - val_loss: 3.4654e-05 - val_mae: 0.0031\n",
            "Epoch 541/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3265e-04 - mae: 0.0069 - val_loss: 3.4004e-05 - val_mae: 0.0032\n",
            "Epoch 542/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7086e-04 - mae: 0.0067 - val_loss: 3.2814e-05 - val_mae: 0.0032\n",
            "Epoch 543/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1603e-04 - mae: 0.0067 - val_loss: 3.1460e-05 - val_mae: 0.0031\n",
            "Epoch 544/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1225e-04 - mae: 0.0066 - val_loss: 3.1721e-05 - val_mae: 0.0031\n",
            "Epoch 545/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0891e-04 - mae: 0.0066 - val_loss: 3.3377e-05 - val_mae: 0.0030\n",
            "Epoch 546/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1999e-04 - mae: 0.0067 - val_loss: 3.7285e-05 - val_mae: 0.0033\n",
            "Epoch 547/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1212e-04 - mae: 0.0066 - val_loss: 3.9907e-05 - val_mae: 0.0034\n",
            "Epoch 548/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0994e-04 - mae: 0.0066 - val_loss: 3.9992e-05 - val_mae: 0.0034\n",
            "Epoch 549/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2524e-04 - mae: 0.0066 - val_loss: 3.9747e-05 - val_mae: 0.0034\n",
            "Epoch 550/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1022e-04 - mae: 0.0066 - val_loss: 3.7012e-05 - val_mae: 0.0033\n",
            "Epoch 551/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1076e-04 - mae: 0.0067 - val_loss: 3.4838e-05 - val_mae: 0.0032\n",
            "Epoch 552/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0865e-04 - mae: 0.0065 - val_loss: 3.4041e-05 - val_mae: 0.0031\n",
            "Epoch 553/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0669e-04 - mae: 0.0065 - val_loss: 3.4387e-05 - val_mae: 0.0031\n",
            "Epoch 554/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0981e-04 - mae: 0.0064 - val_loss: 3.4720e-05 - val_mae: 0.0032\n",
            "Epoch 555/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1977e-04 - mae: 0.0066 - val_loss: 3.6240e-05 - val_mae: 0.0033\n",
            "Epoch 556/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1633e-04 - mae: 0.0066 - val_loss: 3.6855e-05 - val_mae: 0.0033\n",
            "Epoch 557/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1931e-04 - mae: 0.0066 - val_loss: 3.5270e-05 - val_mae: 0.0032\n",
            "Epoch 558/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0463e-04 - mae: 0.0064 - val_loss: 3.8269e-05 - val_mae: 0.0034\n",
            "Epoch 559/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2437e-04 - mae: 0.0065 - val_loss: 3.5947e-05 - val_mae: 0.0032\n",
            "Epoch 560/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0660e-04 - mae: 0.0064 - val_loss: 3.4405e-05 - val_mae: 0.0032\n",
            "Epoch 561/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0406e-04 - mae: 0.0063 - val_loss: 3.4933e-05 - val_mae: 0.0032\n",
            "Epoch 562/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0798e-04 - mae: 0.0065 - val_loss: 3.4527e-05 - val_mae: 0.0032\n",
            "Epoch 563/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1426e-04 - mae: 0.0063 - val_loss: 3.4616e-05 - val_mae: 0.0032\n",
            "Epoch 564/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1468e-04 - mae: 0.0065 - val_loss: 3.4644e-05 - val_mae: 0.0031\n",
            "Epoch 565/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1989e-04 - mae: 0.0066 - val_loss: 3.5858e-05 - val_mae: 0.0032\n",
            "Epoch 566/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0311e-04 - mae: 0.0063 - val_loss: 3.7443e-05 - val_mae: 0.0033\n",
            "Epoch 567/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0062e-04 - mae: 0.0063 - val_loss: 3.8973e-05 - val_mae: 0.0034\n",
            "Epoch 568/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1780e-04 - mae: 0.0064 - val_loss: 3.7547e-05 - val_mae: 0.0033\n",
            "Epoch 569/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1794e-04 - mae: 0.0064 - val_loss: 3.5824e-05 - val_mae: 0.0032\n",
            "Epoch 570/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9.8828e-05 - mae: 0.0062 - val_loss: 3.4692e-05 - val_mae: 0.0032\n",
            "Epoch 571/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.0255e-04 - mae: 0.0063 - val_loss: 3.3818e-05 - val_mae: 0.0032\n",
            "Epoch 572/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0615e-04 - mae: 0.0063 - val_loss: 3.4688e-05 - val_mae: 0.0031\n",
            "Epoch 573/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1176e-04 - mae: 0.0062 - val_loss: 3.8174e-05 - val_mae: 0.0033\n",
            "Epoch 574/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1493e-04 - mae: 0.0064 - val_loss: 3.8206e-05 - val_mae: 0.0033\n",
            "Epoch 575/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1526e-04 - mae: 0.0063 - val_loss: 3.6406e-05 - val_mae: 0.0032\n",
            "Epoch 576/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.3654e-05 - mae: 0.0061 - val_loss: 3.4381e-05 - val_mae: 0.0032\n",
            "Epoch 577/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0058e-04 - mae: 0.0060 - val_loss: 3.4075e-05 - val_mae: 0.0032\n",
            "Epoch 578/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0901e-04 - mae: 0.0062 - val_loss: 3.3761e-05 - val_mae: 0.0031\n",
            "Epoch 579/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0083e-04 - mae: 0.0062 - val_loss: 3.5384e-05 - val_mae: 0.0032\n",
            "Epoch 580/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0414e-04 - mae: 0.0062 - val_loss: 3.6630e-05 - val_mae: 0.0032\n",
            "Epoch 581/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2989e-04 - mae: 0.0063 - val_loss: 3.5327e-05 - val_mae: 0.0032\n",
            "Epoch 582/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1405e-04 - mae: 0.0062 - val_loss: 3.5625e-05 - val_mae: 0.0032\n",
            "Epoch 583/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.7069e-05 - mae: 0.0061 - val_loss: 3.5306e-05 - val_mae: 0.0032\n",
            "Epoch 584/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9512e-04 - mae: 0.0062 - val_loss: 3.2543e-05 - val_mae: 0.0031\n",
            "Epoch 585/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0430e-04 - mae: 0.0062 - val_loss: 3.2639e-05 - val_mae: 0.0030\n",
            "Epoch 586/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1384e-04 - mae: 0.0064 - val_loss: 3.5568e-05 - val_mae: 0.0031\n",
            "Epoch 587/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0879e-04 - mae: 0.0062 - val_loss: 3.8654e-05 - val_mae: 0.0032\n",
            "Epoch 588/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.9113e-05 - mae: 0.0061 - val_loss: 4.1451e-05 - val_mae: 0.0033\n",
            "Epoch 589/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0554e-04 - mae: 0.0062 - val_loss: 4.2783e-05 - val_mae: 0.0034\n",
            "Epoch 590/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0045e-04 - mae: 0.0060 - val_loss: 4.0632e-05 - val_mae: 0.0033\n",
            "Epoch 591/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.7076e-05 - mae: 0.0059 - val_loss: 3.8234e-05 - val_mae: 0.0033\n",
            "Epoch 592/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0050e-04 - mae: 0.0061 - val_loss: 3.9400e-05 - val_mae: 0.0033\n",
            "Epoch 593/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0049e-04 - mae: 0.0062 - val_loss: 3.9708e-05 - val_mae: 0.0033\n",
            "Epoch 594/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.8550e-05 - mae: 0.0061 - val_loss: 4.0140e-05 - val_mae: 0.0034\n",
            "Epoch 595/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0543e-04 - mae: 0.0061 - val_loss: 4.0989e-05 - val_mae: 0.0035\n",
            "Epoch 596/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.1076e-05 - mae: 0.0061 - val_loss: 4.0084e-05 - val_mae: 0.0032\n",
            "Epoch 597/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.6389e-05 - mae: 0.0060 - val_loss: 4.1897e-05 - val_mae: 0.0034\n",
            "Epoch 598/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.5663e-05 - mae: 0.0059 - val_loss: 3.9714e-05 - val_mae: 0.0033\n",
            "Epoch 599/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.6215e-04 - mae: 0.0060 - val_loss: 3.8946e-05 - val_mae: 0.0033\n",
            "Epoch 600/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.6069e-05 - mae: 0.0059 - val_loss: 3.5723e-05 - val_mae: 0.0031\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 3.4092e-05 - mae: 0.0031\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not broadcast input array from shape (164,10) into shape (164,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-4b206148cc02>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdummy_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Example for reverse scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdummy_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0minversed_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdummy_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (164,10) into shape (164,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 4\n",
        "for i in range(5):\n",
        "  print(predictions[i])\n",
        "  print(y_test[i])"
      ],
      "metadata": {
        "id": "EsL_MzcY2Ip3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b15d29e-7423-4ed9-9652-33faee5c15b7"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.08728562 -0.02262482  0.04886379  0.04230111  0.05161922 -0.02828378\n",
            "  0.02481262  0.02928938 -0.01451084  0.00634712]\n",
            "[0.         0.         0.         0.         0.         0.00715506\n",
            " 0.0083793  0.01195068 0.01203473 0.06865263]\n",
            "[-0.01075757 -0.00711581  0.05101072 -0.03718046  0.05138702  0.08439279\n",
            "  0.05311972 -0.0431038   0.0177401   0.01308526]\n",
            "[0.         0.         0.         0.00106089 0.0020298  0.00421593\n",
            " 0.00686135 0.02270967 0.02752369 0.04851331]\n",
            "[ 0.03084274 -0.02121975 -0.00609579  0.00016216  0.05879643  0.07299323\n",
            " -0.06277316 -0.01912572 -0.0214395   0.05094098]\n",
            "[0.         0.         0.         0.         0.         0.00079865\n",
            " 0.01650316 0.01929236 0.03898318 0.03960084]\n",
            "[ 0.04048278  0.01639463 -0.02265374 -0.00063488  0.00591874  0.02202143\n",
            " -0.02057799 -0.00880143  0.06101143  0.01280263]\n",
            "[0.         0.         0.         0.00019293 0.00338235 0.0098387\n",
            " 0.00986396 0.01292481 0.02008005 0.04841391]\n",
            "[ 0.05105521 -0.05236462 -0.03955832  0.02874222 -0.05425973 -0.00522457\n",
            " -0.02248698  0.0210037   0.00973374  0.01689932]\n",
            "[0.         0.         0.         0.00049438 0.0009006  0.0018858\n",
            " 0.00263324 0.01074983 0.01760891 0.0518922 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2wWG8M49gB9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JikHeqeb9SRN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normal_generator(n, mean, sd, mean_variation, sd_variation):\n",
        "    variable_mean = mean + np.random.normal(0, mean_variation * 2)\n",
        "    variable_sd = sd + abs(np.random.normal(0, sd_variation * 2))\n",
        "    return np.random.normal(variable_mean, variable_sd, n)\n",
        "\n",
        "def uniform_generator(n, min_val, max_val, min_variation, max_variation):\n",
        "    variable_min = min_val + np.random.uniform(-min_variation * 2, min_variation * 2)\n",
        "    variable_max = max_val + np.random.uniform(-max_variation * 2, max_variation * 2)\n",
        "    return np.random.uniform(variable_min, variable_max, n)\n",
        "\n",
        "def right_tailed_generator(n, mean, sd, mean_variation, sd_variation):\n",
        "    variable_mean = mean + np.random.normal(0, mean_variation * 2)\n",
        "    variable_sd = sd + abs(np.random.normal(0, sd_variation * 2))\n",
        "    return np.random.lognormal(variable_mean, variable_sd, n)\n",
        "\n",
        "def left_tailed_generator(n, mean, sd, mean_variation, sd_variation):\n",
        "    variable_mean = mean + np.random.normal(0, mean_variation * 2)\n",
        "    variable_sd = sd + abs(np.random.normal(0, sd_variation * 2))\n",
        "    return -np.random.lognormal(variable_mean, variable_sd, n)\n",
        "\n",
        "def multimodal_generator(ns, means, sds, mean_variation, sd_variation):\n",
        "    samples_list = []\n",
        "    for i in range(len(means)):\n",
        "        variable_mean = means[i] + np.random.normal(0, mean_variation * 2)\n",
        "        variable_sd = sds[i] + abs(np.random.normal(0, sd_variation * 2))\n",
        "        samples_list.append(np.random.normal(variable_mean, variable_sd, ns[i]))\n",
        "    return np.concatenate(samples_list)"
      ],
      "metadata": {
        "id": "qNh6250bvHax"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rescale_to_minus_one_one(values):\n",
        "    min_value = np.min(values)\n",
        "    max_value = np.max(values)\n",
        "    scaled_values = 2 * ((values - min_value) / (max_value - min_value)) - 1\n",
        "    return scaled_values"
      ],
      "metadata": {
        "id": "FR3X5_Qdu4Tg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_samples(n, q, generator_func, *args):\n",
        "    samples = generator_func(n, *args)\n",
        "    samples_q = np.quantile(samples, np.linspace(0, 1, q))\n",
        "    return rescale_to_minus_one_one(samples_q)\n",
        "\n",
        "def generate_normal_samples(n=10000, q=10, mean_value=0, sd_value=1, mean_variation=0.5, sd_variation=0.5):\n",
        "    return generate_samples(n, q, normal_generator, mean_value, sd_value, mean_variation, sd_variation)\n",
        "\n",
        "def generate_uniform_samples(n=10000, q=10, min_value=-1, max_value=1, min_variation=0.5, max_variation=0.5):\n",
        "    return generate_samples(n, q, uniform_generator, min_value, max_value, min_variation, max_variation)\n",
        "\n",
        "def generate_right_tailed_samples(n=10000, q=10, mean=0, sd=1, mean_variation=0.5, sd_variation=0.5):\n",
        "    return generate_samples(n, q, right_tailed_generator, mean, sd, mean_variation, sd_variation)\n",
        "\n",
        "def generate_left_tailed_samples(n=10000, q=10, mean=0, sd=1, mean_variation=0.5, sd_variation=0.5):\n",
        "    return generate_samples(n, q, left_tailed_generator, mean, sd, mean_variation, sd_variation)\n",
        "\n",
        "def generate_multimodal_samples(ns=[1000, 50], q=10, means=[1, -1], sds=[1, 0.5], mean_variation=0.5, sd_variation=0.5):\n",
        "    samples = multimodal_generator(ns, means, sds, mean_variation, sd_variation)\n",
        "    samples_q = np.quantile(samples, np.linspace(0, 1, q))\n",
        "    return rescale_to_minus_one_one(samples_q)\n"
      ],
      "metadata": {
        "id": "kBl2rBVNurmk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(n_samples=10000):\n",
        "    data_list = {}\n",
        "\n",
        "    # Generate samples for each distribution type\n",
        "    data_list['normal'] = [generate_normal_samples() for _ in range(n_samples)]\n",
        "    data_list['bimodal'] = [generate_multimodal_samples() for _ in range(n_samples)]\n",
        "    data_list['uniform'] = [generate_uniform_samples() for _ in range(n_samples)]\n",
        "    data_list['right_tailed'] = [generate_right_tailed_samples() for _ in range(n_samples)]\n",
        "    data_list['left_tailed'] = [generate_left_tailed_samples() for _ in range(n_samples)]\n",
        "\n",
        "    # Combine all data into a single DataFrame\n",
        "    combined_data = pd.DataFrame()\n",
        "    for name, samples_list in data_list.items():\n",
        "        df = pd.DataFrame(samples_list)\n",
        "        df['label'] = name\n",
        "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
        "\n",
        "    # Assign column names\n",
        "    combined_data.columns = [f'V{i+1}' for i in range(combined_data.shape[1] - 1)] + ['label']\n",
        "\n",
        "    return combined_data"
      ],
      "metadata": {
        "id": "2HbK6NsAvK9d"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = generate_training_data()"
      ],
      "metadata": {
        "id": "ijhzQw-wvUeu"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "lmZKSX7uvXfA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\n",
        "X = training_data.drop(columns=['label'])\n",
        "y = training_data['label']\n",
        "\n",
        "# Encode labels as integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=500, max_leaf_nodes=50, min_samples_leaf=2, random_state=123)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X, y_encoded)\n",
        "\n",
        "# Print the trained model\n",
        "print(rf_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGay4N_DvknZ",
        "outputId": "10607202-d824-4d7c-f294-84fbbf512062"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500,\n",
            "                       random_state=123)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_rf_ready_predictions = [rescale_to_minus_one_one(sorted(prediction)) for prediction in  y_test]"
      ],
      "metadata": {
        "id": "09QdlxNMwG9H"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference_rf_ready_predictions"
      ],
      "metadata": {
        "id": "ZZTQ-9bU03fj"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_new_data = training_data = generate_training_data()"
      ],
      "metadata": {
        "id": "bQ64AD_xxmL_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions"
      ],
      "metadata": {
        "id": "ZwVK0jK44rX-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_rf_ready_predictions = [rescale_to_minus_one_one(sorted(prediction)) for prediction in  predictions]"
      ],
      "metadata": {
        "id": "tsHCablOzaVj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_quantiles.columns = [f'V{i+1}' for i in range(real_quantiles.shape[1])]"
      ],
      "metadata": {
        "id": "XzEvoGNo4bjz",
        "outputId": "6e00a5c7-db9d-4bf2-d4ac-e93ced6bfae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'real_quantiles' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-78196dffb6d6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreal_quantiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf'V{i+1}'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_quantiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'real_quantiles' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_data_rf_ready_predictions = [rescale_to_minus_one_one(sorted(prediction)) for prediction in  np.array(real_quantiles) ]"
      ],
      "metadata": {
        "id": "-yLGJ_lf36JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming real_data_rf_ready_predictions is your list of predictions\n",
        "real_data_rf_ready_predictions = [prediction for prediction in real_data_rf_ready_predictions if not np.any(np.isnan(prediction))]\n"
      ],
      "metadata": {
        "id": "SWx9mmA94j6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_data_rf_ready_predictions"
      ],
      "metadata": {
        "id": "4YseXCvc6G_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_quantiles = quantiles.unstack().reset_index().iloc[:,1:]"
      ],
      "metadata": {
        "id": "ts3aWnOP35JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_data_rf_ready_predictions"
      ],
      "metadata": {
        "id": "HWRSD8yc6vyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `new_data` is your new dataset without the 'label' column\n",
        "\n",
        "# Use the trained model to make predictions\n",
        "predicted_labels_encoded = rf_model.predict(real_data_rf_ready_predictions)\n",
        "\n",
        "# Decode the encoded labels back to original labels\n",
        "predicted_predicted_labels = label_encoder.inverse_transform(predicted_labels_encoded)\n",
        "\n",
        "# Output the predictions\n",
        "print(predicted_predicted_labels)\n"
      ],
      "metadata": {
        "id": "EnfOWU9Uwqbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(predicted_predicted_labels, reference_predicted_labels)\n"
      ],
      "metadata": {
        "id": "p6_8ZiDNyxDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "id": "sCaFwRCY1LWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'my_array' is your numpy array\n",
        "unique_values, counts = np.unique(predicted_predicted_labels, return_counts=True)\n",
        "\n",
        "# Create a DataFrame to display the counts in a table format\n",
        "counts_table = pd.DataFrame({\n",
        "    'Unique Value': unique_values,\n",
        "    'Count': counts\n",
        "})\n",
        "\n",
        "# Display the table\n",
        "print(counts_table)\n"
      ],
      "metadata": {
        "id": "PcDFXl6my7qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'my_array' is your numpy array\n",
        "unique_values, counts = np.unique(predicted_labels, return_counts=True)\n",
        "\n",
        "# Create a DataFrame to display the counts in a table format\n",
        "counts_table = pd.DataFrame({\n",
        "    'Unique Value': unique_values,\n",
        "    'Count': counts\n",
        "})\n",
        "\n",
        "# Display the table\n",
        "print(counts_table)\n"
      ],
      "metadata": {
        "id": "EEP-HJBXxHNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# matches_within_distance[matches_within_distance['dist_id']!=xval_id].groupby('unique_id').sample(n=1)"
      ],
      "metadata": {
        "id": "iNIdRkBuRWa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xval_data = matches_within_distance[matches_within_distance['dist_id']==xval_id]"
      ],
      "metadata": {
        "id": "Sy4F0HqDP8Dr"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1o8tcfcQDa5",
        "outputId": "7ad77eb5-3ce8-4cc1-dabf-55bcdd67f4ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.000000    0.735027\n",
              "0.111111    0.935904\n",
              "0.222222    0.994083\n",
              "0.333333    1.051334\n",
              "0.444444    1.076923\n",
              "0.555556    1.106132\n",
              "0.666667    1.559841\n",
              "0.777778    1.822485\n",
              "0.888889    1.883787\n",
              "1.000000    1.973491\n",
              "Name: imp_c, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantiles = xval_data[xval_data['depth_adj_bottom'] ==\"20\" ].groupby('unique_id').sample(n=1)['imp_c'].astype(float).quantile(np.linspace(0, 1,10))"
      ],
      "metadata": {
        "id": "R-NRN92i2fLD"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keep_cols = [21,22,23,24,25,26,27,28, 29, 31,32, 33,34,36,36,37,38,39,40,41,42,43,44,45,46,47, 48]\n",
        "\n",
        "numeric_cols = xval_data.iloc[:,keep_cols]\n",
        "\n",
        "# scaler = MinMaxScaler()\n",
        "\n",
        "scaler.fit(numeric_cols)\n",
        "\n",
        "scaled_numeric_cols = scaler.transform(numeric_cols)\n",
        "\n",
        "scaled_numeric_df = pd.DataFrame(scaled_numeric_cols, columns=numeric_cols.columns, index=numeric_cols.index)\n",
        "\n",
        "# scaled_numeric_df['norm_dist_array'] = norm_dist_array\n",
        "\n",
        "id_fields = xval_data[['source_dataset', 'island', 'soil_column_id', 'unique_id', 'depth_top', 'depth_bottom', 'depth_adj_bottom', 'latitude', 'longitude']]\n",
        "\n",
        "numeric_df = pd.concat([id_fields, scaled_numeric_df], axis=1)"
      ],
      "metadata": {
        "id": "qk1KBWUO2AQV"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = scaled_numeric_df.iloc[:, :-1]\n"
      ],
      "metadata": {
        "id": "rF6tbcfHUFa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(scaled_numeric_df)"
      ],
      "metadata": {
        "id": "CVsyfIR3TlKT",
        "outputId": "6e0373a2-d5c2-474a-a2ec-573f2a821f9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "S4AThJp4Uv9E",
        "outputId": "c7edfbeb-dbcf-4a9c-b2c4-1e2ebbf7ba6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.12247125,  0.03118328,  0.0495691 , ..., -0.19799103,\n",
              "        -0.28046292,  0.2542506 ],\n",
              "       [-0.18755071, -0.14517893,  0.05063031, ...,  0.46126023,\n",
              "         0.10858239, -0.06460682],\n",
              "       [ 0.19001669, -0.05443947, -0.24050142, ...,  0.2977469 ,\n",
              "        -0.01477434, -0.05928018],\n",
              "       ...,\n",
              "       [ 0.82937247,  0.16018318, -0.10060246, ...,  0.3745603 ,\n",
              "        -0.26639497,  0.7190533 ],\n",
              "       [ 0.49430498,  0.14218841, -0.18336594, ...,  0.1484254 ,\n",
              "        -0.10297315,  0.4973034 ],\n",
              "       [ 0.38399374,  0.15162261, -0.1568389 , ...,  0.23105922,\n",
              "        -0.19483854,  0.54415834]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_array = np.full((len(predictions), 28), fill_value=0.5)  # Example for reverse scaling\n",
        "dummy_array[:, -1] = predictions\n",
        "inversed_predictions = scaler.inverse_transform(dummy_array)[:, -1]\n",
        "dummy_array[:, -1] = y_test\n",
        "inversed_truth = scaler.inverse_transform(dummy_array)[:, -1]"
      ],
      "metadata": {
        "id": "338ACfOQUnaf",
        "outputId": "acbbfeb4-e49e-413f-9ae6-6a637e567acf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not broadcast input array from shape (164,10) into shape (164,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-398135a6b340>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdummy_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Example for reverse scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdummy_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minversed_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdummy_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minversed_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (164,10) into shape (164,)"
          ]
        }
      ]
    }
  ]
}