{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzRGYJJDlPdHucQTmtxPN9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hayleypc/HawaiiClimate/blob/main/soil_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FJSR_lUJAuGW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfASAHA7B1a0",
        "outputId": "c82dbbcf-1337-4d68-b865-01bd1c5e8a27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd"
      ],
      "metadata": {
        "id": "FUiG_4XBCkTW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator model\n",
        "def build_generator(latent_dim, sequence_length):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(256, activation='relu', input_dim=latent_dim),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dense(1024, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dense(sequence_length, activation='tanh')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "uUacgusjBMnm"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OQCFUCGYZ9-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the discriminator model\n",
        "def build_discriminator(sequence_length):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(1024, activation='relu', input_dim=sequence_length),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "hywSkpYkBOk-"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the GAN model\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    model = models.Sequential([\n",
        "        generator,\n",
        "        discriminator\n",
        "    ])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "xuMwXpo5BRMu"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the training function to include validation\n",
        "def train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim, val_gen):\n",
        "    for epoch in range(epochs):\n",
        "        # Train on batches from the training generator\n",
        "        for _ in range(len(train_sequences) // batch_size):\n",
        "            # Generate fake sequences\n",
        "            noise = tf.random.normal(shape=(batch_size, latent_dim))\n",
        "            fake_sequences = generator.predict(noise)\n",
        "\n",
        "            # Get a batch of real sequences from the training generator\n",
        "            real_sequences = next(train_gen)\n",
        "\n",
        "            # Labels for real and fake data\n",
        "            real_labels = tf.ones((batch_size, 1))\n",
        "            fake_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "            # Train the discriminator\n",
        "            discriminator.trainable = True\n",
        "            d_loss_real = discriminator.train_on_batch(real_sequences, real_labels)\n",
        "            d_loss_fake = discriminator.train_on_batch(fake_sequences, fake_labels)\n",
        "            d_loss = 0.5 * tf.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # Train the generator\n",
        "            discriminator.trainable = False\n",
        "            noise = tf.random.normal(shape=(batch_size, latent_dim))\n",
        "            g_loss = gan.train_on_batch(noise, real_labels)\n",
        "\n",
        "        # Validation\n",
        "        val_real_sequences = next(val_gen)\n",
        "        val_fake_sequences = generator.predict(tf.random.normal(shape=(batch_size, latent_dim)))\n",
        "        val_d_loss_real = discriminator.evaluate(val_real_sequences, tf.ones((batch_size, 1)), verbose=0)\n",
        "        val_d_loss_fake = discriminator.evaluate(val_fake_sequences, tf.zeros((batch_size, 1)), verbose=0)\n",
        "        val_d_loss = 0.5 * np.add(val_d_loss_real, val_d_loss_fake)\n",
        "\n",
        "        # Print the progress\n",
        "        print(f\"Epoch: {epoch+1}/{epochs}, D Loss: {d_loss}, G Loss: {g_loss}, Val D Loss: {val_d_loss}\")\n",
        "\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "          data = validate_generator()\n",
        "\n",
        "          # Create a histogram\n",
        "          plt.hist(data, bins=10, color='blue', edgecolor='black')\n",
        "\n",
        "          # Add labels and title\n",
        "          plt.xlabel('Value')\n",
        "          plt.ylabel('Frequency')\n",
        "          plt.title('Simple Histogram')\n",
        "\n",
        "          # Show the plot\n",
        "          plt.show()"
      ],
      "metadata": {
        "id": "b6hLGfIgBVGZ"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_generator(n_lowest = 10, n_samp = 1024*8 ):\n",
        "  n_lowest = 10\n",
        "  result_vec = []\n",
        "  noise = tf.random.normal(shape=(n_samp, latent_dim))\n",
        "  synthetic_samples = generator.predict(noise)\n",
        "  batch_val = next(val_gen)\n",
        "  for batch_ in batch_val:\n",
        "    # batch_ = batch_val[1]\n",
        "    match_indices = [0,1,2,3,5,6,7,8,9]\n",
        "\n",
        "    data = [np.mean(np.sqrt((batch_[match_indices] - samp[match_indices])**2)) for samp in synthetic_samples]\n",
        "\n",
        "    indices = sorted(range(len(data)), key=lambda i: data[i])[:n_lowest]\n",
        "\n",
        "    most_similar = [synthetic_samples[i] for i in indices]\n",
        "\n",
        "    most_similar_scaled = [scaler.inverse_transform(sim.reshape(1,-1)) for sim in most_similar]\n",
        "\n",
        "    original_scaled = [scaler.inverse_transform(sim.reshape(1,-1)) for sim in [batch_]]\n",
        "\n",
        "    most_similar_scaled_2d = [np.squeeze(sim) for sim in most_similar_scaled]\n",
        "\n",
        "    original_scaled_2d = [np.squeeze(sim) for sim in original_scaled]\n",
        "\n",
        "    most_similar_scaled_df = pd.DataFrame(most_similar_scaled_2d, columns=numeric_cols.columns)\n",
        "\n",
        "    original_scaled_df = pd.DataFrame(original_scaled_2d, columns=numeric_cols.columns)\n",
        "\n",
        "    result = np.sqrt((np.mean(most_similar_scaled_df['imp_c_float'])- np.mean(original_scaled_df['imp_c_float']))**2)\n",
        "    # print(np.mean(original_scaled_df['agbd_m']))\n",
        "    result_vec.append(result)\n",
        "  return(result_vec)"
      ],
      "metadata": {
        "id": "P7L77v0fvrTh"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/sequence_data.csv'"
      ],
      "metadata": {
        "id": "46NsUEt2B80A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drivers_gpd = gpd.read_file('/content/drive/MyDrive/hawaii_soils/Analysis Data/250_summary_grid_dt.gpkg')"
      ],
      "metadata": {
        "id": "PcbyIy1MCszn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soils_csv = gpd.read_file('/content/drive/MyDrive/hawaii_soils/HI soils data/combined_soc_2024_04_05.csv')"
      ],
      "metadata": {
        "id": "4T2wvedGC1aG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shapely.geometry import Point\n",
        "\n",
        "soils_csv = soils_csv[(soils_csv['latitude'] != '') & (soils_csv['longitude'] != '')]\n",
        "soils_csv['geometry'] = soils_csv.apply(lambda row: Point(float(row['longitude']), float(row['latitude'] )), axis=1)\n",
        "soils_gpd = gpd.GeoDataFrame(soils_csv, geometry='geometry', crs=\"EPSG:4326\")"
      ],
      "metadata": {
        "id": "VHIQgCCiD1le"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure both GeoDataFrames have the same CRS\n",
        "soils_gpd = soils_gpd.to_crs(drivers_gpd.crs)\n",
        "\n",
        "# Perform spatial join\n",
        "matched_data = gpd.sjoin_nearest(soils_gpd, drivers_gpd, how='left', distance_col='distance')"
      ],
      "metadata": {
        "id": "GUDqgLj2FDfT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_rows = matched_data[matched_data[\"depth_adj_bottom\"] == '20']\n",
        "unique_rows = unique_rows.drop_duplicates(subset=['latitude', 'longitude'])\n",
        "unique_rows = unique_rows[unique_rows['distance'] < 251]\n",
        "matched_data = unique_rows"
      ],
      "metadata": {
        "id": "DKvp_WkRIRj_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matched_data['imp_c_float'] = [float(datum) for datum in matched_data['imp_c']]"
      ],
      "metadata": {
        "id": "efng2Ra9Ho9l"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(matched_data.select_dtypes(include=[np.number]).columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WsnTyBQKJ8r",
        "outputId": "75a98933-c020-4165-ba7c-a6891285076d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "id_fields = matched_data[['source_dataset', 'island', 'soil_column_id', 'unique_id', 'depth_top', 'depth_bottom', 'depth_adj_bottom', 'latitude', 'longitude']]\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_cols = matched_data.select_dtypes(include=[np.number]).iloc[:,[6,7,8,9,10,11,12,13,14,38]]\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = MinMaxScaler ()\n",
        "\n",
        "# Fit the scaler on the numeric columns\n",
        "scaler.fit(numeric_cols)\n",
        "\n",
        "# Transform the numeric columns\n",
        "scaled_numeric_cols = scaler.transform(numeric_cols)\n",
        "\n",
        "# Convert the scaled numeric columns back to a DataFrame\n",
        "scaled_numeric_df = pd.DataFrame(scaled_numeric_cols, columns=numeric_cols.columns, index=numeric_cols.index)\n",
        "\n",
        "# scaled_numeric_df = scaled_numeric_df\n",
        "# Concatenate the ID fields back with the numeric columns\n",
        "numeric_df = pd.concat([id_fields, scaled_numeric_df], axis=1)"
      ],
      "metadata": {
        "id": "Lzlo7QYVFXwo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set the dimensions and compile the models\n",
        "latent_dim = 100\n",
        "sequence_length = 10  # Adjust based on your sequence length\n",
        "\n",
        "generator = build_generator(latent_dim, sequence_length)\n",
        "discriminator = build_discriminator(sequence_length)\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "# Set the initial learning rate\n",
        "initial_learning_rate = 0.0002\n",
        "\n",
        "# Create optimizers for the generator and discriminator\n",
        "generator_optimizer = Adam(learning_rate=initial_learning_rate, beta_1=0.5)\n",
        "discriminator_optimizer = Adam(learning_rate=initial_learning_rate, beta_1=0.5)\n",
        "gan_optimizer = Adam(learning_rate=initial_learning_rate, beta_1=0.5)\n",
        "\n",
        "# Compile the discriminator\n",
        "generator.compile(optimizer=generator_optimizer, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Compile the GAN\n",
        "gan.compile(optimizer=gan_optimizer, loss='mse')\n",
        "\n",
        "# # Assuming 'final_df' is your scaled dataset with numeric columns and ID fields\n",
        "# # Extract only the numeric columns for the GAN\n",
        "# numeric_columns = [col for col in scaled_numeric_cols.columns if scaled_numeric_cols[col].dtype in [np.float32, np.float64]]\n",
        "# real_sequences_df = scaled_numeric_cols[numeric_columns]\n",
        "\n",
        "# Convert the DataFrame to a NumPy array\n",
        "real_sequences_array = scaled_numeric_cols\n",
        "\n",
        "def real_sequence_generator(data, batch_size):\n",
        "    while True:\n",
        "        # Shuffle the data at the beginning of each epoch\n",
        "        np.random.shuffle(data)\n",
        "        for i in range(0, len(data), batch_size):\n",
        "            batch = data[i:i + batch_size]\n",
        "            # If the batch is smaller than the batch size, pad it with samples from the beginning\n",
        "            if len(batch) < batch_size:\n",
        "                padding = data[:(batch_size - len(batch))]\n",
        "                batch = np.concatenate([batch, padding], axis=0)\n",
        "            yield batch\n",
        "\n",
        "\n",
        "# Create an instance of the generator\n",
        "# real_sequence_gen = real_sequence_generator(real_sequences_array, batch_size)\n"
      ],
      "metadata": {
        "id": "YONOBC-8BSw2"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sequences, val_sequences = train_test_split(real_sequences_array, test_size=0.2, random_state=42)\n",
        "\n",
        "test_sequences, val_sequences = train_test_split(val_sequences, test_size=0.5, random_state=42)\n",
        "\n",
        "batch_size = 128  # Set the batch size\n",
        "\n",
        "\n",
        "# Define the training and validation generators\n",
        "train_gen = real_sequence_generator(train_sequences, batch_size)\n",
        "test_gen = real_sequence_generator(test_sequences, batch_size)\n",
        "val_gen = real_sequence_generator(val_sequences, batch_size)\n"
      ],
      "metadata": {
        "id": "9BDQtO5LKaGk"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the GAN with validation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_gan(generator, discriminator, gan, epochs=10000, batch_size=128, latent_dim=latent_dim, val_gen=val_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpwWxtrOBXT2",
        "outputId": "0174b15f-b70a-45a0-f8cd-58f95b661e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "Epoch: 1/10000, D Loss: [0.7018973  0.42578125], G Loss: 0.25080591440200806, Val D Loss: [0.6977447 0.296875 ]\n",
            "256/256 [==============================] - 3s 10ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3zElEQVR4nO3de1xVZd7///cWBFROIiqSgmfUFPtKakxmnhKt2zSZu0zNQ0xm4VmrYaZSOgxmk4cm0uYeB/MuDzm3Ws1knlKsPJSoqY2DShqYqGEJgrFlYP3+aNy/thyELbL2wtfz8VgPWdc6fa59Yb1d69p72wzDMAQAAGBBdcwuAAAAwFUEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGaCWaNmypcaNG2fKtefMmSObzWbKta8ws/8AzEOQAdzcoUOH9Otf/1rh4eHy8fHRLbfconvuuUd/+tOfzC7thlm2bJlsNpv27t1b5vY+ffqoc+fO132djz76SHPmzLnu8wAwj6fZBQAo386dO9W3b1+FhYXpscceU0hIiLKysrR7924tWrRIkydPduybnp6uOnVu3n+buNL/jz76SMnJyYQZwMIIMoAbe/nllxUQEKAvv/xSgYGBTtvOnTvntO7t7V2DlbkfK/a/oKBADRo0MLsMwNJu3n++ARaQkZGhW2+9tVSIkaQmTZo4rV89R+TK45nPPvtMU6ZMUePGjRUYGKjHH39cly9f1oULFzRmzBg1bNhQDRs21NNPPy3DMBzHnzx5UjabTX/84x+1YMEChYeHq169err77rt1+PDhStX/zjvvKCoqSvXq1VNQUJBGjBihrKwsl16La7m6/0VFRUpMTFS7du3k4+OjRo0aqVevXtq8ebMkady4cUpOTpYk2Ww2x3JFQUGBZs6cqRYtWsjb21sRERH64x//6PQaSdJPP/2kKVOmKDg4WH5+frr//vv13XffyWazOd3puTKP6J///KdGjhyphg0bqlevXpKkgwcPaty4cWrdurV8fHwUEhKiRx99VOfPn3e61pVzHD16VKNHj1ZAQIAaN26s5557ToZhKCsrS0OHDpW/v79CQkL02muvVedLDLgl7sgAbiw8PFy7du3S4cOHXZ4TMnnyZIWEhCgxMVG7d+/Wn//8ZwUGBmrnzp0KCwvTH/7wB3300Ud69dVX1blzZ40ZM8bp+OXLl+vixYuKj49XYWGhFi1apH79+unQoUNq2rRpudd9+eWX9dxzz+nBBx/Ub37zG33//ff605/+pN69e2v//v1lhrOr5ebmKicnp1R7UVHRNY+dM2eOkpKS9Jvf/EY9evRQXl6e9u7dq3379umee+7R448/rtOnT2vz5s363//9X6djDcPQ/fffr23btikuLk633XabNm7cqKeeekrfffedFixY4Nh33Lhxeu+99/TII4/ojjvuUGpqqu67775y6/rv//5vtWvXTn/4wx8coWjz5s365ptvNH78eIWEhOjrr7/Wn//8Z3399dfavXt3qYnUDz30kDp27Ki5c+fqH//4h1566SUFBQXprbfeUr9+/fTKK6/o3Xff1axZs9S9e3f17t37mq8XYFkGALe1adMmw8PDw/Dw8DCio6ONp59+2ti4caNx+fLlUvuGh4cbY8eOdaynpKQYkoyYmBijpKTE0R4dHW3YbDZj4sSJjrZ///vfRvPmzY27777b0XbixAlDklGvXj3j1KlTjvY9e/YYkozp06c72mbPnm388j8nJ0+eNDw8PIyXX37ZqcZDhw4Znp6epdqvdqX2ipZbb721wv537drVuO+++yq8Tnx8vFHWfwbXr19vSDJeeuklp/Zf//rXhs1mM44fP24YhmGkpaUZkoxp06Y57Tdu3DhDkjF79mxH25XX6OGHHy51vUuXLpVqW7lypSHJ2LFjR6lzTJgwwdF2ZexsNpsxd+5cR/uPP/5o1KtXz+k1AWojHi0Bbuyee+7Rrl27dP/99+urr77SvHnzFBMTo1tuuUUffPBBpc4RFxfn9C/6nj17yjAMxcXFOdo8PDx0++2365tvvil1/LBhw3TLLbc41nv06KGePXvqo48+Kveaa9euVUlJiR588EHl5OQ4lpCQELVr107btm2rVO3JycnavHlzqSUyMvKaxwYGBurrr7/WsWPHKnWtX/roo4/k4eGhKVOmOLXPnDlThmFow4YNkqSPP/5YkvTkk0867ffLSdhXmzhxYqm2evXqOX4uLCxUTk6O7rjjDknSvn37Su3/m9/8xvHzlbG7ekwDAwMVERFR5pgCtQmPlgA31717d61du1aXL1/WV199pXXr1mnBggX69a9/rQMHDqhTp04VHh8WFua0HhAQIElq0aJFqfYff/yx1PHt2rUr1da+fXu999575V7z2LFjMgyjzGMlqW7duhXWfEWPHj10++23l2pv2LBhmY+cfumFF17Q0KFD1b59e3Xu3FmDBg3SI488UqkQ9O233yo0NFR+fn5O7R07dnRsv/JnnTp11KpVK6f92rZtW+65r95Xkn744QclJiZq1apVpSZx5+bmltq/rDH18fFRcHBwqfar59kAtQ1BBrAILy8vde/eXd27d1f79u01fvx4rVmzRrNnz67wOA8Pj0q3G1dNZHVVSUmJbDabNmzYUOZ1fH19q+U6Fendu7cyMjL0/vvva9OmTfrLX/6iBQsWaMmSJU53NGraL+++XPHggw9q586deuqpp3TbbbfJ19dXJSUlGjRokEpKSkrtX9ZrWt44V9eYAu6KIANY0JW7FNnZ2Tf8WmU9mjl69KhatmxZ7jFt2rSRYRhq1aqV2rdvfwOrq1hQUJDGjx+v8ePHKz8/X71799acOXMcQaa8TyMODw/Xli1bdPHiRae7Mv/6178c26/8WVJSohMnTjjdfTp+/Hila/zxxx+1detWJSYm6vnnn3e0u/JIDLgZMUcGcGPbtm0r81/UV+anRERE3PAa1q9fr++++86x/sUXX2jPnj0aPHhwuccMHz5cHh4eSkxMLFW/YRg18rjj6mv4+vqqbdu2stvtjrYrn+Fy4cIFp33vvfdeFRcX64033nBqX7BggWw2m6PvMTExkqQ333zTab+qfOrylTspV79OCxcurPQ5gJsZd2QANzZ58mRdunRJDzzwgDp06KDLly9r586dWr16tVq2bKnx48ff8Bratm2rXr166YknnpDdbtfChQvVqFEjPf300+Ue06ZNG7300ktKSEjQyZMnNWzYMPn5+enEiRNat26dJkyYoFmzZt3Qujt16qQ+ffooKipKQUFB2rt3r/72t79p0qRJjn2ioqIkSVOmTFFMTIw8PDw0YsQIDRkyRH379tXvf/97nTx5Ul27dtWmTZv0/vvva9q0aWrTpo3j+NjYWC1cuFDnz593vP366NGjksq/4/NL/v7+6t27t+bNm6eioiLdcsst2rRpk06cOHEDXhWg9iHIAG7sj3/8o9asWaOPPvpIf/7zn3X58mWFhYXpySef1LPPPlupz2K5XmPGjFGdOnW0cOFCnTt3Tj169NAbb7yhZs2aVXjcb3/7W7Vv314LFixQYmKipJ8nGA8cOFD333//Da97ypQp+uCDD7Rp0ybZ7XaFh4frpZde0lNPPeXYZ/jw4Zo8ebJWrVqld955R4ZhaMSIEapTp44++OADPf/881q9erVSUlLUsmVLvfrqq5o5c6bTdZYvX66QkBCtXLlS69at04ABA7R69WpFRETIx8enUrWuWLFCkydPVnJysgzD0MCBA7VhwwaFhoZW62sC1EY2g5lgAMpw8uRJtWrVSq+++uoNv3tS2xw4cED/7//9P73zzjsaNWqU2eUAtRpzZADgOvz000+l2hYuXKg6derwibpADeDREgBch3nz5iktLU19+/aVp6enNmzYoA0bNmjChAmlPqsHQPUjyADAdfjVr36lzZs368UXX1R+fr7CwsI0Z84c/f73vze7NOCmwBwZAABgWcyRAQAAlkWQAQAAllXr58iUlJTo9OnT8vPzq9SHUwEAAPMZhqGLFy8qNDRUdeqUf9+l1geZ06dP884BAAAsKisrS82bNy93e60PMle+8C0rK0v+/v4mVwMAACojLy9PLVq0cPri1rLU+iBz5XGSv78/QQYAAIu51rQQJvsCAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLIsgAAADLcpsgM3fuXNlsNk2bNs3RVlhYqPj4eDVq1Ei+vr6KjY3V2bNnzSsSAAC4FbcIMl9++aXeeustRUZGOrVPnz5dH374odasWaPU1FSdPn1aw4cPN6lKAADgbkwPMvn5+Ro1apT+53/+Rw0bNnS05+bmaunSpZo/f7769eunqKgopaSkaOfOndq9e7eJFQMAAHdhepCJj4/XfffdpwEDBji1p6WlqaioyKm9Q4cOCgsL065du2q6TAAA4IY8zbz4qlWrtG/fPn355Zeltp05c0ZeXl4KDAx0am/atKnOnDlT7jntdrvsdrtjPS8vr9rqrS0yMzOVk5NjdhlVEhwcrLCwMLPLAAC4GdOCTFZWlqZOnarNmzfLx8en2s6blJSkxMTEajtfbZOZmamIiI4qLLxkdilV4uNTX+npRwgzAAAnpgWZtLQ0nTt3Tt26dXO0FRcXa8eOHXrjjTe0ceNGXb58WRcuXHC6K3P27FmFhISUe96EhATNmDHDsZ6Xl6cWLVrckD5YUU5Ozn9CzDuSOppdTiUdUWHhaOXk5BBkAABOTAsy/fv316FDh5zaxo8frw4dOuiZZ55RixYtVLduXW3dulWxsbGSpPT0dGVmZio6Orrc83p7e8vb2/uG1l47dJTU7Zp7AQDgzkwLMn5+furcubNTW4MGDdSoUSNHe1xcnGbMmKGgoCD5+/tr8uTJio6O1h133GFGyQAAwM2YOtn3WhYsWKA6deooNjZWdrtdMTExevPNN80uCwAAuAm3CjLbt293Wvfx8VFycrKSk5PNKQgAALg10z9HBgAAwFUEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFlu9RUFVpOZmamcnByzy6iSI0eOmF0CAADVhiDjoszMTEVEdFRh4SWzSwEA4KZFkHFRTk7Of0LMO5I6ml1OFXwk6TmziwAAoFoQZK5bR0ndzC6iCni0BACoPZjsCwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALIsgAwAALMvUILN48WJFRkbK399f/v7+io6O1oYNGxzb+/TpI5vN5rRMnDjRxIoBAIA78TTz4s2bN9fcuXPVrl07GYaht99+W0OHDtX+/ft16623SpIee+wxvfDCC45j6tevb1a5AADAzZgaZIYMGeK0/vLLL2vx4sXavXu3I8jUr19fISEhZpQHAADcnNvMkSkuLtaqVatUUFCg6OhoR/u7776r4OBgde7cWQkJCbp06ZKJVQIAAHdi6h0ZSTp06JCio6NVWFgoX19frVu3Tp06dZIkjRw5UuHh4QoNDdXBgwf1zDPPKD09XWvXri33fHa7XXa73bGel5d3w/sAAADMYXqQiYiI0IEDB5Sbm6u//e1vGjt2rFJTU9WpUydNmDDBsV+XLl3UrFkz9e/fXxkZGWrTpk2Z50tKSlJiYmJNlQ8AAExk+qMlLy8vtW3bVlFRUUpKSlLXrl21aNGiMvft2bOnJOn48ePlni8hIUG5ubmOJSsr64bUDQAAzGf6HZmrlZSUOD0a+qUDBw5Ikpo1a1bu8d7e3vL29r4RpQEAADdjapBJSEjQ4MGDFRYWposXL2rFihXavn27Nm7cqIyMDK1YsUL33nuvGjVqpIMHD2r69Onq3bu3IiMjzSwbAAC4CVODzLlz5zRmzBhlZ2crICBAkZGR2rhxo+655x5lZWVpy5YtWrhwoQoKCtSiRQvFxsbq2WefNbNkAADgRkwNMkuXLi13W4sWLZSamlqD1QAAAKsxfbIvAACAqwgyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAskwNMosXL1ZkZKT8/f3l7++v6OhobdiwwbG9sLBQ8fHxatSokXx9fRUbG6uzZ8+aWDEAAHAnpgaZ5s2ba+7cuUpLS9PevXvVr18/DR06VF9//bUkafr06frwww+1Zs0apaam6vTp0xo+fLiZJQMAADfiaebFhwwZ4rT+8ssva/Hixdq9e7eaN2+upUuXasWKFerXr58kKSUlRR07dtTu3bt1xx13mFEyAABwI24zR6a4uFirVq1SQUGBoqOjlZaWpqKiIg0YMMCxT4cOHRQWFqZdu3aZWCkAAHAXpt6RkaRDhw4pOjpahYWF8vX11bp169SpUycdOHBAXl5eCgwMdNq/adOmOnPmTLnns9vtstvtjvW8vLwbVToAADCZ6XdkIiIidODAAe3Zs0dPPPGExo4dq3/+858uny8pKUkBAQGOpUWLFtVYLQAAcCemBxkvLy+1bdtWUVFRSkpKUteuXbVo0SKFhITo8uXLunDhgtP+Z8+eVUhISLnnS0hIUG5urmPJysq6wT0AAABmMT3IXK2kpER2u11RUVGqW7eutm7d6tiWnp6uzMxMRUdHl3u8t7e34+3cVxYAAFA7mTpHJiEhQYMHD1ZYWJguXryoFStWaPv27dq4caMCAgIUFxenGTNmKCgoSP7+/po8ebKio6N5xxIAAJBkcpA5d+6cxowZo+zsbAUEBCgyMlIbN27UPffcI0lasGCB6tSpo9jYWNntdsXExOjNN980s2QAAOBGTA0yS5curXC7j4+PkpOTlZycXEMVAQAAK3G7OTIAAACVRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWZepXFABVceTIEbNLqJLg4GCFhYWZXQYA1GoEGVhAtqQ6Gj16tNmFVImPT32lpx8hzADADUSQgQVckFQi6R1JHc0tpdKOqLBwtHJycggyAHADEWRgIR0ldTO7CACAG2GyLwAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCyCDAAAsCxTg0xSUpK6d+8uPz8/NWnSRMOGDVN6errTPn369JHNZnNaJk6caFLFAADAnZgaZFJTUxUfH6/du3dr8+bNKioq0sCBA1VQUOC032OPPabs7GzHMm/ePJMqBgAA7sTTzIt//PHHTuvLli1TkyZNlJaWpt69ezva69evr5CQkJouDwAAuDm3miOTm5srSQoKCnJqf/fddxUcHKzOnTsrISFBly5dMqM8AADgZky9I/NLJSUlmjZtmu6880517tzZ0T5y5EiFh4crNDRUBw8e1DPPPKP09HStXbu2zPPY7XbZ7XbHel5e3g2vHQAAmMNtgkx8fLwOHz6szz77zKl9woQJjp+7dOmiZs2aqX///srIyFCbNm1KnScpKUmJiYk3vF4AAGA+t3i0NGnSJP3973/Xtm3b1Lx58wr37dmzpyTp+PHjZW5PSEhQbm6uY8nKyqr2egEAgHtw6Y7MN998o9atW1/3xQ3D0OTJk7Vu3Tpt375drVq1uuYxBw4ckCQ1a9aszO3e3t7y9va+7toAAID7c+mOTNu2bdW3b1+98847KiwsdPni8fHxeuedd7RixQr5+fnpzJkzOnPmjH766SdJUkZGhl588UWlpaXp5MmT+uCDDzRmzBj17t1bkZGRLl8XAADUDi4FmX379ikyMlIzZsxQSEiIHn/8cX3xxRdVPs/ixYuVm5urPn36qFmzZo5l9erVkiQvLy9t2bJFAwcOVIcOHTRz5kzFxsbqww8/dKVsAABQy7j0aOm2227TokWL9Nprr+mDDz7QsmXL1KtXL7Vv316PPvqoHnnkETVu3Pia5zEMo8LtLVq0UGpqqislAgCAm8B1Tfb19PTU8OHDtWbNGr3yyis6fvy4Zs2apRYtWmjMmDHKzs6urjoBAABKua4gs3fvXj355JNq1qyZ5s+fr1mzZikjI0ObN2/W6dOnNXTo0OqqEwAAoBSXHi3Nnz9fKSkpSk9P17333qvly5fr3nvvVZ06P+eiVq1aadmyZWrZsmV11goAAODEpSCzePFiPfrooxo3bly5b4Nu0qSJli5del3FAQAAVMSlIHPs2LFr7uPl5aWxY8e6cnoAAIBKcWmOTEpKitasWVOqfc2aNXr77bevuygAAIDKcCnIJCUlKTg4uFR7kyZN9Ic//OG6iwIAAKgMl4JMZmZmmV8nEB4erszMzOsuCgAAoDJcCjJNmjTRwYMHS7V/9dVXatSo0XUXBQAAUBkuBZmHH35YU6ZM0bZt21RcXKzi4mJ98sknmjp1qkaMGFHdNQIAAJTJpXctvfjiizp58qT69+8vT8+fT1FSUqIxY8YwRwYAANQYl4KMl5eXVq9erRdffFFfffWV6tWrpy5duig8PLy66wMAACiXS0Hmivbt26t9+/bVVQsAAECVuBRkiouLtWzZMm3dulXnzp1TSUmJ0/ZPPvmkWooDAACoiEtBZurUqVq2bJnuu+8+de7cWTabrbrrAgAAuCaXgsyqVav03nvv6d57763uegAAACrNpbdfe3l5qW3bttVdCwAAQJW4FGRmzpypRYsWyTCM6q4HAACg0lx6tPTZZ59p27Zt2rBhg2699VbVrVvXafvatWurpTgAAICKuBRkAgMD9cADD1R3LQAAAFXiUpBJSUmp7joAAACqzKU5MpL073//W1u2bNFbb72lixcvSpJOnz6t/Pz8aisOAACgIi7dkfn22281aNAgZWZmym6365577pGfn59eeeUV2e12LVmypLrrBAAAKMWlOzJTp07V7bffrh9//FH16tVztD/wwAPaunVrtRUHAABQEZfuyHz66afauXOnvLy8nNpbtmyp7777rloKAwAAuBaX7siUlJSouLi4VPupU6fk5+d33UUBAABUhktBZuDAgVq4cKFj3WazKT8/X7Nnz+ZrCwAAQI1x6dHSa6+9ppiYGHXq1EmFhYUaOXKkjh07puDgYK1cubK6awQAACiTS0GmefPm+uqrr7Rq1SodPHhQ+fn5iouL06hRo5wm/wIAANxILgUZSfL09NTo0aOrsxYAAIAqcSnILF++vMLtY8aMcakYAACAqnApyEydOtVpvaioSJcuXZKXl5fq169PkAEAADXCpXct/fjjj05Lfn6+0tPT1atXLyb7AgCAGuPydy1drV27dpo7d26puzUVSUpKUvfu3eXn56cmTZpo2LBhSk9Pd9qnsLBQ8fHxatSokXx9fRUbG6uzZ89WV9kAAMDCqi3ISD9PAD59+nSl909NTVV8fLx2796tzZs3q6ioSAMHDlRBQYFjn+nTp+vDDz/UmjVrlJqaqtOnT2v48OHVWTYAALAol+bIfPDBB07rhmEoOztbb7zxhu68885Kn+fjjz92Wl+2bJmaNGmitLQ09e7dW7m5uVq6dKlWrFihfv36SZJSUlLUsWNH7d69W3fccYcr5QMAgFrCpSAzbNgwp3WbzabGjRurX79+eu2111wuJjc3V5IUFBQkSUpLS1NRUZEGDBjg2KdDhw4KCwvTrl27CDIAANzkXAoyJSUl1V2HSkpKNG3aNN15553q3LmzJOnMmTPy8vJSYGCg075NmzbVmTNnyjyP3W6X3W53rOfl5VV7rQAAwD1U6xyZ6xEfH6/Dhw9r1apV13WepKQkBQQEOJYWLVpUU4UAAMDduHRHZsaMGZXed/78+dfcZ9KkSfr73/+uHTt2qHnz5o72kJAQXb58WRcuXHC6K3P27FmFhISUea6EhASn+vLy8ggzAADUUi4Fmf3792v//v0qKipSRESEJOno0aPy8PBQt27dHPvZbLYKz2MYhiZPnqx169Zp+/btatWqldP2qKgo1a1bV1u3blVsbKwkKT09XZmZmYqOji7znN7e3vL29nalWwAAwGJcCjJDhgyRn5+f3n77bTVs2FDSzx+SN378eN11112aOXNmpc4THx+vFStW6P3335efn59j3ktAQIDq1aungIAAxcXFacaMGQoKCpK/v78mT56s6OhoJvoCAADXgsxrr72mTZs2OUKMJDVs2FAvvfSSBg4cWOkgs3jxYklSnz59nNpTUlI0btw4SdKCBQtUp04dxcbGym63KyYmRm+++aYrZQMAgFrGpSCTl5en77//vlT7999/r4sXL1b6PIZhXHMfHx8fJScnKzk5uUo1AgCA2s+ldy098MADGj9+vNauXatTp07p1KlT+r//+z/FxcXxqbsAAKDGuHRHZsmSJZo1a5ZGjhypoqKin0/k6am4uDi9+uqr1VogAABAeVwKMvXr19ebb76pV199VRkZGZKkNm3aqEGDBtVaHAAAQEWu6wPxsrOzlZ2drXbt2qlBgwaVmvMCAABQXVwKMufPn1f//v3Vvn173XvvvcrOzpYkxcXFVfodSwAAANfLpSAzffp01a1bV5mZmapfv76j/aGHHir1jdYAAAA3iktzZDZt2qSNGzc6fZ2AJLVr107ffvtttRQGAABwLS7dkSkoKHC6E3PFDz/8wNcDAACAGuNSkLnrrru0fPlyx7rNZlNJSYnmzZunvn37VltxAAAAFXHp0dK8efPUv39/7d27V5cvX9bTTz+tr7/+Wj/88IM+//zz6q4RAACgTC7dkencubOOHj2qXr16aejQoSooKNDw4cO1f/9+tWnTprprBAAAKFOV78gUFRVp0KBBWrJkiX7/+9/fiJoAAAAqpcp3ZOrWrauDBw/eiFoAAACqxKVHS6NHj9bSpUuruxYAAIAqcWmy77///W/99a9/1ZYtWxQVFVXqO5bmz59fLcUBAABUpEpB5ptvvlHLli11+PBhdevWTZJ09OhRp31sNlv1VQcAAFCBKgWZdu3aKTs7W9u2bZP081cSvP7662ratOkNKQ4AAKAiVZojc/W3W2/YsEEFBQXVWhAAAEBluTTZ94qrgw0AAEBNqlKQsdlspebAMCcGAACYpUpzZAzD0Lhx4xxfDFlYWKiJEyeWetfS2rVrq69CAACAclQpyIwdO9ZpffTo0dVaDAAAQFVUKcikpKTcqDoAAACq7Lom+wIAAJiJIAMAACyLIAMAACyLIAMAACyLIAMAACzLpW+/BlA5R44cMbuEKgkODlZYWJjZZQBApRFkgBsiW1Idy33Wko9PfaWnHyHMALAMggxwQ1yQVCLpHUkdzS2l0o6osHC0cnJyCDIALIMgA9xQHSV1M7sIAKi1mOwLAAAsy9Qgs2PHDg0ZMkShoaGy2Wxav3690/Zx48Y5vnH7yjJo0CBzigUAAG7H1CBTUFCgrl27Kjk5udx9Bg0apOzsbMeycuXKGqwQAAC4M1PnyAwePFiDBw+ucB9vb2+FhITUUEUAAMBK3H6OzPbt29WkSRNFREToiSee0Pnz580uCQAAuAm3ftfSoEGDNHz4cLVq1UoZGRn63e9+p8GDB2vXrl3y8PAo8xi73S673e5Yz8vLq6lyAQBADXPrIDNixAjHz126dFFkZKTatGmj7du3q3///mUek5SUpMTExJoqEQAAmMjtHy39UuvWrRUcHKzjx4+Xu09CQoJyc3MdS1ZWVg1WCAAAapJb35G52qlTp3T+/Hk1a9as3H28vb3l7e1dg1UBAACzmBpk8vPzne6unDhxQgcOHFBQUJCCgoKUmJio2NhYhYSEKCMjQ08//bTatm2rmJgYE6sGAADuwtQgs3fvXvXt29exPmPGDEnS2LFjtXjxYh08eFBvv/22Lly4oNDQUA0cOFAvvvgid1wAAIAkk4NMnz59ZBhGuds3btxYg9UAAACrsdRkXwAAgF8iyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsyNcjs2LFDQ4YMUWhoqGw2m9avX++03TAMPf/882rWrJnq1aunAQMG6NixY+YUCwAA3I6pQaagoEBdu3ZVcnJymdvnzZun119/XUuWLNGePXvUoEEDxcTEqLCwsIYrBQAA7sjTzIsPHjxYgwcPLnObYRhauHChnn32WQ0dOlSStHz5cjVt2lTr16/XiBEjarJUAADghtx2jsyJEyd05swZDRgwwNEWEBCgnj17ateuXSZWBgAA3IWpd2QqcubMGUlS06ZNndqbNm3q2FYWu90uu93uWM/Ly7sxBQIAANO57R0ZVyUlJSkgIMCxtGjRwuySAADADeK2QSYkJESSdPbsWaf2s2fPOraVJSEhQbm5uY4lKyvrhtYJAADM47ZBplWrVgoJCdHWrVsdbXl5edqzZ4+io6PLPc7b21v+/v5OCwAAqJ1MnSOTn5+v48ePO9ZPnDihAwcOKCgoSGFhYZo2bZpeeukltWvXTq1atdJzzz2n0NBQDRs2zLyiAQCA2zA1yOzdu1d9+/Z1rM+YMUOSNHbsWC1btkxPP/20CgoKNGHCBF24cEG9evXSxx9/LB8fH7NKBgAAbsTUINOnTx8ZhlHudpvNphdeeEEvvPBCDVYFAACswm3nyAAAAFwLQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFgWQQYAAFiWWweZOXPmyGazOS0dOnQwuywAAOAmPM0u4FpuvfVWbdmyxbHu6en2JQMAgBri9qnA09NTISEhZpcBAADckFs/WpKkY8eOKTQ0VK1bt9aoUaOUmZlpdkkAAMBNuPUdmZ49e2rZsmWKiIhQdna2EhMTddddd+nw4cPy8/Mr8xi73S673e5Yz8vLq6lyAQBADXPrIDN48GDHz5GRkerZs6fCw8P13nvvKS4ursxjkpKSlJiYWFMlAgAAE7n9o6VfCgwMVPv27XX8+PFy90lISFBubq5jycrKqsEKAQBATbJUkMnPz1dGRoaaNWtW7j7e3t7y9/d3WgAAQO3k1kFm1qxZSk1N1cmTJ7Vz50498MAD8vDw0MMPP2x2aQAAwA249RyZU6dO6eGHH9b58+fVuHFj9erVS7t371bjxo3NLg0AALgBtw4yq1atMrsEAADgxtz60RIAAEBFCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyPM0uAABuNpmZmcrJyTG7jCqx2+3y9vY2u4wqCQ4OVlhYmNllVIkVfzfMfp0JMgBQgzIzMxUR0VGFhZfMLqWKPCQVm11Elfj41Fd6+hHLhBmr/m6Y/ToTZACgBuXk5Pznf1TvSOpodjmV9JGk52Stmo+osHC0cnJyLBNkrPm7Yf7rTJABAFN0lNTN7CIq6ch//rRSzVbG61wVTPYFAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWZYkgk5ycrJYtW8rHx0c9e/bUF198YXZJAADADbh9kFm9erVmzJih2bNna9++feratatiYmJ07tw5s0sDAAAmc/sgM3/+fD322GMaP368OnXqpCVLlqh+/fr661//anZpAADAZG4dZC5fvqy0tDQNGDDA0VanTh0NGDBAu3btMrEyAADgDjzNLqAiOTk5Ki4uVtOmTZ3amzZtqn/9619lHmO322W32x3rubm5kqS8vLxqrS0/P/8/P6VJyq9oVzdz5D9/Wqluaq4Z6ZKktLS0X/x+u786deqopKTE7DIqLT09/T8/Wel3g9/nmmDN342fa87Pz6/2/89eOZ9hGBXvaLix7777zpBk7Ny506n9qaeeMnr06FHmMbNnzzYksbCwsLCwsNSCJSsrq8Ks4NZ3ZIKDg+Xh4aGzZ886tZ89e1YhISFlHpOQkKAZM2Y41ktKSvTDDz+oUaNGstlsTvvm5eWpRYsWysrKkr+/f/V3wA3QR+ur7f2T6GNtUNv7J9HHmmYYhi5evKjQ0NAK93PrIOPl5aWoqCht3bpVw4YNk/RzMNm6dasmTZpU5jHe3t7y9vZ2agsMDKzwOv7+/qYP2I1GH62vtvdPoo+1QW3vn0Qfa1JAQMA193HrICNJM2bM0NixY3X77berR48eWrhwoQoKCjR+/HizSwMAACZz+yDz0EMP6fvvv9fzzz+vM2fO6LbbbtPHH39cagIwAAC4+bh9kJGkSZMmlfso6Xp4e3tr9uzZpR5F1Sb00fpqe/8k+lgb1Pb+SfTRXdkM41rvawIAAHBPbv2BeAAAABUhyAAAAMsiyAAAAMsiyAAAAMu6qYNMcnKyWrZsKR8fH/Xs2VNffPGF2SVVmzlz5shmszktHTp0MLssl+3YsUNDhgxRaGiobDab1q9f77TdMAw9//zzatasmerVq6cBAwbo2LFj5hTromv1cdy4caXGdNCgQeYU64KkpCR1795dfn5+atKkiYYNG/aL75b5WWFhoeLj49WoUSP5+voqNja21Cd7u7PK9LFPnz6lxnHixIkmVVx1ixcvVmRkpOMD06Kjo7VhwwbHdquP4bX6Z/XxK8vcuXNls9k0bdo0R5uVxvGmDTKrV6/WjBkzNHv2bO3bt09du3ZVTEyMzp07Z3Zp1ebWW29Vdna2Y/nss8/MLsllBQUF6tq1q5KTk8vcPm/ePL3++utasmSJ9uzZowYNGigmJkaFhYU1XKnrrtVHSRo0aJDTmK5cubIGK7w+qampio+P1+7du7V582YVFRVp4MCBKigocOwzffp0ffjhh1qzZo1SU1N1+vRpDR8+3MSqq6YyfZSkxx57zGkc582bZ1LFVde8eXPNnTtXaWlp2rt3r/r166ehQ4fq66+/lmT9MbxW/yRrj9/VvvzyS7311luKjIx0arfUOFbLtztaUI8ePYz4+HjHenFxsREaGmokJSWZWFX1mT17ttG1a1ezy7ghJBnr1q1zrJeUlBghISHGq6++6mi7cOGC4e3tbaxcudKECq/f1X00DMMYO3asMXToUFPquRHOnTtnSDJSU1MNw/h5zOrWrWusWbPGsc+RI0cMScauXbvMKvO6XN1HwzCMu+++25g6dap5Rd0ADRs2NP7yl7/UyjE0jP+/f4ZRu8bv4sWLRrt27YzNmzc79ctq43hT3pG5fPmy0tLSNGDAAEdbnTp1NGDAAO3atcvEyqrXsWPHFBoaqtatW2vUqFHKzMw0u6Qb4sSJEzpz5ozTeAYEBKhnz561ajwlafv27WrSpIkiIiL0xBNP6Pz582aX5LLc3FxJUlBQkCQpLS1NRUVFTuPYoUMHhYWFWXYcr+7jFe+++66Cg4PVuXNnJSQk6NKlS2aUd92Ki4u1atUqFRQUKDo6utaN4dX9u6K2jF98fLzuu+8+p/GSrPd30RKf7FvdcnJyVFxcXOprDpo2bap//etfJlVVvXr27Klly5YpIiJC2dnZSkxM1F133aXDhw/Lz8/P7PKq1ZkzZySpzPG8sq02GDRokIYPH65WrVopIyNDv/vd7zR48GDt2rVLHh4eZpdXJSUlJZo2bZruvPNOde7cWdLP4+jl5VXqS16tOo5l9VGSRo4cqfDwcIWGhurgwYN65plnlJ6errVr15pYbdUcOnRI0dHRKiwslK+vr9atW6dOnTrpwIEDtWIMy+ufVDvGT5JWrVqlffv26csvvyy1zWp/F2/KIHMzGDx4sOPnyMhI9ezZU+Hh4XrvvfcUFxdnYmVw1YgRIxw/d+nSRZGRkWrTpo22b9+u/v37m1hZ1cXHx+vw4cOWnrd1LeX1ccKECY6fu3TpombNmql///7KyMhQmzZtarpMl0REROjAgQPKzc3V3/72N40dO1apqalml1Vtyutfp06dasX4ZWVlaerUqdq8ebN8fHzMLue63ZSPloKDg+Xh4VFqBvbZs2cVEhJiUlU3VmBgoNq3b6/jx4+bXUq1uzJmN9N4SlLr1q0VHBxsuTGdNGmS/v73v2vbtm1q3ry5oz0kJESXL1/WhQsXnPa34jiW18ey9OzZU5IsNY5eXl5q27atoqKilJSUpK5du2rRokW1ZgzL619ZrDh+aWlpOnfunLp16yZPT095enoqNTVVr7/+ujw9PdW0aVNLjeNNGWS8vLwUFRWlrVu3OtpKSkq0detWp+egtUl+fr4yMjLUrFkzs0updq1atVJISIjTeObl5WnPnj21djwl6dSpUzp//rxlxtQwDE2aNEnr1q3TJ598olatWjltj4qKUt26dZ3GMT09XZmZmZYZx2v1sSwHDhyQJMuMY1lKSkpkt9trxRiW5Ur/ymLF8evfv78OHTqkAwcOOJbbb79do0aNcvxsqXE0e7axWVatWmV4e3sby5YtM/75z38aEyZMMAIDA40zZ86YXVq1mDlzprF9+3bjxIkTxueff24MGDDACA4ONs6dO2d2aS65ePGisX//fmP//v2GJGP+/PnG/v37jW+//dYwDMOYO3euERgYaLz//vvGwYMHjaFDhxqtWrUyfvrpJ5Mrr7yK+njx4kVj1qxZxq5du4wTJ04YW7ZsMbp162a0a9fOKCwsNLv0SnniiSeMgIAAY/v27UZ2drZjuXTpkmOfiRMnGmFhYcYnn3xi7N2714iOjjaio6NNrLpqrtXH48ePGy+88IKxd+9e48SJE8b7779vtG7d2ujdu7fJlVfeb3/7WyM1NdU4ceKEcfDgQeO3v/2tYbPZjE2bNhmGYf0xrKh/tWH8ynP1u7GsNI43bZAxDMP405/+ZISFhRleXl5Gjx49jN27d5tdUrV56KGHjGbNmhleXl7GLbfcYjz00EPG8ePHzS7LZdu2bTMklVrGjh1rGMbPb8F+7rnnjKZNmxre3t5G//79jfT0dHOLrqKK+njp0iVj4MCBRuPGjY26desa4eHhxmOPPWap4F1W3yQZKSkpjn1++ukn48knnzQaNmxo1K9f33jggQeM7Oxs84quomv1MTMz0+jdu7cRFBRkeHt7G23btjWeeuopIzc319zCq+DRRx81wsPDDS8vL6Nx48ZG//79HSHGMKw/hhX1rzaMX3muDjJWGkebYRhGzd3/AQAAqD435RwZAABQOxBkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAACAZRFkAFhSnz59NG3aNLPLAGAyggyAGjdkyBANGjSozG2ffvqpbDabDh48WMNVAbAiggyAGhcXF6fNmzfr1KlTpbalpKTo9ttvV2RkpAmVAbAaggyAGvdf//Vfaty4sZYtW+bUnp+frzVr1mjYsGF6+OGHdcstt6h+/frq0qWLVq5cWeE5bTab1q9f79QWGBjodI2srCw9+OCDCgwMVFBQkIYOHaqTJ09WT6cAmIIgA6DGeXp6asyYMVq2bJl++XVva9asUXFxsUaPHq2oqCj94x//0OHDhzVhwgQ98sgj+uKLL1y+ZlFRkWJiYuTn56dPP/1Un3/+uXx9fTVo0CBdvny5OroFwAQEGQCmePTRR5WRkaHU1FRHW0pKimJjYxUeHq5Zs2bptttuU+vWrTV58mQNGjRI7733nsvXW716tUpKSvSXv/xFXbp0UceOHZWSkqLMzExt3769GnoEwAwEGQCm6NChg371q1/pr3/9qyTp+PHj+vTTTxUXF6fi4mK9+OKL6tKli4KCguTr66uNGzcqMzPT5et99dVXOn78uPz8/OTr6ytfX18FBQWpsLBQGRkZ1dUtADXM0+wCANy84uLiNHnyZCUnJyslJUVt2rTR3XffrVdeeUWLFi3SwoUL1aVLFzVo0EDTpk2r8BGQzWZzekwl/fw46Yr8/HxFRUXp3XffLXVs48aNq69TAGoUQQaAaR588EFNnTpVK1as0PLly/XEE0/IZrPp888/19ChQzV69GhJUklJiY4ePapOnTqVe67GjRsrOzvbsX7s2DFdunTJsd6tWzetXr1aTZo0kb+//43rFIAaxaMlAKbx9fXVQw89pISEBGVnZ2vcuHGSpHbt2mnz5s3auXOnjhw5oscff1xnz56t8Fz9+vXTG2+8of3792vv3r2aOHGi6tat69g+atQoBQcHa+jQofr000914sQJbd++XVOmTCnzbeAArIEgA8BUcXFx+vHHHxUTE6PQ0FBJ0rPPPqtu3bopJiZGffr0UUhIiIYNG1bheV577TW1aNFCd911l0aOHKlZs2apfv36ju3169fXjh07FBYWpuHDh6tjx46Ki4tTYWEhd2gAC7MZVz9UBgAAsAjuyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMsiyAAAAMv6/wBoVRZDK/8gywAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 12ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "Epoch: 2/10000, D Loss: [0.7013984  0.43359375], G Loss: 0.25035998225212097, Val D Loss: [0.69775862 0.296875  ]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 3/10000, D Loss: [0.7003815  0.45703125], G Loss: 0.25061315298080444, Val D Loss: [0.69763875 0.0703125 ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 4/10000, D Loss: [0.7007367 0.46875  ], G Loss: 0.25073686242103577, Val D Loss: [0.69793493 0.0703125 ]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 5/10000, D Loss: [0.70102817 0.45703125], G Loss: 0.2508733868598938, Val D Loss: [0.69725788 0.1171875 ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 6/10000, D Loss: [0.70067835 0.44921875], G Loss: 0.25131791830062866, Val D Loss: [0.69690469 0.0703125 ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "Epoch: 7/10000, D Loss: [0.69951653 0.44921875], G Loss: 0.2505542039871216, Val D Loss: [0.69861048 0.140625  ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 8/10000, D Loss: [0.7008642 0.4296875], G Loss: 0.25079768896102905, Val D Loss: [0.69809327 0.09375   ]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 9/10000, D Loss: [0.7012131  0.45703125], G Loss: 0.250884473323822, Val D Loss: [0.69751799 0.32421875]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 10/10000, D Loss: [0.70106626 0.40234375], G Loss: 0.2518291473388672, Val D Loss: [0.6978105 0.0859375]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "Epoch: 11/10000, D Loss: [0.70164657 0.4296875 ], G Loss: 0.2503167986869812, Val D Loss: [0.69739985 0.3515625 ]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "Epoch: 12/10000, D Loss: [0.7010765 0.4296875], G Loss: 0.2511383295059204, Val D Loss: [0.69781965 0.13671875]\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 13/10000, D Loss: [0.70164394 0.390625  ], G Loss: 0.2505119740962982, Val D Loss: [0.69807673 0.078125  ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 14/10000, D Loss: [0.70170975 0.4296875 ], G Loss: 0.2507724165916443, Val D Loss: [0.69735807 0.125     ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 15/10000, D Loss: [0.7013917 0.4375   ], G Loss: 0.25100570917129517, Val D Loss: [0.69741604 0.34375   ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch: 16/10000, D Loss: [0.7008976 0.4296875], G Loss: 0.25116705894470215, Val D Loss: [0.69677502 0.07421875]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "Epoch: 17/10000, D Loss: [0.7020117 0.46875  ], G Loss: 0.25059860944747925, Val D Loss: [0.69737568 0.0625    ]\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch: 18/10000, D Loss: [0.700444  0.4140625], G Loss: 0.2514057755470276, Val D Loss: [0.69822115 0.0546875 ]\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch: 19/10000, D Loss: [0.6997423  0.42578125], G Loss: 0.2510565519332886, Val D Loss: [0.69746387 0.0859375 ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "Epoch: 20/10000, D Loss: [0.70223594 0.39453125], G Loss: 0.250370055437088, Val D Loss: [0.69773686 0.29296875]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "Epoch: 21/10000, D Loss: [0.7007607  0.44921875], G Loss: 0.2517783045768738, Val D Loss: [0.69745886 0.05078125]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 22/10000, D Loss: [0.7008279  0.47265625], G Loss: 0.2513093948364258, Val D Loss: [0.69769368 0.06640625]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 23/10000, D Loss: [0.70060205 0.45703125], G Loss: 0.2515866458415985, Val D Loss: [0.69798815 0.09375   ]\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "Epoch: 24/10000, D Loss: [0.70151997 0.41015625], G Loss: 0.25012436509132385, Val D Loss: [0.69810182 0.0546875 ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 25/10000, D Loss: [0.69970363 0.453125  ], G Loss: 0.25107520818710327, Val D Loss: [0.6978257 0.140625 ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 26/10000, D Loss: [0.70074594 0.421875  ], G Loss: 0.25097858905792236, Val D Loss: [0.69757801 0.078125  ]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 27/10000, D Loss: [0.70122975 0.484375  ], G Loss: 0.25129181146621704, Val D Loss: [0.69698608 0.35546875]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch: 28/10000, D Loss: [0.7023957 0.375    ], G Loss: 0.2506895959377289, Val D Loss: [0.69727471 0.36328125]\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "Epoch: 29/10000, D Loss: [0.7011065 0.3984375], G Loss: 0.25071239471435547, Val D Loss: [0.69741943 0.07421875]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "Epoch: 30/10000, D Loss: [0.70155525 0.41015625], G Loss: 0.25043246150016785, Val D Loss: [0.69778681 0.06640625]\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "Epoch: 31/10000, D Loss: [0.70103806 0.4453125 ], G Loss: 0.2516985535621643, Val D Loss: [0.69786847 0.11328125]\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samp = 1024*8\n",
        "# latent_dim\n",
        "n_lowest = 10\n",
        "result_vec = []\n",
        "noise = tf.random.normal(shape=(n_samp, latent_dim))\n",
        "synthetic_samples = generator.predict(noise)\n",
        "batch_val = next(val_gen)\n",
        "for batch_ in batch_val:\n",
        "  # batch_ = batch_val[1]\n",
        "  match_indices = [0,1,2,3,5,6,7,8,9]\n",
        "\n",
        "  data = [np.mean(np.sqrt((batch_[match_indices] - samp[match_indices])**2)) for samp in synthetic_samples]\n",
        "\n",
        "  indices = sorted(range(len(data)), key=lambda i: data[i])[:n_lowest]\n",
        "\n",
        "  most_similar = [synthetic_samples[i] for i in indices]\n",
        "\n",
        "  most_similar_scaled = [scaler.inverse_transform(sim.reshape(1,-1)) for sim in most_similar]\n",
        "\n",
        "  original_scaled = [scaler.inverse_transform(sim.reshape(1,-1)) for sim in [batch_]]\n",
        "  # most_similar_scaled_df = pd.DataFrame(most_similar_scaled, columns=numeric_cols.columns)\n",
        "\n",
        "  most_similar_scaled_2d = [np.squeeze(sim) for sim in most_similar_scaled]\n",
        "\n",
        "  original_scaled_2d = [np.squeeze(sim) for sim in original_scaled]\n",
        "\n",
        "  most_similar_scaled_df = pd.DataFrame(most_similar_scaled_2d, columns=numeric_cols.columns)\n",
        "\n",
        "  original_scaled_df = pd.DataFrame(original_scaled_2d, columns=numeric_cols.columns)\n",
        "\n",
        "  result = np.sqrt((np.mean(most_similar_scaled_df['imp_c_float'])- np.mean(original_scaled_df['imp_c_float']))**2)/np.mean(original_scaled_df['imp_c_float'])\n",
        "  # print(np.mean(original_scaled_df['agbd_m']))\n",
        "  result_vec.append(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-m4YknSb_ng",
        "outputId": "cff20706-2ab0-480b-e481-15ed2dcf8615"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256/256 [==============================] - 2s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc8rt5XeQkXF",
        "outputId": "d79f975f-2e07-4bab-83f3-569c5d82b62b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 28.531334 , -11.202219 , -40.439777 , -10.090137 ,   8.2734   ,\n",
              "         -9.428419 ,  11.930028 ,   1.0942104, -22.76571  ,   8.018955 ],\n",
              "       dtype=float32),\n",
              " array([ 26.278467 , -13.948817 , -43.122784 , -13.704297 ,  -0.3593356,\n",
              "         -0.880978 ,  17.13365  ,  -4.0011663, -16.45799  ,   8.377134 ],\n",
              "       dtype=float32),\n",
              " array([ 27.357634 , -13.8198805, -42.084545 , -13.7134905,   2.781976 ,\n",
              "         -1.5432317,  15.445559 ,  -6.4791827, -18.052958 ,   7.3337617],\n",
              "       dtype=float32),\n",
              " array([ 30.264784 , -11.677847 , -41.794704 , -11.004966 ,   6.7667494,\n",
              "         -6.901617 ,  12.113672 ,  -2.4122186, -23.751757 ,   7.4664197],\n",
              "       dtype=float32),\n",
              " array([ 2.7120161e+01, -1.5374141e+01, -4.3389359e+01, -1.3616334e+01,\n",
              "         4.1027898e-01,  2.4836615e-02,  1.7055265e+01, -6.4799428e+00,\n",
              "        -1.6840025e+01,  8.7692604e+00], dtype=float32),\n",
              " array([ 26.57422  , -14.09194  , -42.864433 , -14.682696 ,  -1.7990932,\n",
              "          2.1483393,  17.79635  ,  -7.8763576, -15.176037 ,   7.6323295],\n",
              "       dtype=float32),\n",
              " array([ 30.885653 , -12.297737 , -40.972473 , -11.344613 ,  10.935388 ,\n",
              "         -8.878796 ,  11.438049 ,   1.1128407, -24.370947 ,   8.392095 ],\n",
              "       dtype=float32),\n",
              " array([ 27.227896  , -14.235371  , -43.73579   , -14.326497  ,\n",
              "         -1.1940247 ,   0.55526173,  18.126545  ,  -6.5483193 ,\n",
              "        -16.99877   ,   8.360414  ], dtype=float32),\n",
              " array([ 26.707157 , -15.58845  , -42.970753 , -14.253486 ,  -0.6094159,\n",
              "          0.8304539,  16.143381 ,  -8.519323 , -16.747728 ,   8.931544 ],\n",
              "       dtype=float32),\n",
              " array([ 25.58497  , -15.169441 , -42.876514 , -14.88791  ,  -3.3159783,\n",
              "          3.2187798,  18.351938 ,  -8.434898 , -14.640684 ,   7.891635 ],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}