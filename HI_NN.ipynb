{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hayleypc/HawaiiClimate/blob/main/HI_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Quz3PwWnrs-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a69322-baf6-4e23-8ccd-52d21156a40c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diptest\n",
            "  Downloading diptest-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from diptest) (5.9.5)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from diptest) (1.26.4)\n",
            "Downloading diptest-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.7/195.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diptest\n",
            "Successfully installed diptest-0.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "!pip install diptest\n",
        "import diptest\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from shapely.geometry import Point\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lrQb4Owry2i",
        "outputId": "5abfa18a-1f91-4939-f0f9-362f6e6fdf29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK-z3uJFCryn"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWD2By-r9sOf"
      },
      "outputs": [],
      "source": [
        "# Preprocess data function\n",
        "def preprocess_data(matched_data):\n",
        "    matched_data['distance'] = 0\n",
        "    matched_data = matched_data[[str(i) == '20' for i in matched_data[\"depth_adj_bottom\"]] ]\n",
        "    matched_data['imp_c_float'] = matched_data['imp_c'].astype(float)\n",
        "\n",
        "    # Select ID fields and numeric columns\n",
        "    id_fields = matched_data[['source_dataset', 'island', 'dist_id', 'soil_column_id', 'unique_id', 'depth_top',\n",
        "                              'depth_bottom', 'depth_adj_bottom', 'latitude', 'longitude', 'x_sample', 'y_sample',\n",
        "                              'x_driver', 'y_driver']]\n",
        "    keep_cols = ['water', 'trees', 'grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built',\n",
        "                 'bare', 'snow_and_ice', 'max', 'elevation', 'landform', 'SRTM_mTPI', 'aet', 'def',\n",
        "                 'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn', 'tmmx', 'vap', 'vpd', 'vs',\n",
        "                 'agbd_m', 'agbd_sd', 'agbd_n']\n",
        "    numeric_cols = matched_data[keep_cols].replace('', np.nan).astype(float).fillna(0)\n",
        "\n",
        "    # Scale numeric columns\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_numeric_cols = scaler.fit_transform(numeric_cols)\n",
        "    scaled_numeric_df = pd.DataFrame(scaled_numeric_cols, columns=numeric_cols.columns, index=numeric_cols.index)\n",
        "\n",
        "    # Scale imp_c\n",
        "    min_c = matched_data['imp_c_float'].min()\n",
        "    max_c = matched_data['imp_c_float'].max()\n",
        "    scaled_imp_c = (matched_data['imp_c_float'] - min_c) / (max_c - min_c)\n",
        "\n",
        "    # Combine ID fields with scaled numeric data\n",
        "    numeric_df = pd.concat([id_fields, scaled_numeric_df], axis=1)\n",
        "    numeric_df['imp_c_scaled'] = scaled_imp_c\n",
        "\n",
        "    return numeric_df, scaler, min_c, max_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opr25fTaAKLo"
      },
      "outputs": [],
      "source": [
        "# Train model function\n",
        "def train_model(preprocessed_data):\n",
        "    keep_cols = ['water', 'trees', 'grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built',\n",
        "                 'bare', 'snow_and_ice', 'max', 'elevation', 'landform', 'SRTM_mTPI', 'aet', 'def',\n",
        "                 'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn', 'tmmx', 'vap', 'vpd', 'vs',\n",
        "                 'agbd_m', 'agbd_sd', 'agbd_n']\n",
        "    X = preprocessed_data[keep_cols]\n",
        "    y = preprocessed_data['imp_c_scaled']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build and compile model\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_dim=X_train.shape[1]),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(512, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(1024, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=128, verbose=1)\n",
        "\n",
        "    test_loss = model.evaluate(X_test, y_test)\n",
        "    predictions = model.predict(X_test).flatten()\n",
        "    r_squared = r2_score(y_test, predictions)\n",
        "\n",
        "    return model, test_loss, r_squared, predictions, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMaF7fNHAMQZ"
      },
      "outputs": [],
      "source": [
        "# Predict on reserve function\n",
        "def predict_on_reserve(preprocessed_data, model, min_c, max_c):\n",
        "    keep_cols = ['water', 'trees', 'grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built',\n",
        "                'bare', 'snow_and_ice', 'max', 'elevation', 'landform', 'SRTM_mTPI', 'aet', 'def',\n",
        "                'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn', 'tmmx', 'vap', 'vpd', 'vs',\n",
        "                'agbd_m', 'agbd_sd', 'agbd_n']\n",
        "    X = preprocessed_data[keep_cols]\n",
        "    predictions = model.predict(X)\n",
        "\n",
        "    inversed_predictions = predictions * (max_c - min_c) + min_c\n",
        "    inversed_truth = preprocessed_data['imp_c_scaled'] * (max_c - min_c) + min_c\n",
        "\n",
        "    df_out = preprocessed_data.copy()\n",
        "    df_out['predictions'] = predictions\n",
        "    df_out['inversed_predictions'] = inversed_predictions\n",
        "    df_out['inversed_imp_c'] = inversed_truth\n",
        "\n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHFSeNNFAOm4"
      },
      "outputs": [],
      "source": [
        "# Evaluate model function\n",
        "def evaluate_model(model, X_test, y_test, inversed_predictions, inversed_truth):\n",
        "    test_loss = model.evaluate(X_test, y_test)\n",
        "    r_squared = r2_score(inversed_truth, inversed_predictions)\n",
        "\n",
        "    print(\"Test Loss:\", test_loss)\n",
        "    print(\"R-Squared Score:\", r_squared)\n",
        "\n",
        "    mae = mean_absolute_error(inversed_truth, inversed_predictions)\n",
        "    rmse = mean_squared_error(inversed_truth, inversed_predictions, squared=False)\n",
        "\n",
        "    print(\"Mean Absolute Error (MAE):\", mae)\n",
        "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "    # Scatter plot of true vs predicted values\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=inversed_truth, y=inversed_predictions)\n",
        "    plt.xlabel(\"True Values\")\n",
        "    plt.ylabel(\"Predicted Values\")\n",
        "    plt.title(\"True vs Predicted Values\")\n",
        "    plt.plot([min(inversed_truth), max(inversed_truth)], [min(inversed_truth), max(inversed_truth)], 'r')\n",
        "    plt.show()\n",
        "\n",
        "    # Residual plot\n",
        "    residuals = inversed_truth - inversed_predictions\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(residuals, kde=True)\n",
        "    plt.xlabel(\"Residuals\")\n",
        "    plt.title(\"Distribution of Residuals\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-m9vVyFARKQ"
      },
      "outputs": [],
      "source": [
        "# Cross-validation and model training\n",
        "def build_model(input_shape, output_shape):\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_dim=input_shape),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(512, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(1024, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(output_shape, activation='linear')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfP-Yv3oAUIG"
      },
      "outputs": [],
      "source": [
        "# Define function for rescaling\n",
        "def rescale_to_minus_one_one(array):\n",
        "    return 2 * (array - array.min()) / (array.max() - array.min()) - 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "PO2AwaR9EgHi"
      },
      "outputs": [],
      "source": [
        "def train_model_a(preprocess_data):\n",
        "\n",
        "    keep_cols = ['water', 'trees','grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built',\n",
        "                'bare', 'snow_and_ice', 'max', 'elevation', 'landform', 'SRTM_mTPI','aet', 'def',\n",
        "                'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn','tmmx', 'vap', 'vpd', 'vs',\n",
        "                'agbd_m', 'agbd_sd', 'agbd_n']\n",
        "\n",
        "    X = preprocess_data[keep_cols]\n",
        "\n",
        "    y = preprocess_data['imp_c_scaled']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define model\n",
        "    def build_model(input_shape):\n",
        "        model = Sequential([\n",
        "            Dense(256, activation='relu', input_dim=input_shape),\n",
        "            BatchNormalization(),\n",
        "            LeakyReLU(alpha=0.2),\n",
        "            Dropout(0.3),\n",
        "            Dense(512, activation='relu'),\n",
        "            BatchNormalization(),\n",
        "            LeakyReLU(alpha=0.2),\n",
        "            Dropout(0.3),\n",
        "            Dense(1024, activation='relu'),\n",
        "            BatchNormalization(),\n",
        "            LeakyReLU(alpha=0.2),\n",
        "            Dropout(0.3),\n",
        "            Dense(1, activation='linear')\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "    model = build_model(X_train.shape[1])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "    model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=128, verbose=0)\n",
        "\n",
        "    test_loss = model.evaluate(X_test, y_test)\n",
        "    predictions = model.predict(X_test).flatten()\n",
        "    r_squared = r2_score(y_test, predictions)\n",
        "\n",
        "    return model, test_loss, r_squared, predictions, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iL2LBgDCywp"
      },
      "source": [
        "# Load and preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Kevt1Sgrz7V"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "gdf = gpd.read_file('/content/drive/MyDrive/hawaii_soils/HI soils data/2024_update/annotated_combo_imputed_SOC.gpkg')\n",
        "drivers_gpd = gpd.read_file('/content/drive/MyDrive/hawaii_soils/Analysis Data/250_summary_grid_dt.gpkg')\n",
        "soils_csv = pd.read_csv('/content/drive/MyDrive/hawaii_soils/HI soils data/combined_soc_2024_04_05.csv')\n",
        "labeled_dist = pd.read_csv('/content/drive/MyDrive/hawaii_soils/labeled_distr_annote.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ECmlVaxvys7"
      },
      "outputs": [],
      "source": [
        "# Preprocess soils data\n",
        "soils_csv = soils_csv.dropna(subset=['latitude', 'longitude'])\n",
        "soils_csv['geometry'] = soils_csv.apply(lambda row: Point(float(row['longitude']), float(row['latitude'])), axis=1)\n",
        "soils_gpd = gpd.GeoDataFrame(soils_csv, geometry='geometry', crs=\"EPSG:4326\")\n",
        "\n",
        "# Merge and transform GeoDataFrames\n",
        "soils_gpd = pd.merge(soils_gpd, gdf[['dist_id', 'unique_id']], on='unique_id', how='inner')\n",
        "soils_gpd = soils_gpd.to_crs(drivers_gpd.crs)\n",
        "\n",
        "# Perform spatial join\n",
        "matched_data = gpd.sjoin_nearest(soils_gpd, drivers_gpd, how='left', distance_col='distance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0me_uTZv4cn"
      },
      "outputs": [],
      "source": [
        "# Additional preprocessing steps\n",
        "drivers_gpd['x_driver'] = drivers_gpd.geometry.x\n",
        "drivers_gpd['y_driver'] = drivers_gpd.geometry.y\n",
        "soils_gpd['x_sample'] = soils_gpd.geometry.x\n",
        "soils_gpd['y_sample'] = soils_gpd.geometry.y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soils_gpd = pd.merge(soils_gpd, labeled_dist,  on='dist_id')"
      ],
      "metadata": {
        "id": "gPSv3sFl3pj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVUvkzHBv7dz"
      },
      "outputs": [],
      "source": [
        "# Reproject both GeoDataFrames to the same CRS\n",
        "soils_buffered = soils_gpd.to_crs(epsg=32604)\n",
        "drivers_gpd = drivers_gpd.to_crs(soils_buffered.crs)\n",
        "\n",
        "# Apply buffer in the same CRS\n",
        "soils_buffered['x_sample'] = soils_buffered.geometry.x\n",
        "soils_buffered['y_sample'] = soils_buffered.geometry.y\n",
        "soils_buffered.geometry = soils_buffered.geometry.buffer(1000)\n",
        "\n",
        "# Perform spatial join\n",
        "matches_within_distance = gpd.sjoin(soils_buffered, drivers_gpd, how='left', predicate='intersects')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matches_within_distance = pd.merge(labeled_dist, matches_within_distance, on='dist_id')"
      ],
      "metadata": {
        "id": "s2VedzbMxHu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4932WNga2cJ6",
        "outputId": "b6bb8904-6c94-4e86-b965-3032733d770a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1b253ce105aa>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  matched_data['imp_c_float'] = matched_data['imp_c'].astype(float)\n"
          ]
        }
      ],
      "source": [
        "# Preprocess data and get scaled values\n",
        "numeric_df, scaler, min_c, max_c = preprocess_data(matches_within_distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming numeric_df needs to have dist_id included, merge or join it if necessary\n",
        "# numeric_df = numeric_df.merge(matches_within_distance[['dist_id']], on='some_common_column', how='left')\n",
        "\n",
        "dict_list = []\n",
        "\n",
        "for dist_id in matches_within_distance['dist_id'].unique():\n",
        "    dist_df = pd.DataFrame({\n",
        "        \"dist_id\": [dist_id],\n",
        "        \"labeled_dist\": soils_gpd[(soils_gpd['dist_id'] == dist_id) & (soils_gpd['depth_adj_bottom'] == 20)]['labeled_dist_h'].unique(),\n",
        "        \"imp_c\": [soils_gpd[(soils_gpd['dist_id'] == dist_id) & (soils_gpd['depth_adj_bottom'] == 20)]['imp_c'].tolist()],\n",
        "        \"imp_c_quantile\": [np.quantile(soils_gpd[(soils_gpd['dist_id'] == dist_id) & (soils_gpd['depth_adj_bottom'] == 20)]['imp_c'], np.linspace(0, 1, 10)).tolist()]\n",
        "    })\n",
        "    dict_list.append(dist_df)\n",
        "\n",
        "# Concatenate all DataFrames in dict_list to form a final DataFrame if needed\n",
        "dist_df = pd.concat(dict_list, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "xRrZ3Ff4dzvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxfmjFNQC3iJ"
      },
      "source": [
        "# Prepare random forest classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS3RfOz_DPsP"
      },
      "source": [
        "## Random forest specific functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Bimodal and multimodal generators\n",
        "\n",
        "def generate_bimodal_distribution(size, mean1, std1, mean2, std2, proportion1):\n",
        "    \"\"\"\n",
        "    Generate a random bimodal distribution.\n",
        "\n",
        "    Parameters:\n",
        "        size (int): Total number of samples to generate.\n",
        "        mean1 (float): Mean of the first distribution.\n",
        "        std1 (float): Standard deviation of the first distribution.\n",
        "        mean2 (float): Mean of the second distribution.\n",
        "        std2 (float): Standard deviation of the second distribution.\n",
        "        proportion1 (float): Proportion of samples from the first distribution.\n",
        "\n",
        "    Returns:\n",
        "        np.array: An array of samples from the bimodal distribution.\n",
        "    \"\"\"\n",
        "    size1 = int(size * proportion1)\n",
        "    size2 = size - size1\n",
        "    samples1 = np.random.normal(mean1, abs(std1), size1)\n",
        "    samples2 = np.random.normal(mean2, abs(std2), size2)\n",
        "    return np.concatenate([samples1, samples2])\n",
        "\n",
        "def multimodal_generator(n, mean, sd, mean_variation, sd_variation):\n",
        "    # bimodal_data = generate_bimodal_distribution(size=1000, mean1=-1*mean, std1=np.random.normal(0, sd_variation, 1), mean2=mean, std2=np.random.normal(0, sd_variation, 1), proportion1=np.random.uniform(.4, .6, 1)[0])\n",
        "    # bi_dist =  np.quantile(bimodal_data, np.linspace(0, 1, n))\n",
        "    variable_mean = mean + np.random.normal(0, mean_variation)\n",
        "    variable_sd = sd + abs(np.random.normal(0, sd_variation))\n",
        "    dist = np.random.normal(variable_mean, variable_sd, int(n*1.5))\n",
        "    dist.sort()\n",
        "    dist_a = dist[-int(n):]\n",
        "\n",
        "    variable_mean = mean+(1+mean*1.5+sd*1.5) + np.random.normal(0, mean_variation)\n",
        "    variable_sd = sd + abs(np.random.normal(0, sd_variation))\n",
        "    dist = np.random.normal(variable_mean, variable_sd, int(n*1.5)) +(1+mean_variation*1.5+sd*1.5)\n",
        "    dist.sort()\n",
        "    dist_b = dist[:int(n)]\n",
        "\n",
        "    bi_dist = np.concatenate([dist_a,dist_b])\n",
        "    return bi_dist"
      ],
      "metadata": {
        "id": "Ip6w_FynuOJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKQhCxxUDUFh"
      },
      "outputs": [],
      "source": [
        "def normal_generator(n, mean, sd, mean_variation, sd_variation):\n",
        "    variable_mean = mean + np.random.normal(0, mean_variation)\n",
        "    variable_sd = sd + abs(np.random.normal(0, sd_variation))\n",
        "    return np.random.normal(variable_mean, variable_sd, n)\n",
        "\n",
        "def uniform_generator(n, min_val, max_val, min_variation, max_variation):\n",
        "    variable_min = min_val + np.random.uniform(-min_variation, min_variation)\n",
        "    variable_max = max_val + np.random.uniform(-max_variation, max_variation)\n",
        "    return np.random.uniform(variable_min, variable_max, n)\n",
        "\n",
        "def left_tailed_generator(n, mean, sd, mean_variation, sd_variation):\n",
        "    variable_mean = mean + np.random.normal(0, mean_variation)\n",
        "    variable_sd = sd + abs(np.random.normal(0, sd_variation))\n",
        "    dist = np.random.normal(variable_mean, variable_sd, int(n*1.5))\n",
        "    dist.sort()\n",
        "    return dist[:int(n)]\n",
        "\n",
        "def right_tailed_generator(n, mean, sd, mean_variation, sd_variation):\n",
        "    variable_mean = mean + np.random.normal(0, mean_variation)\n",
        "    variable_sd = sd + abs(np.random.normal(0, sd_variation))\n",
        "    dist = np.random.normal(variable_mean, variable_sd, int(n*1.5))\n",
        "    dist.sort()\n",
        "    return dist[-int(n):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00J-3sF6DVB_"
      },
      "outputs": [],
      "source": [
        "def rescale_to_minus_one_one(values):\n",
        "    min_value = np.min(values)\n",
        "    max_value = np.max(values)\n",
        "    scaled_values = 2 * ((values - min_value) / (max_value - min_value)) - 1\n",
        "    return scaled_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZDSdtSwDXDf"
      },
      "outputs": [],
      "source": [
        "def generate_samples(n, q, generator_func, *args):\n",
        "    samples = generator_func(n, *args)\n",
        "    samples_q = np.quantile(samples, np.linspace(0, 1, q))\n",
        "    return rescale_to_minus_one_one(samples_q)\n",
        "\n",
        "def generate_normal_samples(n=10000, q=10, mean_value=0, sd_value=1, mean_variation=0.5, sd_variation=0.5):\n",
        "    return generate_samples(n, q, normal_generator, mean_value, sd_value, mean_variation, sd_variation)\n",
        "\n",
        "def generate_uniform_samples(n=10000, q=10, min_value=-1, max_value=1, min_variation=0.5, max_variation=0.5):\n",
        "    return generate_samples(n, q, uniform_generator, min_value, max_value, min_variation, max_variation)\n",
        "\n",
        "def generate_right_tailed_samples(n=10000, q=10, mean=0, sd=1, mean_variation=0.5, sd_variation=0.5):\n",
        "    return generate_samples(n, q, right_tailed_generator, mean, sd, mean_variation, sd_variation)\n",
        "\n",
        "def generate_left_tailed_samples(n=10000, q=10, mean=0, sd=1, mean_variation=0.5, sd_variation=0.5):\n",
        "    return generate_samples(n, q, left_tailed_generator, mean, sd, mean_variation, sd_variation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_multimodal_samples(n=10000, q=10, mean=0, sd=1, mean_variation=0.5, sd_variation=0.5):\n",
        "#     # samples = generate_samples(n, q, left_tailed_generator, mean, sd, mean_variation, sd_variation)\n",
        "#     return generate_samples(n, q, multimodal_generator, mean, sd, mean_variation, sd_variation)"
      ],
      "metadata": {
        "id": "RU4tmEM3MLyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogNva38SDbyZ"
      },
      "outputs": [],
      "source": [
        "def generate_training_data(n_samples=10000):\n",
        "    data_list = {}\n",
        "\n",
        "    # Generate samples for each distribution type\n",
        "    data_list['normal'] = [generate_normal_samples() for _ in range(n_samples)]\n",
        "   # data_list['bimodal'] = [generate_multimodal_samples() for _ in range(n_samples)]\n",
        "    data_list['uniform'] = [generate_uniform_samples() for _ in range(n_samples)]\n",
        "    data_list['right_tailed'] = [generate_right_tailed_samples() for _ in range(n_samples)]\n",
        "    data_list['left_tailed'] = [generate_left_tailed_samples() for _ in range(n_samples)]\n",
        "\n",
        "    # Combine all data into a single DataFrame\n",
        "    combined_data = pd.DataFrame()\n",
        "    for name, samples_list in data_list.items():\n",
        "        df = pd.DataFrame(samples_list)\n",
        "        df['label'] = name\n",
        "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
        "\n",
        "    # Assign column names\n",
        "    combined_data.columns = [f'V{i+1}' for i in range(combined_data.shape[1] - 1)] + ['label']\n",
        "\n",
        "    return combined_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0phs9ADczH"
      },
      "source": [
        "## Train random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def left_tailed_generator(n, mean, sd, mean_variation, sd_variation):\n",
        "    variable_mean = mean + np.random.normal(0, mean_variation)\n",
        "    variable_sd = sd + abs(np.random.normal(0, sd_variation))\n",
        "    dist = np.random.normal(variable_mean, variable_sd, int(n*1.5))\n",
        "    dist.sort()\n",
        "    return dist[-int(n):]"
      ],
      "metadata": {
        "id": "21jmfUoENrs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # data = np.quantile(multimodal_generator(100, 1,  1,1,1),np.linspace(0, 1, 10))\n",
        "# # data = multimodal_generator(100, 1,  1,1,1)\n",
        "\n",
        "# # Create a histogram plot\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.hist(data, bins=30, color='blue', alpha=0.7)\n",
        "# plt.title('Histogram of Random Data')\n",
        "# plt.xlabel('Values')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.grid(True)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "ijLmNpl9N6My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Quantile plot\n",
        "# plt.figure(figsize=(8, 4))\n",
        "# percentiles = [10,20,30,40,50,60,70,80,90,100]\n",
        "# plt.plot(percentiles, np.quantile(multimodal_generator(100, 1,  1,1,1),np.linspace(0, 1, 10)), marker='o')\n",
        "# plt.title('Quantile Plot')\n",
        "# plt.xlabel('Percentiles')\n",
        "# plt.ylabel('Quantile Values')\n",
        "# plt.grid(True)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0rkpKlj-67UD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_df['imp_c_quantile_scaled'] = [rescale_to_minus_one_one(dist) for dist in dist_df[\"imp_c_quantile\"]]"
      ],
      "metadata": {
        "id": "nCod5-Zs7pQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4k-6e748Cyl",
        "outputId": "e86be4a4-48d6-4b27-f79e-a82047e28633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['dist_id', 'labeled_dist', 'imp_c', 'imp_c_quantile',\n",
              "       'imp_c_quantile_scaled'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_true = label_encoder.inverse_transform(y_encoded).tolist()"
      ],
      "metadata": {
        "id": "Teq2rShTBQwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = generate_training_data()"
      ],
      "metadata": {
        "id": "bE2_qeVRCFdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ghIXgrOUhewm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpxXSdi8DqIv",
        "outputId": "cf1011f0-6066-4380-d854-8da3614d8c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Save for later; cross validation random forest for truth data\n",
        "\n",
        "# Separate features and labels\n",
        "X = pd.DataFrame(dist_df['imp_c_quantile_scaled'].tolist(), columns=[f'col{i}' for i in range(1, 11)])\n",
        "y = dist_df['labeled_dist']\n",
        "# Encode labels as integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_pred_list = []\n",
        "for i in range(len(X)):\n",
        "\n",
        "\n",
        "  # Initialize the Random Forest Classifier\n",
        "  rf_model = RandomForestClassifier(n_estimators=500, max_leaf_nodes=50, min_samples_leaf=2)\n",
        "\n",
        "  # Train the model\n",
        "  rf_model.fit(np.array(X.drop(index= i)), np.concatenate([y[:i], y[i+1:]]))\n",
        "\n",
        "  # Print the trained model\n",
        "  print(rf_model)\n",
        "\n",
        "  # Predict the responses for test dataset\n",
        "  y_pred =  rf_model.predict(X)[i]\n",
        "  y_pred_list.append(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=500, max_leaf_nodes=50, min_samples_leaf=2)\n",
        "\n",
        "# Train the model\n",
        "# rf_model.fit(np.array(training_data.drop('label', axis=1)),training_data['label'])\n",
        "rf_model.fit(np.array(X),y)"
      ],
      "metadata": {
        "id": "mV2gwiwLuD_0",
        "outputId": "461d06f5-a00d-46c7-ff8f-1a5dc5d884c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_leaf_nodes=50, min_samples_leaf=2, n_estimators=500)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred_list = rf_model.predict(X)\n",
        "y_true = y"
      ],
      "metadata": {
        "id": "_HQVP4xMHC_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred_list))\n",
        "\n",
        "# Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred_list))\n",
        "\n",
        "# Precision, Recall, F1-Score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_list))\n",
        "\n",
        "# If it's a binary classification, calculate ROC-AUC\n",
        "if len(np.unique(y_pred_list)) == 2:\n",
        "    y_probs = rf_model.predict_proba(X_test)[:, 1]  # probability estimates for the positive class\n",
        "    fpr, tpr, thresholds = roc_curve(y_pred_list, y_probs)\n",
        "    print(\"AUC:\", auc(fpr, tpr))\n"
      ],
      "metadata": {
        "id": "cr2DM2Njugee",
        "outputId": "b9842794-867f-4395-cb22-7f8c14034ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 9  1  0  1]\n",
            " [ 1  7  0  5]\n",
            " [ 0  1 25  1]\n",
            " [ 2  1  4 19]]\n",
            "Accuracy: 0.7792207792207793\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " left tailed       0.75      0.82      0.78        11\n",
            "      normal       0.70      0.54      0.61        13\n",
            "right tailed       0.86      0.93      0.89        27\n",
            "     uniform       0.73      0.73      0.73        26\n",
            "\n",
            "    accuracy                           0.78        77\n",
            "   macro avg       0.76      0.75      0.75        77\n",
            "weighted avg       0.77      0.78      0.77        77\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLt0CBTkC9VZ"
      },
      "source": [
        "# Cross validation loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZ55XihZMdsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation: loop through all dist_ids, one at a time\n",
        "# subset data to exclude unlabeled distributions 1st\n",
        "\n",
        "data = numeric_df.dropna(subset=['dist_id'])\n",
        "\n",
        "unique_dist_ids = data['dist_id'].unique()\n",
        "np.random.shuffle(unique_dist_ids)\n"
      ],
      "metadata": {
        "id": "zME6ms1_8EtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_lists = [unique_dist_ids[i:i + 5] for i in range(0, len(unique_dist_ids), 5)]"
      ],
      "metadata": {
        "id": "jfSWblBj8FuE"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set_lists"
      ],
      "metadata": {
        "id": "JQqmcwLV9EAH",
        "outputId": "c790290a-8f82-412f-83cc-0e53e448f0e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([73,  1, 60, 18, 58]),\n",
              " array([23, 76, 51, 63, 66]),\n",
              " array([31, 47, 30, 20,  5]),\n",
              " array([15, 77, 43, 53, 12]),\n",
              " array([ 3, 56, 29, 75, 13]),\n",
              " array([70, 42, 65, 52, 54]),\n",
              " array([46, 41, 50, 40, 82]),\n",
              " array([67, 24, 84, 61,  6]),\n",
              " array([26, 74, 17,  2, 44]),\n",
              " array([81, 71, 49, 45, 88]),\n",
              " array([22, 11, 86, 83, 14]),\n",
              " array([33, 27, 25, 59, 38]),\n",
              " array([68, 39, 78, 69, 87]),\n",
              " array([16, 19, 48, 21, 79]),\n",
              " array([57, 72, 80, 64, 28]),\n",
              " array([62, 85])]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpM7JLhTwKJ8",
        "outputId": "650138d9-1c1a-4ef1-dfe8-6b9d64cf38b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0115\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "for set_list_id in range(len(set_lists)):\n",
        "  unique_dist_ids = set_lists[set_list_id]\n",
        "  result_list = []\n",
        "\n",
        "  # Loop over each dist_id, leaving one out at time\n",
        "  for xval_id in unique_dist_ids:\n",
        "      r2_list = []\n",
        "      loss_list = []\n",
        "      prediction_list = []\n",
        "      matched_data_list = []\n",
        "      model_list = []\n",
        "      # Reserve data for validation\n",
        "      xval_data = data[data['dist_id'] == xval_id]\n",
        "\n",
        "      # Matched data for training\n",
        "      train_data = data[data['dist_id'] != xval_id]\n",
        "\n",
        "      reserve_data = train_data.groupby('unique_id').sample(n=1)\n",
        "\n",
        "      for i in range(10):\n",
        "          matched_data = train_data.groupby('unique_id').sample(n=1)\n",
        "          matched_data = matched_data.reset_index(drop=True)\n",
        "\n",
        "          model, test_loss, r_squared, predictions, y_test = train_model_a(matched_data)\n",
        "\n",
        "          predictions = predict_on_reserve(reserve_data, model, min_c, max_c)\n",
        "\n",
        "          matched_data_list.append(matched_data)\n",
        "          prediction_list.append(predictions)\n",
        "          model_list.append(model)\n",
        "          loss_list.append(test_loss)\n",
        "          r2_list.append(r_squared)\n",
        "\n",
        "      combined_array = np.array([predictions['predictions'].values for predictions in prediction_list])\n",
        "      combined_array[combined_array < 0 ] = 0\n",
        "\n",
        "      arr_min = np.min(combined_array.flatten())\n",
        "      arr_max = np.max(combined_array.flatten())\n",
        "\n",
        "      dist_array = [np.sort(np.array([i[j] for  i in combined_array])) for j in range(combined_array.shape[1])]\n",
        "      norm_dist_array =  [np.sort((np.array([i[j] for  i in combined_array]) - arr_min) / (arr_max-arr_min)) for j in range(combined_array.shape[1])]\n",
        "\n",
        "      keep_cols = ['water', 'trees','grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built',\n",
        "                  'bare', 'snow_and_ice', 'max', 'elevation', 'landform', 'SRTM_mTPI','aet', 'def',\n",
        "                  'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn','tmmx', 'vap', 'vpd', 'vs',\n",
        "                  'agbd_m', 'agbd_sd', 'agbd_n']\n",
        "\n",
        "      scaled_numeric_df = prediction_list[0][keep_cols]\n",
        "\n",
        "      scaled_numeric_df['norm_dist_array'] = norm_dist_array\n",
        "      scaled_numeric_df.dropna(inplace=True)\n",
        "\n",
        "      scaled_numeric_df['norm_dist_array'] = scaled_numeric_df['norm_dist_array'].to_list()\n",
        "\n",
        "      norm_dist_array = np.array([i for i in scaled_numeric_df['norm_dist_array']])\n",
        "\n",
        "      X = scaled_numeric_df[keep_cols]\n",
        "      y = norm_dist_array\n",
        "\n",
        "      # X = scaled_numeric_df.iloc[:, :-1]\n",
        "      # y = scaled_numeric_df.iloc[:, -1]\n",
        "\n",
        "      # x = np.array(X)\n",
        "      # y = np.array(norm_dist_array)\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "      model = build_model(X_train.shape[1],output_shape=10)\n",
        "\n",
        "      model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error',metrics = ['mae'])\n",
        "      model.fit(X_train, y_train, validation_split=0.2, epochs=600, batch_size=128, verbose=0)\n",
        "      model.compile(optimizer=Adam(learning_rate=0.00001), loss='mean_squared_error',metrics = ['mae'])\n",
        "      model.fit(X_train, y_train, validation_split=0.2, epochs=600, batch_size=128, verbose=0)\n",
        "\n",
        "      test_loss = model.evaluate(X_test, y_test)\n",
        "\n",
        "\n",
        "      predictions = model.predict(xval_data[keep_cols])\n",
        "      imp_c_scaled = np.sort(xval_data.groupby('unique_id').sample(n=1)['imp_c_scaled']*max_c+min_c)\n",
        "\n",
        "      imp_c_quantiles = np.quantile(imp_c_scaled, np.linspace(0, 1,10))\n",
        "\n",
        "      scaled_predictions = predictions*max_c+min_c\n",
        "      prediction_quantiles = [np.quantile(prediction, np.linspace(0, 1,10)) for prediction in scaled_predictions]\n",
        "\n",
        "      prediction_rf_ready_predictions = [rescale_to_minus_one_one(sorted(prediction)) for prediction in  predictions]\n",
        "\n",
        "      # Use the trained model to make predictions\n",
        "      predicted_labels_encoded = rf_model.predict(prediction_rf_ready_predictions)\n",
        "\n",
        "      # Decode the encoded labels back to original labels\n",
        "      predicted_predicted_labels = predicted_labels_encoded #here\n",
        "\n",
        "      real_rf_ready = [rescale_to_minus_one_one(sorted(prediction)+ np.random.uniform(-0.001, 0.001, prediction.shape[0])) for prediction in  [imp_c_quantiles]]\n",
        "\n",
        "      # Use the trained model to make predictions\n",
        "      real_labels_encoded = rf_model.predict(real_rf_ready)\n",
        "\n",
        "\n",
        "      # Decode the encoded labels back to original labels\n",
        "      real_predicted_labels = real_labels_encoded #here\n",
        "\n",
        "      lat_lon = [Point(xy) for xy in zip(xval_data['latitude'],xval_data['longitude'])]\n",
        "      xy_sample = [Point(xy) for xy in zip(xval_data['x_sample'],xval_data['y_sample'])]\n",
        "      xy_driver = [Point(xy) for xy in zip(xval_data['x_driver'],xval_data['y_driver'])]\n",
        "\n",
        "      result_dict ={\n",
        "                    \"xval_id\": xval_id,\n",
        "                    \"lat_lon\": lat_lon,\n",
        "                    \"xy_sample\": xy_sample,\n",
        "                    \"xy_driver\": xy_driver,\n",
        "                    \"imp_c_scaled\": imp_c_scaled,\n",
        "                    \"imp_c_quantiles\": imp_c_quantiles,\n",
        "                    \"real_predicted_labels\": real_predicted_labels,\n",
        "                    \"scaled_predictions\": scaled_predictions,\n",
        "                    \"prediction_quantiles\": prediction_quantiles,\n",
        "                    \"predicted_predicted_labels\": predicted_predicted_labels\n",
        "                  }\n",
        "      result_list.append(result_dict)\n",
        "\n",
        "  import pickle\n",
        "  # Specify the filename\n",
        "  filename = f'/content/drive/MyDrive/hawaii_soils/result_list_{set_list_id}.pkl'\n",
        "\n",
        "  # Open the file in binary write mode and save the result_list\n",
        "  with open(filename, 'wb') as file:\n",
        "      pickle.dump(result_list, file)\n",
        "\n",
        "  print(f\"Data has been pickled and saved to {filename}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result_list)"
      ],
      "metadata": {
        "id": "UQzDIPdhzz0K",
        "outputId": "cd831f45-9b40-4b83-e43d-e6ea45ea5604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QYmOsRWys4UE",
        "outputId": "425dadfe-9038-4a4e-8e89-e3331203364f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been pickled and saved to result_list.pkl.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_list[4]['imp_c_quantiles']\n"
      ],
      "metadata": {
        "id": "1GWo8gLczV6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf = gpd.GeoDataFrame({'median ': [i[5]for i in result_list[4]['prediction_quantiles']],'median_z': [i[5]-result_list[4]['imp_c_quantiles'][5] for i in result_list[4]['prediction_quantiles']],'geometry': result_list[4]['xy_driver']})\n",
        "gdf.set_crs(epsg = 32604, inplace=True)\n",
        "gdf.to_file('test.gpkg')"
      ],
      "metadata": {
        "id": "sOrk2UaEw8Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di4gqBeWFycT"
      },
      "outputs": [],
      "source": [
        "# Calculate average R-squared and loss\n",
        "average_r_squared = np.mean(r2_list)\n",
        "average_loss = np.mean(loss_list)\n",
        "\n",
        "print(average_r_squared)\n",
        "print(average_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(r2_list, bins=20, color='blue', alpha=0.7)\n",
        "plt.title('R-squared Distribution')\n",
        "plt.xlabel('R-squared')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(loss_list, bins=20, color='red', alpha=0.7)\n",
        "plt.title('Loss Distribution')\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h0Q1CjpKatTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_id_performance = {}\n",
        "for i, dist_id in enumerate(unique_dist_ids):\n",
        "    if dist_id not in dist_id_performance:\n",
        "        dist_id_performance[dist_id] = []\n",
        "    dist_id_performance[dist_id].append(r2_list[i])\n",
        "\n",
        "# Print R-squared by dist_id\n",
        "for dist_id, performances in dist_id_performance.items():\n",
        "    print(f\"Dist_id {dist_id} - Average R-squared: {np.mean(performances)}\")"
      ],
      "metadata": {
        "id": "FppR_9TTa1f_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMN4qWApGsuqb8cmGJroW/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}